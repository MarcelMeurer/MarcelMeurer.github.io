
var documents = [{
    "id": 0,
    "url": "https://blog.itprocloud.de/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "https://blog.itprocloud.de/about",
    "title": "About this blog",
    "body": "What is the purpose of this page?: The blog is part of ITProCloud GmbH. The company is focused on developing software solutions to make working in IT easier. I’m writing this blog to share my experiences in IT focused on Microsoft Azure. My Biography: I started my IT career in the early 1990s with first contacts to personal computers (and before that with the Commodore 64). Assembler and hardware-related programming were in my focus – the IoT of the 90s. In the year 1995, I started studying electrical engineering. During my studies, machine learning and neural networks were one of my favorite topics. In addition to my studies, I worked for a small computer company in Aachen, where I provided operating systems and applications with automated methods on many computers. I graduated as an engineer in electrical engineering from the University of Applied Science Aachen. Speaking at your conference: If you are hosting events realted to the Azure Cloud, IoT, Development, Azure Monitor, etc. I would be happy to support this event with content. Feel free to contact me. Get in touch with me:       												             												      			  												            												      			"
    }, {
    "id": 2,
    "url": "https://blog.itprocloud.de/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 3,
    "url": "https://blog.itprocloud.de/Impressum",
    "title": "Impressum",
    "body": "Angaben gemäß § 5 TMGITProCloud GmbHEichholzer Weg 3551519 OdenthalDeutschland / Germany Vertreten durch:Marcel Meurer, Geschäftsführer Kontakt:Telefon: +49 2207 8497770E-Mail: marcel. meurer@itprocloud. com Registereintrag:Eintragung im Registergericht: KölnRegisternummer: HRB 107207 Verantwortlich für den Inhalt nach § 55 Abs. 2 RStV:Marcel MeurerEichholzer Weg 3551519 Odenthal "
    }, {
    "id": 4,
    "url": "https://blog.itprocloud.de/ImpressumEn",
    "title": "Imprint",
    "body": "Information in accordance with section 5 TMG:ITProCloud GmbHEichholzer Weg 3551519 OdenthalGermany Represented by:Marcel Meurer, CEO Contact:Phone: +49 2207 8497770Mail: marcel. meurer@itprocloud. com Register entry:Entry in the register court: CologneNumber: HRB 107207 Person responsible for content in accordance with 55 Abs. 2 RStV:Marcel MeurerEichholzer Weg 3551519 Odenthal "
    }, {
    "id": 5,
    "url": "https://blog.itprocloud.de/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:     {% for post in site. posts %}  {% if post. featured == true %}    {% include featuredbox. html %}  {% endif %}{% endfor %}&lt;/div&gt;{% endif %} &lt;div class=&quot;section-title&quot;&gt;  &lt;h2&gt;&lt;span&gt;All Posts&lt;/span&gt;&lt;/h2&gt;&lt;/div&gt;&lt;div class=&quot;row listrecent&quot;&gt;  {% for post in paginator. posts %}  {% include postbox. html %}  {% endfor %}&lt;/div&gt;  {% include pagination. html %}"
    }, {
    "id": 6,
    "url": "https://blog.itprocloud.de/privacyDe",
    "title": "Datenschutz",
    "body": "[English version]({% link _pages/privacy-en. md %}) Datenschutzerklärung: Personenbezogene Daten (nachfolgend zumeist nur „Daten“ genannt) werden von uns nur im Rahmen der Erforderlichkeit sowie zum Zwecke der Bereitstellung eines funktionsfähigen und nutzerfreundlichen Internetauftritts, inklusive seiner Inhalte und der dort angebotenen Leistungen, verarbeitet. Gemäß Art. 4 Ziffer 1. der Verordnung (EU) 2016/679, also der Datenschutz-Grundverordnung (nachfolgend nur „DSGVO“ genannt), gilt als „Verarbeitung“ jeder mit oder ohne Hilfe automatisierter Verfahren ausgeführter Vorgang oder jede solche Vorgangsreihe im Zusammenhang mit personenbezogenen Daten, wie das Erheben, das Erfassen, die Organisation, das Ordnen, die Speicherung, die Anpassung oder Veränderung, das Auslesen, das Abfragen, die Verwendung, die Offenlegung durch Übermittlung, Verbreitung oder eine andere Form der Bereitstellung, den Abgleich oder die Verknüpfung, die Einschränkung, das Löschen oder die Vernichtung. Mit der nachfolgenden Datenschutzerklärung informieren wir Sie insbesondere über Art, Umfang, Zweck, Dauer und Rechtsgrundlage der Verarbeitung personenbezogener Daten, soweit wir entweder allein oder gemeinsam mit anderen über die Zwecke und Mittel der Verarbeitung entscheiden. Zudem informieren wir Sie nachfolgend über die von uns zu Optimierungszwecken sowie zur Steigerung der Nutzungsqualität eingesetzten Fremdkomponenten, soweit hierdurch Dritte Daten in wiederum eigener Verantwortung verarbeiten. Unsere Datenschutzerklärung ist wie folgt gegliedert: I. Informationen über uns als VerantwortlicheII. Rechte der Nutzer und BetroffenenIII. Informationen zur Datenverarbeitung I. Informationen über uns als Verantwortliche: Verantwortlicher Anbieter dieses Internetauftritts im datenschutzrechtlichen Sinne ist: ITProCloud GmbHEichholzer Weg 3551519 OdenthalDeutschland Telefon: +49 2207 8497770E-Mail: marcel. meurer@itprocloud. com II. Rechte der Nutzer und Betroffenen: Mit Blick auf die nachfolgend noch näher beschriebene Datenverarbeitung haben die Nutzer und Betroffenen das Recht auf Bestätigung, ob sie betreffende Daten verarbeitet werden, auf Auskunft über die verarbeiteten Daten, auf weitere Informationen über die Datenverarbeitung sowie auf Kopien der Daten (vgl. auch Art. 15 DSGVO);auf Berichtigung oder Vervollständigung unrichtiger bzw. unvollständiger Daten (vgl. auch Art. 16 DSGVO);auf unverzügliche Löschung der sie betreffenden Daten (vgl. auch Art. 17 DSGVO), oder, alternativ, soweit eine weitere Verarbeitung gemäß Art. 17 Abs. 3 DSGVO erforderlich ist, auf Einschränkung der Verarbeitung nach Maßgabe von Art. 18 DSGVO;auf Erhalt der sie betreffenden und von ihnen bereitgestellten Daten und auf Übermittlung dieser Daten an andere Anbieter/Verantwortliche (vgl. auch Art. 20 DSGVO);auf Beschwerde gegenüber der Aufsichtsbehörde, sofern sie der Ansicht sind, dass die sie betreffenden Daten durch den Anbieter unter Verstoß gegen datenschutzrechtliche Bestimmungen verarbeitet werden (vgl. auch Art. 77 DSGVO). Darüber hinaus ist der Anbieter dazu verpflichtet, alle Empfänger, denen gegenüber Daten durch den Anbieter offengelegt worden sind, über jedwede Berichtigung oder Löschung von Daten oder die Einschränkung der Verarbeitung, die aufgrund der Artikel 16, 17 Abs. 1, 18 DSGVO erfolgt, zu unterrichten. Diese Verpflichtung besteht jedoch nicht, soweit diese Mitteilung unmöglich oder mit einem unverhältnismäßigen Aufwand verbunden ist. Unbeschadet dessen hat der Nutzer ein Recht auf Auskunft über diese Empfänger. Ebenfalls haben die Nutzer und Betroffenen nach Art. 21 DSGVO das Recht auf Widerspruch gegen die künftige Verarbeitung der sie betreffenden Daten, sofern die Daten durch den Anbieter nach Maßgabe von Art. 6 Abs. 1 lit. f) DSGVO verarbeitet werden. Insbesondere ist ein Widerspruch gegen die Datenverarbeitung zum Zwecke der Direktwerbung statthaft. III. Informationen zur Datenverarbeitung: Ihre bei Nutzung unseres Internetauftritts verarbeiteten Daten werden gelöscht oder gesperrt, sobald der Zweck der Speicherung entfällt, der Löschung der Daten keine gesetzlichen Aufbewahrungspflichten entgegenstehen und nachfolgend keine anderslautenden Angaben zu einzelnen Verarbeitungsverfahren gemacht werden. Cookies: a) Sitzungs-Cookies/Session-CookiesWir verwenden mit unserem Internetauftritt sog. Cookies. Cookies sind kleine Textdateien oder andere Speichertechnologien, die durch den von Ihnen eingesetzten Internet-Browser auf Ihrem Endgerät ablegt und gespeichert werden. Durch diese Cookies werden im individuellen Umfang bestimmte Informationen von Ihnen, wie beispielsweise Ihre Browser- oder Standortdaten oder Ihre IP-Adresse, verarbeitet.   Durch diese Verarbeitung wird unser Internetauftritt benutzerfreundlicher, effektiver und sicherer, da die Verarbeitung bspw. die Wiedergabe unseres Internetauftritts in unterschiedlichen Sprachen oder das Angebot einer Warenkorbfunktion ermöglicht. Rechtsgrundlage dieser Verarbeitung ist Art. 6 Abs. 1 lit b. ) DSGVO, sofern diese Cookies Daten zur Vertragsanbahnung oder Vertragsabwicklung verarbeitet werden. Falls die Verarbeitung nicht der Vertragsanbahnung oder Vertragsabwicklung dient, liegt unser berechtigtes Interesse in der Verbesserung der Funktionalität unseres Internetauftritts. Rechtsgrundlage ist in dann Art. 6 Abs. 1 lit. f) DSGVO. Mit Schließen Ihres Internet-Browsers werden diese Session-Cookies gelöscht. b) Drittanbieter-CookiesGegebenenfalls werden mit unserem Internetauftritt auch Cookies von Partnerunternehmen, mit denen wir zum Zwecke der Werbung, der Analyse oder der Funktionalitäten unseres Internetauftritts zusammenarbeiten, verwendet. Die Einzelheiten hierzu, insbesondere zu den Zwecken und den Rechtsgrundlagen der Verarbeitung solcher Drittanbieter-Cookies, entnehmen Sie bitte den nachfolgenden Informationen. c) BeseitigungsmöglichkeitSie können die Installation der Cookies durch eine Einstellung Ihres Internet-Browsers verhindern oder einschränken. Ebenfalls können Sie bereits gespeicherte Cookies jederzeit löschen. Die hierfür erforderlichen Schritte und Maßnahmen hängen jedoch von Ihrem konkret genutzten Internet-Browser ab. Bei Fragen benutzen Sie daher bitte die Hilfefunktion oder Dokumentation Ihres Internet-Browsers oder wenden sich an dessen Hersteller bzw. Support. Bei sog. Flash-Cookies kann die Verarbeitung allerdings nicht über die Einstellungen des Browsers unterbunden werden. Stattdessen müssen Sie insoweit die Einstellung Ihres Flash-Players ändern. Auch die hierfür erforderlichen Schritte und Maßnahmen hängen von Ihrem konkret genutzten Flash-Player ab. Bei Fragen benutzen Sie daher bitte ebenso die Hilfefunktion oder Dokumentation Ihres Flash-Players oder wenden sich an den Hersteller bzw. Benutzer-Support. Sollten Sie die Installation der Cookies verhindern oder einschränken, kann dies allerdings dazu führen, dass nicht sämtliche Funktionen unseres Internetauftritts vollumfänglich nutzbar sind. Kontaktanfragen / Kontaktmöglichkeit: Sofern Sie per Kontaktformular oder E-Mail mit uns in Kontakt treten, werden die dabei von Ihnen angegebenen Daten zur Bearbeitung Ihrer Anfrage genutzt. Die Angabe der Daten ist zur Bearbeitung und Beantwortung Ihre Anfrage erforderlich - ohne deren Bereitstellung können wir Ihre Anfrage nicht oder allenfalls eingeschränkt beantworten. Rechtsgrundlage für diese Verarbeitung ist Art. 6 Abs. 1 lit. b) DSGVO. Ihre Daten werden gelöscht, sofern Ihre Anfrage abschließend beantwortet worden ist und der Löschung keine gesetzlichen Aufbewahrungspflichten entgegenstehen, wie bspw. bei einer sich etwaig anschließenden Vertragsabwicklung. Nutzerbeiträge, Kommentare und Bewertungen: Wir bieten Ihnen an, auf unseren Internetseiten Fragen, Antworten, Meinungen oder Bewertungen, nachfolgend nur „Beiträge genannt, zu veröffentlichen. Sofern Sie dieses Angebot in Anspruch nehmen, verarbeiten und veröffentlichen wir Ihren Beitrag, Datum und Uhrzeit der Einreichung sowie das von Ihnen ggf. genutzte Pseudonym. Rechtsgrundlage hierbei ist Art. 6 Abs. 1 lit. a) DSGVO. Die Einwilligung können Sie gemäß Art. 7 Abs. 3 DSGVO jederzeit mit Wirkung für die Zukunft widerrufen. Hierzu müssen Sie uns lediglich über Ihren Widerruf in Kenntnis setzen. Darüber hinaus verarbeiten wir auch Ihre IP- und E-Mail-Adresse. Die IP-Adresse wird verarbeitet, weil wir ein berechtigtes Interesse daran haben, weitere Schritte einzuleiten oder zu unterstützen, sofern Ihr Beitrag in Rechte Dritter eingreift und/oder er sonst wie rechtswidrig erfolgt. Rechtsgrundlage ist in diesem Fall Art. 6 Abs. 1 lit. f) DSGVO. Unser berechtigtes Interesse liegt in der ggf. notwendigen Rechtsverteidigung. Abonnement von Beiträgen: Sofern Sie Beiträge auf unseren Internetseiten veröffentlichen, bieten wir Ihnen zusätzlich an, etwaige Folgebeiträge Dritter zu abonnieren. Um Sie über diese Folgebeiträge per E-Mail informieren zu können, verarbeiten wir Ihre E-Mail-Adresse. Rechtsgrundlage hierbei ist Art. 6 Abs. 1 lit. a) DSGVO. Die Einwilligung in dieses Abonnement können Sie gemäß Art. 7 Abs. 3 DSGVO jederzeit mit Wirkung für die Zukunft widerrufen. Hierzu müssen Sie uns lediglich über Ihren Widerruf in Kenntnis setzen oder den in der jeweiligen E-Mail enthaltenen Abmeldelink betätigen. Twitter: Wir unterhalten bei Twitter eine Onlinepräsenz um unser Unternehmen sowie unsere Leistungen zu präsentieren und mit Kunden/Interessenten zu kommunizieren. Twitter ist ein Service der Twitter Inc. , 1355 Market Street, Suite 900, San Francisco, CA 94103, USA. Insofern weisen wir darauf hin, dass die Möglichkeit besteht, dass Daten der Nutzer außerhalb der Europäischen Union, insbesondere in den USA, verarbeitet werden. Hierdurch können gesteigerte Risiken für die Nutzer insofern bestehen, als dass z. B. der spätere Zugriff auf die Nutzerdaten erschwert werden kann. Auch haben wir keinen Zugriff auf diese Nutzerdaten. Die Zugriffsmöglichkeit liegt ausschließlich bei Twitter. Die Twitter Inc. ist unter dem Privacy Shield zertifiziert und hat sich damit verpflichtet, die europäischen Datenschutzstandards einzuhalten https://www. privacyshield. gov/participant?id=a2zt0000000TORzAAO&amp;status=Active Die Datenschutzhinweise von Twitter finden Sie unter https://twitter. com/de/privacy YouTube: Wir unterhalten bei YouTube eine Onlinepräsenz um unser Unternehmen sowie unsere Leistungen zu präsentieren und mit Kunden/Interessenten zu kommunizieren. YouTube ist ein Service der Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland, ein Tochterunternehmen der Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043 USA. Insofern weisen wir darauf hin, dass die Möglichkeit besteht, dass Daten der Nutzer außerhalb der Europäischen Union, insbesondere in den USA, verarbeitet werden. Hierdurch können gesteigerte Risiken für die Nutzer insofern bestehen, als dass z. B. der spätere Zugriff auf die Nutzerdaten erschwert werden kann. Auch haben wir keinen Zugriff auf diese Nutzerdaten. Die Zugriffsmöglichkeit liegt ausschließlich bei YouTube. Die Google LLC ist unter dem Privacy Shield zertifiziert und hat sich damit verpflichtet, die europäischen Datenschutzstandards einzuhalten https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active Die Datenschutzhinweise von YouTube finden Sie unter https://policies. google. com/privacy LinkedIn: Wir unterhalten bei LinkedIn eine Onlinepräsenz um unser Unternehmen sowie unsere Leistungen zu präsentieren und mit Kunden/Interessenten zu kommunizieren. LinkedIn ist ein Service der LinkedIn Ireland Unlimited Company, Wilton Plaza, Wilton Place, Dublin 2, Irland, ein Tochterunternehmen der LinkedIn Corporation, 1000 W. Maude Avenue, Sunnyvale, CA 94085, USA. Insofern weisen wir darauf hin, dass die Möglichkeit besteht, dass Daten der Nutzer außerhalb der Europäischen Union, insbesondere in den USA, verarbeitet werden. Hierdurch können gesteigerte Risiken für die Nutzer insofern bestehen, als dass z. B. der spätere Zugriff auf die Nutzerdaten erschwert werden kann. Auch haben wir keinen Zugriff auf diese Nutzerdaten. Die Zugriffsmöglichkeit liegt ausschließlich bei LinkedIn. Die LinkedIn Corporation ist unter dem Privacy Shield zertifiziert und hat sich damit verpflichtet, die europäischen Datenschutzstandards einzuhalten https://www. privacyshield. gov/participant?id=a2zt0000000L0UZAA0&amp;status=Active Die Datenschutzhinweise von LinkedIn finden Sie unter https://www. linkedin. com/legal/privacy-policy Verlinkung Social-Media über Grafik oder Textlink: Wir bewerben auf unserer Webseite auch Präsenzen auf den nachstehend aufgeführten sozialen Netzwerken. Die Einbindung erfolgt dabei über eine verlinkte Grafik des jeweiligen Netzwerks. Durch den Einsatz dieser verlinkten Grafik wird verhindert, dass es bei dem Aufruf einer Website, die über eine Social-Media-Bewerbung verfügt, automatisch zu einem Verbindungsaufbau zum jeweiligen Server des sozialen Netzwerks kommt, um eine Grafik des jeweiligen Netzwerkes selbst darzustellen. Erst durch einen Klick auf die entsprechende Grafik wird der Nutzer zu dem Dienst des jeweiligen sozialen Netzwerks weitergeleitet. Nach der Weiterleitung des Nutzers werden durch das jeweilige Netzwerk Informationen über den Nutzer erfasst. Es kann hierbei nicht ausgeschlossen werden, dass eine Verarbeitung der so erhobenen  Daten in den USA stattfindet. Dies sind zunächst Daten wie IP-Adresse, Datum, Uhrzeit und besuchte Seite. Ist der Nutzer währenddessen in seinem Benutzerkonto des jeweiligen Netzwerks eingeloggt, kann der Netzwerk-Betreiber ggf. die gesammelten Informationen des konkreten Besuchs des Nutzers dem persönlichen Account des Nutzers zuordnen. Interagiert der Nutzer über einen „Teilen“-Button des jeweiligen Netzwerks, können diese Informationen in dem persönlichen Benutzerkonto des Nutzers gespeichert und ggf. veröffentlicht werden. Will der Nutzer verhindern, dass die gesammelten Informationen unmittelbar seinem Benutzerkonto zugeordnet werden, muss er sich vor dem Anklicken der Grafik ausloggen. Zudem besteht die Möglichkeit, das jeweilige Benutzerkonto entsprechend zu konfigurieren. Folgende soziale Netzwerke werden in unsere Seite durch Verlinkung eingebunden: twitter: Twitter Inc. , 795 Folsom St. , Suite 600, San Francisco, CA 94107, USA Datenschutzerklärung: https://twitter. com/privacy Zertifizierung EU-US-Datenschutz („EU-US Privacy Shield“) https://www. privacyshield. gov/…0000TORzAAO&amp;status=Active YouTube: Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland, ein Tochterunternehmen der Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043 USA Datenschutzerklärung: https://policies. google. com/privacy Zertifizierung EU-US-Datenschutz („EU-US Privacy Shield“) https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active LinkedIn: LinkedIn Ireland Unlimited Company, Wilton Plaza, Wilton Place, Dublin 2, Irland, ein Tochterunternehmen der LinkedIn Corporation, 1000 W. Maude Avenue, Sunnyvale, CA 94085 USA. Datenschutzerklärung: https://www. linkedin. com/legal/privacy-policy Zertifizierung EU-US-Datenschutz („EU-US Privacy Shield“) https://www. privacyshield. gov/participant?id=a2zt0000000L0UZAA0&amp;status=Active „Twitter“-Social-Plug-in: In unserem Internetauftritt setzen wir das Plug-in des Social-Networks Twitter ein. Bei Twitter handelt es sich um einen Internetservice der Twitter Inc. , 795 Folsom St. , Suite 600, San Francisco, CA 94107, USA, nachfolgend nur „Twitter“ genannt. Durch die Zertifizierung nach dem EU-US-Datenschutzschild („EU-US Privacy Shield“) https://www. privacyshield. gov/participant?id=a2zt0000000TORzAAO&amp;status=Active garantiert Twitter, dass die Datenschutzvorgaben der EU auch bei der Verarbeitung von Daten in den USA eingehalten werden. Rechtsgrundlage ist Art. 6 Abs. 1 lit. f) DSGVO. Unser berechtigtes Interesse liegt in der Qualitätsverbesserung unseres Internetauftritts. Sofern das Plug-in auf einer der von Ihnen besuchten Seiten unseres Internetauftritts hinterlegt ist, lädt Ihr Internet-Browser eine Darstellung des Plug-ins von den Servern von Twitter in den USA herunter. Aus technischen Gründen ist es dabei notwendig, dass Twitter Ihre IP-Adresse verarbeitet. Daneben werden aber auch Datum und Uhrzeit des Besuchs unserer Internetseiten erfasst. Sollten Sie bei Twitter eingeloggt sein, während Sie eine unserer mit dem Plug-in versehenen Internetseite besuchen, werden die durch das Plug-in gesammelten Informationen Ihres konkreten Besuchs von Twitter erkannt. Die so gesammelten Informationen weist Twitter womöglich Ihrem dortigen persönlichen Nutzerkonto zu. Sofern Sie also bspw. den sog. „Teilen“-Button von Twitter benutzen, werden diese Informationen in Ihrem Twitter-Nutzerkonto gespeichert und ggf. über die Plattform von Twitter veröffentlicht. Wenn Sie das verhindern möchten, müssen Sie sich entweder vor dem Besuch unseres Internetauftritts bei Twitter ausloggen oder die entsprechenden Einstellungen in Ihrem Twitter-Benutzerkonto vornehmen. Weitergehende Informationen über die Erhebung und Nutzung von Daten sowie Ihre diesbezüglichen Rechte und Schutzmöglichkeiten hält Twitter in den unter https://twitter. com/privacy abrufbaren Datenschutzhinweisen bereit. Google Analytics: In unserem Internetauftritt setzen wir Google Analytics ein. Hierbei handelt es sich um einen Webanalysedienst der Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland, nachfolgend nur „Google“ genannt. Durch die Zertifizierung nach dem EU-US-Datenschutzschild („EU-US Privacy Shield“) https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active garantiert Google, dass die Datenschutzvorgaben der EU auch bei der Verarbeitung von Daten in den USA eingehalten werden. Der Dienst Google Analytics dient zur Analyse des Nutzungsverhaltens unseres Internetauftritts. Rechtsgrundlage ist Art. 6 Abs. 1 lit. f) DSGVO. Unser berechtigtes Interesse liegt in der Analyse, Optimierung und dem wirtschaftlichen Betrieb unseres Internetauftritts. Nutzungs- und nutzerbezogene Informationen, wie bspw. IP-Adresse, Ort, Zeit oder Häufigkeit des Besuchs unseres Internetauftritts, werden dabei an einen Server von Google in den USA übertragen und dort gespeichert. Allerdings nutzen wir Google Analytics mit der sog. Anonymisierungsfunktion. Durch diese Funktion kürzt Google die IP-Adresse schon innerhalb der EU bzw. des EWR. Die so erhobenen Daten werden wiederum von Google genutzt, um uns eine Auswertung über den Besuch unseres Internetauftritts sowie über die dortigen Nutzungsaktivitäten zur Verfügung zu stellen. Auch können diese Daten genutzt werden, um weitere Dienstleistungen zu erbringen, die mit der Nutzung unseres Internetauftritts und der Nutzung des Internets zusammenhängen. Google gibt an, Ihre IP-Adresse nicht mit anderen Daten zu verbinden. Zudem hält Google unter https://www. google. com/intl/de/policies/privacy/partners weitere datenschutzrechtliche Informationen für Sie bereit, so bspw. auch zu den Möglichkeiten, die Datennutzung zu unterbinden. Zudem bietet Google unter https://tools. google. com/dlpage/gaoptout?hl=de ein sog. Deaktivierungs-Add-on nebst weiteren Informationen hierzu an. Dieses Add-on lässt sich mit den gängigen Internet-Browsern installieren und bietet Ihnen weitergehende Kontrollmöglichkeit über die Daten, die Google bei Aufruf unseres Internetauftritts erfasst. Dabei teilt das Add-on dem JavaScript (ga. js) von Google Analytics mit, dass Informationen zum Besuch unseres Internetauftritts nicht an Google Analytics übermittelt werden sollen. Dies verhindert aber nicht, dass Informationen an uns oder an andere Webanalysedienste übermittelt werden. Ob und welche weiteren Webanalysedienste von uns eingesetzt werden, erfahren Sie natürlich ebenfalls in dieser Datenschutzerklärung. YouTube: In unserem Internetauftritt setzen wir YouTube ein. Hierbei handelt es sich um ein Videoportal der YouTube LLC. , 901 Cherry Ave. , 94066 San Bruno, CA, USA, nachfolgend nur „YouTube“ genannt. YouTube ist ein Tochterunternehmen der Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland, nachfolgend nur „Google“ genannt. Durch die Zertifizierung nach dem EU-US-Datenschutzschild („EU-US Privacy Shield“) https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active garantiert Google und damit auch das Tochterunternehmen YouTube, dass die Datenschutzvorgaben der EU auch bei der Verarbeitung von Daten in den USA eingehalten werden. Wir nutzen YouTube im Zusammenhang mit der Funktion „Erweiterter Datenschutzmodus“, um Ihnen Videos anzeigen zu können. Rechtsgrundlage ist Art. 6 Abs. 1 lit. f) DSGVO. Unser berechtigtes Interesse liegt in der Qualitätsverbesserung unseres Internetauftritts. Die Funktion „Erweiterter Datenschutzmodus“ bewirkt laut Angaben von YouTube, dass die nachfolgend noch näher bezeichneten Daten nur dann an den Server von YouTube übermittelt werden, wenn Sie ein Video auch tatsächlich starten. Ohne diesen „Erweiterten Datenschutz“ wird eine Verbindung zum Server von YouTube in den USA hergestellt, sobald Sie eine unserer Internetseiten, auf der ein YouTube-Video eingebettet ist, aufrufen. Diese Verbindung ist erforderlich, um das jeweilige Video auf unserer Internetseite über Ihren Internet-Browser darstellen zu können. Im Zuge dessen wird YouTube zumindest Ihre IP-Adresse, das Datum nebst Uhrzeit sowie die von Ihnen besuchte Internetseite erfassen und verarbeiten. Zudem wird eine Verbindung zu dem Werbenetzwerk „DoubleClick“ von Google hergestellt. Sollten Sie gleichzeitig bei YouTube eingeloggt sein, weist YouTube die Verbindungsinformationen Ihrem YouTube-Konto zu. Wenn Sie das verhindern möchten, müssen Sie sich entweder vor dem Besuch unseres Internetauftritts bei YouTube ausloggen oder die entsprechenden Einstellungen in Ihrem YouTube-Benutzerkonto vornehmen. Zum Zwecke der Funktionalität sowie zur Analyse des Nutzungsverhaltens speichert YouTube dauerhaft Cookies über Ihren Internet-Browser auf Ihrem Endgerät. Falls Sie mit dieser Verarbeitung nicht einverstanden sind, haben Sie die Möglichkeit, die Speicherung der Cookies durch eine Einstellung in Ihrem Internet-Browsers zu verhindern. Nähere Informationen hierzu finden Sie vorstehend unter „Cookies“. Weitergehende Informationen über die Erhebung und Nutzung von Daten sowie Ihre diesbezüglichen Rechte und Schutzmöglichkeiten hält Google in den unter https://policies. google. com/privacy abrufbaren Datenschutzhinweisen bereit. {% comment %} MailChimp - Newsletter: Wir bieten Ihnen die Möglichkeit an, sich bei uns über unseren Internetauftritt für unsere kostenlosen Newsletter anmelden zu können. Zum Newsletterversand setzen wir MailChimp, einen Dienst der The Rocket Science Group, LLC, 512 Means Street, Suite 404, Atlanta, GA 30318, USA, nachfolgend nur „The Rocket Science Group“ genannt, ein. Durch die Zertifizierung nach dem EU-US-Datenschutzschild („EU-US Privacy Shield“) https://www. privacyshield. gov/participant?id=a2zt0000000TO6hAAG&amp;status=Active garantiert The Rocket Science Group, dass die Datenschutzvorgaben der EU auch bei der Verarbeitung von Daten in den USA eingehalten werden. Zudem bietet The Rocket Science Group unter http://mailchimp. com/legal/privacy/ weitergehende Datenschutzinformationen an. Falls Sie sich zu unserem Newsletter-Versand anmelden, werden die während des Anmeldevorgangs abgefragten Daten, wie Ihre E-Mail-Adresse sowie, optional, Ihr Name nebst Anschrift, durch The Rocket Science Group verarbeitet. Zudem werden Ihre IP-Adresse sowie das Datum Ihrer Anmeldung nebst Uhrzeit gespeichert. Im Rahmen des weiteren Anmeldevorgangs wird Ihre Einwilligung in die Übersendung des Newsletters eingeholt, der Inhalt konkret beschreiben und auf diese Datenschutzerklärung verwiesen. Der anschließend über The Rocket Science Group versandte Newsletter enthält zudem einen sog. Zählpixel, auch Web Beacon genannt“. Mit Hilfe dieses Zählpixels können wir auswerten, ob und wann Sie unseren Newsletter gelesen haben und ob Sie den in dem Newsletter etwaig enthaltenen weiterführenden Links gefolgt sind. Neben weiteren technischen Daten, wie bspw. die Daten Ihres EDV-Systems und Ihre IP-Adresse, werden die dabei verarbeiteten Daten gespeichert, damit wir unser Newsletter-Angebot optimieren und auf die Wünsche der Leser eingehen können. Die Daten werden also zur Steigerung der Qualität und Attraktivität unseres Newsletter-Angebots zu steigern. Rechtsgrundlage für den Versand des Newsletters und die Analyse ist Art. 6 Abs. 1 lit. a. ) DSGVO. Die Einwilligung in den Newsletter-Versand können Sie gemäß Art. 7 Abs. 3 DSGVO jederzeit mit Wirkung für die Zukunft widerrufen. Hierzu müssen Sie uns lediglich über Ihren Widerruf in Kenntnis setzen oder den in jedem Newsletter enthaltenen Abmeldelink betätigen. {% endcomment %} Muster-Datenschutzerklärung der Anwaltskanzlei Weiß &amp; Partner "
    }, {
    "id": 7,
    "url": "https://blog.itprocloud.de/privacyEn",
    "title": "Data Privacy",
    "body": "[German version]({% link _pages/privacy-de. md %}) Privacy Policy: Personal data (usually referred to just as “data” below) will only be processed by us to the extent necessary and for the purpose of providing a functional and user-friendly website, including its contents, and the services offered there. Per Art. 4 No. 1 of Regulation (EU) 2016/679, i. e. the General Data Protection Regulation (hereinafter referred to as the “GDPR”), “processing” refers to any operation or set of operations such as collection, recording, organization, structuring, storage, adaptation, alteration, retrieval, consultation, use, disclosure by transmission, dissemination, or otherwise making available, alignment, or combination, restriction, erasure, or destruction performed on personal data, whether by automated means or not. The following privacy policy is intended to inform you in particular about the type, scope, purpose, duration, and legal basis for the processing of such data either under our own control or in conjunction with others. We also inform you below about the third-party components we use to optimize our website and improve the user experience which may result in said third parties also processing data they collect and control. Our privacy policy is structured as follows: I. Information about us as controllers of your dataII. The rights of users and data subjectsIII. Information about the data processing I. Information about us as controllers of your data: The party responsible for this website (the “controller”) for purposes of data protection law is: ITProCloud GmbHEichholzer Weg 3551519 OdenthalGermany Phone: +49 2207 8497770Mail: marcel. meurer@itprocloud. com II. The rights of users and data subjects: With regard to the data processing to be described in more detail below, users and data subjects have the right to confirmation of whether data concerning them is being processed, information about the data being processed, further information about the nature of the data processing, and copies of the data (cf. also Art. 15 GDPR);to correct or complete incorrect or incomplete data (cf. also Art. 16 GDPR);to the immediate deletion of data concerning them (cf. also Art. 17 DSGVO), or, alternatively, if further processing is necessary as stipulated in Art. 17 Para. 3 GDPR, to restrict said processing per Art. 18 GDPR;to receive copies of the data concerning them and/or provided by them and to have the same transmitted to other providers/controllers (cf. also Art. 20 GDPR);to file complaints with the supervisory authority if they believe that data concerning them is being processed by the controller in breach of data protection provisions (see also Art. 77 GDPR). In addition, the controller is obliged to inform all recipients to whom it discloses data of any such corrections, deletions, or restrictions placed on processing the same per Art. 16, 17 Para. 1, 18 GDPR. However, this obligation does not apply if such notification is impossible or involves a disproportionate effort. Nevertheless, users have a right to information about these recipients. Likewise, under Art. 21 GDPR, users and data subjects have the right to object to the controller’s future processing of their data pursuant to Art. 6 Para. 1 lit. f) GDPR. In particular, an objection to data processing for the purpose of direct advertising is permissible. III. Information about the data processing: Your data processed when using our website will be deleted or blocked as soon as the purpose for its storage ceases to apply, provided the deletion of the same is not in breach of any statutory storage obligations or unless otherwise stipulated below. Cookies: a) Session cookiesWe use cookies on our website. Cookies are small text files or other storage technologies stored on your computer by your browser. These cookies process certain specific information about you, such as your browser, location data, or IP address.   This processing makes our website more user-friendly, efficient, and secure, allowing us, for example, to display our website in different languages or to offer a shopping cart function. The legal basis for such processing is Art. 6 Para. 1 lit. b) GDPR, insofar as these cookies are used to collect data to initiate or process contractual relationships. If the processing does not serve to initiate or process a contract, our legitimate interest lies in improving the functionality of our website. The legal basis is then Art. 6 Para. 1 lit. f) GDPR. When you close your browser, these session cookies are deleted. b) Third-party cookiesIf necessary, our website may also use cookies from companies with whom we cooperate for the purpose of advertising, analyzing, or improving the features of our website. Please refer to the following information for details, in particular for the legal basis and purpose of such third-party collection and processing of data collected through cookies. c) Disabling cookiesYou can refuse the use of cookies by changing the settings on your browser. Likewise, you can use the browser to delete cookies that have already been stored. However, the steps and measures required vary, depending on the browser you use. If you have any questions, please use the help function or consult the documentation for your browser or contact its maker for support. Browser settings cannot prevent so-called flash cookies from being set. Instead, you will need to change the setting of your Flash player. The steps and measures required for this also depend on the Flash player you are using. If you have any questions, please use the help function or consult the documentation for your Flash player or contact its maker for support. If you prevent or restrict the installation of cookies, not all of the functions on our site may be fully usable. Contact: If you contact us via email or the contact form, the data you provide will be used for the purpose of processing your request. We must have this data in order to process and answer your inquiry; otherwise we will not be able to answer it in full or at all. The legal basis for this data processing is Art. 6 Para. 1 lit. b) GDPR. Your data will be deleted once we have fully answered your inquiry and there is no further legal obligation to store your data, such as if an order or contract resulted therefrom. User posts, comments, and ratings: We offer you the opportunity to post questions, answers, opinions, and ratings on our website, hereinafter referred to jointly as “posts. ” If you make use of this opportunity, we will process and publish your post, the date and time you submitted it, and any pseudonym you may have used. The legal basis for this is Art. 6 Para. 1 lit. a) GDPR. You may revoke your prior consent under Art. 7 Para. 3 GDPR with future effect. All you have to do is inform us that you are revoking your consent. In addition, we will also process your IP address and email address. The IP address is processed because we might have a legitimate interest in taking or supporting further action if your post infringes the rights of third parties and/or is otherwise unlawful. In this case, the legal basis is Art. 6 Para. 1 lit. f) GDPR. Our legitimate interest lies in any legal defense we may have to mount. Follow-up comments: If you make posts on our website, we also offer you the opportunity to subscribe to any subsequent follow-up comments made by third parties. In order to be able to inform you about these follow-up comments, we will need to process your email address. The legal basis for this is Art. 6 Para. 1 lit. a) GDPR. You may revoke your prior consent to this subscription under Art. 7 Para. 3 GDPR with future effect. All you have to do is inform us that you are revoking your consent or click on the unsubscribe link contained in each email. Twitter: We maintain an online presence on Twitter to present our company and our services and to communicate with customers/prospects. Twitter is a service provided by Twitter Inc. , 1355 Market Street, Suite 900, San Francisco, CA 94103, USA. We would like to point out that this might cause user data to be processed outside the European Union, particularly in the United States. This may increase risks for users that, for example, may make subsequent access to the user data more difficult. We also do not have access to this user data. Access is only available to Twitter. Twitter Inc. is certified under the Privacy Shield and committed to adhering to European privacy standards. https://www. privacyshield. gov/participant?id=a2zt0000000TORzAAO&amp;status=Active The privacy policy of Twitter can be found at https://twitter. com/privacy YouTube: We maintain an online presence on YouTube to present our company and our services and to communicate with customers/prospects. YouTube is a service of Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Ireland, a subsidiary of Google LLC, 1600 Amphitheater Parkway, Mountain View, CA 94043 USA. We would like to point out that this might cause user data to be processed outside the European Union, particularly in the United States. This may increase risks for users that, for example, may make subsequent access to the user data more difficult. We also do not have access to this user data. Access is only available to YouTube. Google LLC is certified under the Privacy Shield and committed to comply with European privacy standards. https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active The YouTube privacy policy can be found here: https://policies. google. com/privacy LinkedIn: We maintain an online presence on LinkedIn to present our company and our services and to communicate with customers/prospects. LinkedIn is a service of LinkedIn Ireland Unlimited Company, Wilton Plaza, Wilton Place, Dublin 2, Irland, a subsidiary of LinkedIn Corporation, 1000 W. Maude Avenue, Sunnyvale, CA 94085, USA. We would like to point out that this might cause user data to be processed outside the European Union, particularly in the United States. This may increase risks for users that, for example, may make subsequent access to the user data more difficult. We also do not have access to this user data. Access is only available to LinkedIn. LinkedIn Corporation is certified under the Privacy Shield and committed to comply with European privacy standards. https://www. privacyshield. gov/participant?id=a2zt0000000L0UZAA0&amp;status=Active The LinkedIn privacy policy can be found here: https://www. linkedin. com/legal/privacy-policy Social media links via graphics: We also integrate the following social media sites into our website. The integration takes place via a linked graphic of the respective site. The use of these graphics stored on our own servers prevents the automatic connection to the servers of these networks for their display. Only by clicking on the corresponding graphic will you be forwarded to the service of the respective social network. Once you click, that network may record information about you and your visit to our site. It cannot be ruled out that such data will be processed in the United States. Initially, this data includes such things as your IP address, the date and time of your visit, and the page visited. If you are logged into your user account on that network, however, the network operator might assign the information collected about your visit to our site to your personal account. If you interact by clicking Like, Share, etc. , this information can be stored your personal user account and possibly posted on the respective network. To prevent this, you need to log out of your social media account before clicking on the graphic. The various social media networks also offer settings that you can configure accordingly. The following social networks are integrated into our site by linked graphics: twitter: Twitter Inc. , 795 Folsom St. , Suite 600, San Francisco, CA 94107, USA Privacy Policy: https://twitter. com/privacy EU-US Privacy Shield https://www. privacyshield. gov/…0000TORzAAO&amp;status=Active YouTube: Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland, a subsidiary of Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043 USA Privacy Policy: https://policies. google. com/privacy EU-US Privacy Shield https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active LinkedIn: LinkedIn Ireland Unlimited Company, Wilton Plaza, Wilton Place, Dublin 2, Irland, a subsidiary of LinkedIn Corporation, 1000 W. Maude Avenue, Sunnyvale, CA 94085 USA. Privacy Policy: https://www. linkedin. com/legal/privacy-policy EU-US Privacy Shield https://www. privacyshield. gov/participant?id=a2zt0000000L0UZAA0&amp;status=Active Twitter plug-in: Our website uses the plug-in of the Twitter social network. The Twitter service is operated by Twitter Inc. , 795 Folsom St. , Suite 600, San Francisco, CA 94107, USA (“Twitter”). Through certification according to the EU-US Privacy Shield https://www. privacyshield. gov/participant?id=a2zt0000000TORzAAO&amp;status=Active Twitter guarantees that it will follow the EU’s data protection regulations when processing data in the United States. The legal basis is Art. 6 Para. 1 lit. f) GDPR. Our legitimate interest lies in improving the quality of our website. If the plug-in is stored on one of the pages you visit on our website, your browser will download an icon for the plug-in from Twitter’s servers in the USA. For technical reasons, it is necessary for Twitter to process your IP address. In addition, the date and time of your visit to our website will also be recorded. If you are logged in to Twitter while visiting one of our plugged-in websites, the information collected by the plug-in from your specific visit will be recognized by Twitter. The information collected may then be assigned to your personal account at Twitter. If, for example, you use the Twitter Tweet button, this information will be stored in your Twitter account and may be published on the Twitter platform. To prevent this, you must either log out of Twitter before visiting our site or make the appropriate settings in your Twitter account. Further information about the collection and use of data as well as your rights and protection options in Twitter’s privacy policy found at https://twitter. com/privacy Google Analytics: We use Google Analytics on our website. This is a web analytics service provided by Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland (hereinafter: Google). Through certification according to the EU-US Privacy Shield https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active Google guarantees that it will follow the EU’s data protection regulations when processing data in the United States. The Google Analytics service is used to analyze how our website is used. The legal basis is Art. 6 Para. 1 lit. f) GDPR. Our legitimate interest lies in the analysis, optimization, and economic operation of our site. Usage and user-related information, such as IP address, place, time, or frequency of your visits to our website will be transmitted to a Google server in the United States and stored there. However, we use Google Analytics with the so-called anonymization function, whereby Google truncates the IP address within the EU or the EEA before it is transmitted to the US. The data collected in this way is in turn used by Google to provide us with an evaluation of visits to our website and what visitors do once there. This data can also be used to provide other services related to the use of our website and of the internet in general. Google states that it will not connect your IP address to other data. In addition, Google provides further information with regard to its data protection practices at https://www. google. com/intl/de/policies/privacy/partners, including options you can exercise to prevent such use of your data. In addition, Google offers an opt-out add-on at https://tools. google. com/dlpage/gaoptout?hl=en in addition with further information. This add-on can be installed on the most popular browsers and offers you further control over the data that Google collects when you visit our website. The add-on informs Google Analytics’ JavaScript (ga. js) that no information about the website visit should be transmitted to Google Analytics. However, this does not prevent information from being transmitted to us or to other web analytics services we may use as detailed herein. YouTube: We use YouTube on our website. This is a video portal operated by YouTube LLC, 901 Cherry Ave, 94066 San Bruno, CA, USA, hereinafter referred to as “YouTube”. YouTube is a subsidiary of Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland, hereinafter referred to as “Google”. Through certification according to the EU-US Privacy Shield https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active Google and its subsidiary YouTube guarantee that they will follow the EU’s data protection regulations when processing data in the United States. We use YouTube in its advanced privacy mode to show you videos. The legal basis is Art. 6 Para. 1 lit. f) GDPR. Our legitimate interest lies in improving the quality of our website. According to YouTube, the advanced privacy mode means that the data specified below will only be transmitted to the YouTube server if you actually start a video. Without this mode, a connection to the YouTube server in the USA will be established as soon as you access any of our webpages on which a YouTube video is embedded. This connection is required in order to be able to display the respective video on our website within your browser. YouTube will record and process at a minimum your IP address, the date and time the video was displayed, as well as the website you visited. In addition, a connection to the DoubleClick advertising network of Google is established. If you are logged in to YouTube when you access our site, YouTube will assign the connection information to your YouTube account. To prevent this, you must either log out of YouTube before visiting our site or make the appropriate settings in your YouTube account. For the purpose of functionality and analysis of usage behavior, YouTube permanently stores cookies on your device via your browser. If you do not agree to this processing, you have the option of preventing the installation of cookies by making the appropriate settings in your browser. Further details can be found in the section about cookies above. Further information about the collection and use of data as well as your rights and protection options in Google’s privacy policy found at https://policies. google. com/privacy{% comment %} MailChimp - Newsletter: We offer you the opportunity to register for our free newsletter via our website. We use MailChimp, a service of The Rocket Science Group, LLC, 512 Means Street, Suite 404, Atlanta, GA 30318, USA, hereinafter referred to as “The Rocket Science Group”. Through certification according to the EU-US Privacy Shield https://www. privacyshield. gov/participant?id=a2zt0000000TO6hAAG&amp;status=Active the Rocket Science Group guarantees that it will follow the EU’s data protection regulations when processing data in the United States. In addition, the Rocket Science Group offers further information about its data protection practices at http://mailchimp. com/legal/privacy/ If you register for our free newsletter, the data requested from you for this purpose, i. e. your email address and, optionally, your name and address, will be processed by The Rocket Science Group. In addition, your IP address and the date and time of your registration will be saved. During the registration process, your consent to receive this newsletter will be obtained together with a concrete description of the type of content it will offer and reference made to this privacy policy. The newsletter then sent out by The Rocket Science Group will also contain a tracking pixel called a web beacon. This pixel helps us evaluate whether and when you have read our newsletter and whether you have clicked any links contained therein. In addition to further technical data, such as data about your computer hardware and your IP address, the data processed will be stored so that we can optimize our newsletter and respond to the wishes of our readers. The data will therefore increase the quality and attractiveness of our newsletter. The legal basis for sending the newsletter and the analysis is Art. 6 Para. 1 lit. a) GDPR. You may revoke your prior consent to receive this newsletter under Art. 7 Para. 3 GDPR with future effect. All you have to do is inform us that you are revoking your consent or click on the unsubscribe link contained in each newsletter. {% endcomment %} Model Data Protection Statement for Anwaltskanzlei Weiß &amp; Partner "
    }, {
    "id": 8,
    "url": "https://blog.itprocloud.de/tools",
    "title": "Tools & Solutions",
    "body": "{% include module. html image_path=“assets/images/WVDAdmin-01. png” title=“WVDAdmin aka AVDAdmin” description=“A free solution to manage Azure Virtual Desktop, including imaging (without destroying the template VM), deployment, running multiple scrips on VM and session hosts, moving session hosts between pools, shrinking disks, and much more. ” link=“https://blog. itprocloud. de/Windows-Virtual-Desktop-Admin/” %}{% include module. html image_path=“assets/images/Avd-Sessions-01. png” title=“Hydra for Azure Virtual Desktop” description=“Our flagship in managing AVD: Hydra, the solution to manage Azure Virtual Desktop for one or more tenants. Hydra’s web platform allows administrators to deploy new session hosts, configure an auto-adapt scaling, maintain session hosts and pools automatically, and much more. Free and licensed modes are available. ” link=“https://blog. itprocloud. de/Hydra-for-Azure-Virtual-Desktop-AVD-is-available-in-the-Azure-Marketplace/” %}{% include module. html image_path=“assets/images/ODClaenUp-00. png” title=“OneDrive Clean-Up” description=“Keep FSLogix profiles or your workstation clean from too many locally stored OneDrive files. You can define the age of files, the maximum size on the profile disk/hard disk, etc. The tool will un-pin the oldest file automatically. ” link=“https://blog. itprocloud. de/OneDrive-Clean-Up-For-Azure-Virtual-Desktop-AVD-agains-Profile-Blotting/&quot;%}{% include module. html image_path=“assets/images/CountrySwitch. png” title=“Country Switch &amp; App Starter” description=“First Logon Experience and language selector and an app starter for remote apps on network paths for AVD. ” link=“https://blog. itprocloud. de/CountrySwitch-Select-Language-on-first-start-and-an-appstarter-for-remoteapps/” %}{% include module. html image_path=“assets/images/AVD-Monitoring-Workbook-Errors. png” title=“AVD Deep Insight Workbook” description=“Get all out of the diagnostic settings to show issues in your environment, usage, available bandwidth, latencies, FSLogix usage, and much more. Additionally, you can find orphan resources, like nics, disks, VMs, and hosts, to avoid unnecessary costs. ” link=“https://blog. itprocloud. de/AVD-Azure-Virtual-Desktop-Error-Drill-Down-Workbook/” %}{% include module. html image_path=“assets/images/AVD-Client-IP-00. png” title=“Get the client IP “ description=“Install a small tool to get the client IP in the users session. ” link=“https://blog. itprocloud. de/Azure-Virtual-Desktop-Client-IP/” %} "
    }, {
    "id": 9,
    "url": "https://blog.itprocloud.de/page2/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:     {% for post in site. posts %}  {% if post. featured == true %}    {% include featuredbox. html %}  {% endif %}{% endfor %}&lt;/div&gt;{% endif %} &lt;div class=&quot;section-title&quot;&gt;  &lt;h2&gt;&lt;span&gt;All Posts&lt;/span&gt;&lt;/h2&gt;&lt;/div&gt;&lt;div class=&quot;row listrecent&quot;&gt;  {% for post in paginator. posts %}  {% include postbox. html %}  {% endfor %}&lt;/div&gt;  {% include pagination. html %}"
    }, {
    "id": 10,
    "url": "https://blog.itprocloud.de/page3/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:     {% for post in site. posts %}  {% if post. featured == true %}    {% include featuredbox. html %}  {% endif %}{% endfor %}&lt;/div&gt;{% endif %} &lt;div class=&quot;section-title&quot;&gt;  &lt;h2&gt;&lt;span&gt;All Posts&lt;/span&gt;&lt;/h2&gt;&lt;/div&gt;&lt;div class=&quot;row listrecent&quot;&gt;  {% for post in paginator. posts %}  {% include postbox. html %}  {% endfor %}&lt;/div&gt;  {% include pagination. html %}"
    }, {
    "id": 11,
    "url": "https://blog.itprocloud.de/page4/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:     {% for post in site. posts %}  {% if post. featured == true %}    {% include featuredbox. html %}  {% endif %}{% endfor %}&lt;/div&gt;{% endif %} &lt;div class=&quot;section-title&quot;&gt;  &lt;h2&gt;&lt;span&gt;All Posts&lt;/span&gt;&lt;/h2&gt;&lt;/div&gt;&lt;div class=&quot;row listrecent&quot;&gt;  {% for post in paginator. posts %}  {% include postbox. html %}  {% endfor %}&lt;/div&gt;  {% include pagination. html %}"
    }, {
    "id": 12,
    "url": "https://blog.itprocloud.de/page5/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:     {% for post in site. posts %}  {% if post. featured == true %}    {% include featuredbox. html %}  {% endif %}{% endfor %}&lt;/div&gt;{% endif %} &lt;div class=&quot;section-title&quot;&gt;  &lt;h2&gt;&lt;span&gt;All Posts&lt;/span&gt;&lt;/h2&gt;&lt;/div&gt;&lt;div class=&quot;row listrecent&quot;&gt;  {% for post in paginator. posts %}  {% include postbox. html %}  {% endfor %}&lt;/div&gt;  {% include pagination. html %}"
    }, {
    "id": 13,
    "url": "https://blog.itprocloud.de/page6/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:     {% for post in site. posts %}  {% if post. featured == true %}    {% include featuredbox. html %}  {% endif %}{% endfor %}&lt;/div&gt;{% endif %} &lt;div class=&quot;section-title&quot;&gt;  &lt;h2&gt;&lt;span&gt;All Posts&lt;/span&gt;&lt;/h2&gt;&lt;/div&gt;&lt;div class=&quot;row listrecent&quot;&gt;  {% for post in paginator. posts %}  {% include postbox. html %}  {% endfor %}&lt;/div&gt;  {% include pagination. html %}"
    }, {
    "id": 14,
    "url": "https://blog.itprocloud.de/page7/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:     {% for post in site. posts %}  {% if post. featured == true %}    {% include featuredbox. html %}  {% endif %}{% endfor %}&lt;/div&gt;{% endif %} &lt;div class=&quot;section-title&quot;&gt;  &lt;h2&gt;&lt;span&gt;All Posts&lt;/span&gt;&lt;/h2&gt;&lt;/div&gt;&lt;div class=&quot;row listrecent&quot;&gt;  {% for post in paginator. posts %}  {% include postbox. html %}  {% endfor %}&lt;/div&gt;  {% include pagination. html %}"
    }, {
    "id": 15,
    "url": "https://blog.itprocloud.de/robots.txt",
    "title": "",
    "body": "Sitemap: {{ “sitemap. xml” | absolute_url }} "
    }, {
    "id": 16,
    "url": "https://blog.itprocloud.de/Install-The-New-Teams-Client-On-AVD/",
    "title": "Install the New Teams Client on Azure Virtual Desktop (preview) - AVD",
    "body": "2023/10/29 - Microsoft made the New Teams client available for VDIs (preview): The new client is based on a different technology than the classic client and should require fewer resources, which is especially important for Azure Virtual Desktop from a cost perspective. Microsoft has documented the installation here: Link I have created a small PowerShell script to automate the complete installation. The script also installs WebView2 and makes the settings for sideloading and AVD. I use the script in WVDAdmin and Hydra for Azure Virtual Desktop to install the new team client on hosts without sessions or directly on the master. The script can also be run directly in administrator mode interactively, Intune, API, etc. After the installation, the new Teams client is visible in the start menu. In addition, the team’s administrator can configure whether the new team’s client is proposed. Important: In line 4, set the value for $acceptEula to $true if you agree to Microsoft’s EULA. Please make sure that the path “%UserProfile%\AppData\Local\Packages\MSTeams_8wekyb3d8bbwe\LocalCache\Microsoft\MSTeams” is not excluded from the FSlogix profile by the Redirections. xml. # Set $acceptEula to $true to accepp the eula:# Eula for Webview2: https://developer. microsoft. com/en-us/microsoft-edge/webview2/#download-section$acceptEula=$false if ($acceptEula -eq $false) {throw &quot;Accept the EULA first&quot;} Set IsWVDEnvironment to 1New-Item -Path &quot;HKLM:\SOFTWARE\Microsoft&quot; -Name &quot;Teams&quot; -Force -ErrorAction IgnoreNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\Microsoft\Teams&quot; -Name &quot;IsWVDEnvironment&quot; -Value 1 -force Allow side-loading for trusted appsNew-Item -Path &quot;HKLM:\Software\Policies\Microsoft\Windows&quot; -Name &quot;Appx&quot; -Force -ErrorAction IgnoreNew-ItemProperty -Path &quot;HKLM:\Software\Policies\Microsoft\Windows\Appx&quot; -Name &quot;AllowAllTrustedApps&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\Software\Policies\Microsoft\Windows\Appx&quot; -Name &quot;AllowDevelopmentWithoutDevLicense&quot; -Value 1 -force Download and install WebView2(New-Object System. Net. WebClient). DownloadFile(&quot;https://go. microsoft. com/fwlink/p/?LinkId=2124703&quot;, &quot;$($env:temp)\WebView2. exe&quot;)Start-Process -FilePath &quot;$($env:temp)\WebView2. exe&quot; -Wait -ArgumentList &quot;/silent /install&quot; -ErrorAction SilentlyContinue Download and install the New Teams(New-Object System. Net. WebClient). DownloadFile(&quot;https://go. microsoft. com/fwlink/?linkid=2243204&quot;, &quot;$($env:temp)\TeamsBootstrapper. exe&quot;)$rv=Start-Process -FilePath &quot;$($env:temp)\TeamsBootstrapper. exe&quot; -Wait -ArgumentList &quot;-p&quot; -PassThru -ErrorAction SilentlyContinue$rv. ExitCode You can also add the script as a custom script in WVDAdmin or in Hydra: "
    }, {
    "id": 17,
    "url": "https://blog.itprocloud.de/Azure-Virtual-Desktop-Client-IP/",
    "title": "How to get the Client IP Address in Azure Virtual Desktop",
    "body": "2023/10/23 - While migrating Virtual Desktop Environments to AVD, I got another challenge from the past: Sometimes, companies use the client IP address to identify the user’s location to map a specific printer in the location. Unfortunately, AVD didn’t provide this client’s IP address. Even the property of WTSQuerySessionInformation is empty. I only get the internet-faced IP address if I try to use the diagnostic settings. But not the client’s own address. But there is a solution/workaround: If clients are using RDP Shortpath (public or private), we can grab the information locally to do some printer mappings. The good thing is that RDP Shortpath is enabled by default (except for the HTML 5 web client). The RDAgent, installed on each session host, reports a lot of data to the backend (logs). You can configure the diagnostic settings to store this data to log analytics or some other data stores. Some of those logs are also on the session host in the event log. The event log “RemoteDesktopServices” contains the log entries. The source “Microsoft. RDInfra. Diagnostics. DataSink. RestPipelineSink” contains data about RDP Shortpath connection, including the IP address of the client: We can use the activity ID to match the information to a specific user on the host. The correlation user/activity ID is stored in the log from the source “Microsoft. RDInfra. RDAgent. ConnectionTrackingService. DefaultConnectionTrackingService”. I built a small tool to read the event log continuously. AvdClientIp reads the single entries, extracts the data, and matches the data by the activity ID. Result: The installation of AvdClientIp will create a scheduled task with the name “ITPC-AVD-ClientIP”. This task starts with the computer and monitors the RemoteDesktopServices event log. If a client IP is detected, the tool writes the client IP into the users’ registry in HKEY_CURRENT_USER\Volatile Environment ClientIpValue		-&gt; IPv4ClientIpUTC		-&gt; The timestamp Logging and configuration: The default configuration can be changed by setting the following values to the registry HKLM:\SOFTWARE\ITProCloud\AvdClientIp KeyTypeValueDefault valueHideUserNamesInLogfileReg_DWORDHides the user names in the logfile0=falseLoggingReg_DWORDEnbale logging1=trueAvdClientIp writes a log file to *%AppData%\ITProCloud\AvdClientIp. log. *Note: It would be much better if the RDAgent would store this information directly in the registry or provide the information with the WTSQuerySessionInformation. So, use this tool as a workaround until we get the data natively. Note: It would be much better if the RDAgent would store this information directly in the registry or provide the information with the WTSQuerySessionInformation. So, use this tool as a workaround until we get the data natively. Kudos: A big thank to Jörg Hoffmann finding the right logs 👍 Download: Download the latest release from 10/23/2023 Please feel free to send me ideas for improvements. "
    }, {
    "id": 18,
    "url": "https://blog.itprocloud.de/OneDrive-Clean-Up-For-Azure-Virtual-Desktop-AVD-agains-Profile-Blotting-Copy/",
    "title": "OneDrive Clean-Up for Azure Virtual Desktop",
    "body": "2023/10/17 - Running OneDrive with Azure Virtual Desktop is a common scenario and enables users to work in a modern way with Teams and SharePoint. If FSLogix is used, there is a challenge in combination with OneDrive: Users can download OneDrive files to the host, and the data are stored in the profile. The profile size increases heavily and causes some extra costs on the storage account. Having so many OneDrive files stored in the profile may make no sense in every case - if a user access a file, the file is downloaded automatically (on demand). And it’s mostly fine to “unpin” the file later if the file is no longer needed. The files are downloaded fast, while AVD and OneDrive are in the Microsoft cloud. Background:: OneDrive files can have three different states: Cloud:The file content is in the cloud only. The file system simulates that the file exists. While the content is not on the disk, the files don’t need storage on the device. If a user opens such a file, the content is downloaded, and the file state change to On-Device. On-Device:The file content is also on the local disk, and the files are using local storage. Always:The file content is also on the local disk, and the files are using local storage. OneDrive wouldn’t change the state to “Cloud”. OneDrive can change the state to “Cloud” on normal Windows 10/11 devices using storage sense. Based on the implementation of storage sense, this is not working for Azure Virtual Desktop (Multi-Session) with FSLogix profiles. A solution to avoid profile blotting in combination with FSLogix is changing the state of OneDrive files to “Cloud” (unpin files). If files are unpinned, they are no longer using local storage, and the “Disk Compaction” of FSLogix would reduce the profile automatically over time (or have more space left for user data). I built a small tool to solve this challenge (I didn’t find a native solution). The tool is called OneDrive CleanUp. OneDrive CleanUp can run in two ways: Started automatically with the login of the user (after the installation, it creates a link in the start-up folder of the start menu). It directly starts in the background and validates and maybe unpin OneDrive files. This process is repeated every 30 minutes and during the logoff of the user. Start the program with the parameter /RunOnce during the logoff using a (group) policy. I prefer the first method to ensure that OneDrive has time to react to the unpinning of files. Example for method 2: Result: In my test, my profile grew to 8 GByte while I pinned some files in OneDrive, and after logoff, the profile went back to 800 MByte while the tool unpinned the OneDrive files. Logging and configuration: The default configuration can be changed by setting the following values to the registry HKLM:\SOFTWARE\ITProCloud\OneDriveCleanUp KeyTypeValueDefault valueEnabledReg_DWORDIf false, the application will not check the files1=trueRunEachMinutesReg_DWORDCheck OneDrive files each minutes30AlwaysUnpinFilesOlderThenDaysReg_DWORDUnpin files older then days (0: disabled )0AllowMbytesOnDiskReg_DWORDAllow the configured value in MByte on the local disk5120IgnoreFilesContainingReg_SZString with separated values (;). If the path of a file contains one of the values, the file is ignoredEmptyOneDrive CleanUp writes a log file to %AppData%\ITProCloud\OneDriveCleanUp. log. Example: How does it work: OneDrive CleanUp regularly checks all OneDrive paths and calculates the size of the disk. If the size is larger than the configured maximum size (AllowMbytesOnDisk), it unpins files to go under the configured size. It starts from the oldest to the newest file based on the LastAccessTime property. Release notes: ReleaseDateChanges &amp; Notes1. 0. 42023-05-04Initial1. 0. 52023-07-13Fix: Files larger than 2 GByte were counted wrong1. 0. 62023-10-17Fix: Files larger than 4 GByte were counted wrongDownload: Download the latest release from 10/17/2023 Please feel free to send me ideas for improvements. "
    }, {
    "id": 19,
    "url": "https://blog.itprocloud.de/Windows-Virtual-Desktop-Admin/",
    "title": "WVDAdmin - A native administration Gui for Azure Virtual Desktop (AVD) / Windows Virtual Desktop (WVD)",
    "body": "2023/10/13 - Azure Windows Virtual Desktop administration with WVDAdminAzure (Windows) Virtual Desktop is generally available under continuous improvement and currently available in the ARM and in the Classic (Fall) version. The ARM version is completely into the Azure Portal.  Sometimes it helps to have a native GUI to make some configuration and - for me, most important - to have an easy image handling to deploy session hosts based on a template VM (golden image approach). Therefore I build a native Windows application to do this, and I’m happy to share it with the community. Are you interested in the new “Hydra for Azure Virtual Desktop” solution to manage AVD even better with a lot of automation? Check it out here.  Download the latest release from 10/13/2023 Check out the Youtube video to install and configure WVDAdmin in four steps The current version supports a lot of configuration and administration capabilities, and I’m continuously improving WVDAdmin. Some features: ImagingCreate images from golden masters (without destroying the master)Handle sysprep and modern appClean-upUse of shared image gallery definitionsRolloutRollout of multiple session hostsStore some base settings encrypted for reuse (domain join name, password, …)Select VM type for each rollout (is not fixed to the host pool)Use of ephemeral disksSupport of a second partition from the master VM (D:)Azure MonitorAAD only, join to MEM/intuneAVD SupportClassic AVDARM AVD (Spring Update)Migration of resources and session hostsWorking with AVD resourcesAdd/create/deleteHost PoolsApplication groupsWorkspacesSession hostsWorking with user sessionsDisconnectLogoffSend messageShadowSession hostsMove between host poolsStart/Stop/RestartDelete - with VM, disk, and nicGet error report from AVD agentRun scripts remotely on hosts (trigger Windows updates, enable RDP Shortpath, …)Change drain-modeChange disk type, e. g. : on-start -&gt; to Premium, after deallocation -&gt; to HDD(for cost savings)Remove user assignmentVirtual machineList all VMs with power state in all subscriptionsStart/Stop/RestartRun scripts remotely on hosts (trigger Windows updates, enable RDP Shortpath, …)Shrink disk to 64 or 32 GByte (to create small images for ephemeral hosts)Change disk type, e. g. : on-start -&gt; to premium, after deallocation -&gt; to HDD (for cost savings)Create and restore snapshots with a clickAdd an existing domain-joined VM as a session hostOthersMulti-Tenant switchSplit-Tenant modeSearch for unused disks and nicsRollout VM Scale SetsStart and deallocate Scale Set instancesRe-image Scale Set instancesRemove customer-managed key (CMK)…InstallationRelease History: Download the latest release from 10/13/2023Check out the Youtube video to install and configure WVDAdmin in four steps I'm continuously updating WVDAdmin to make it easier to administrate and deploy WVD, users, and session hosts. Click to see the change history. ReleaseDateChanges &amp; Notes1. 8. 05. 02023-10-13Add: Support for different VM sizes (Bas_v2, Bls_v2, Bats_v2, etc. ); Update of the imaging script1. 8. 01. 02023-09-19Add: Support to capture trusted launch VMs directly into an Azure Compute Gallery; More reliable rollout of session hosts working around some of the AVD-agent issues1. 7. 63. 02023-07-09Fix: Update of the installation script to install WinGet/Microsoft Package Manager applications1. 7. 62. 02023-06-28Add: New deployed hosts: In the first minutes, the correct start of the BootloaderAgent is monitored (if the service is not running, the service will be started)1. 7. 61. 02023-06-19Add: Modification to keep settings through Intune in the template1. 7. 60. 02023-06-07Fix: In some cases a remote app icon crashed the application1. 7. 59. 02023-05-06Add: Custom scirpt extension can ask for a parameter (see CustomScript-WithParameterString. ps1)1. 7. 58. 02023-04-07Add: Ressetting the SCCM/MECM configuration during imaging; speed-up imaging for Windows 11 22H21. 7. 57. 02023-04-03Fix: A DLL was missing to read the Winget data (current packages)1. 7. 56. 02023-03-25Add: Update the imaging script to be even more resilient to sysprep issues. Sysprep is now monitored, and some workarounds for sysprep are triggered automatically in case of a sysprep error1. 7. 55. 0Fix: Deployment tags with an empty value are now set1. 7. 54. 0Add: If a larger disk size is used as the image: the last partition will be automatically extend; Add: Gallery images for Windows 10 22H21. 7. 52. 0Add: Better handling for AAD only joined VM1. 7. 51. 0Add: Support for Central India as meta-data location1. 7. 50. 0Add: Workaround to image Windows 11 22H2 (there is a bug in the sysprep process)1. 7. 49. 0Add: Secure boot enabled hosts are now supporting ‘Guest Attestation’ (automatically installed)1. 7. 48. 0Fix: Support for Azure Disk Encryption fixed (ADE); Change to the PowerShell script: Avoiding a sysprep issue with the desired state configuration1. 7. 47. 0Fix: GUI, overlapping checkbox for use newes agent and secure boot1. 7. 46. 0Add: Additional Galley images; Add: Download newest AVD agent during the rollout (instead of using the agent stored in the image)1. 7. 45. 0Fix: Galley images are only shown if a custom image exist1. 7. 44. 0Add: Australia East as meta-data location1. 7. 43. 0Add: Support for FX-series VM size1. 7. 42. 0Add: You can filter on the ‘Virtual Machines’ by the string ‘!orphanhosts’. That shows all VMs created by WVDAdmin or Hydra as a session host but currently not part of any seen host pool (used internally the tags WVD. Path or AVD. Path); Change: Modify WVD. Path/AVD. Path in another way while moving a session host to another host pool1. 7. 41. 0Add: Japan East as meta-data location1. 7. 40. 0Fix: Move host pool: The user assignment was not always kept;1. 7. 39. 0Add: You can enable “Secure Boot” for marketplace images and for Custom Images in an Azure Compute Gallery (configure the VM image definition to support Secure Boot before copying a captured image to the gallery definition)1. 7. 38. 0Add: Deploy Azure market place images; Add: Show assigned users in the session hosts tab1. 7. 37. 0Add: Adding VM Size: NCasT4_v3-series; Add: All new created VMs are flagged to delete nic and disk if the VM is deleted in the Azure Portal1. 7. 35. 0Add: NoTags-mode. Prevents WVDAdmin to set the default tags on new session hosts, scale sets and images. Set HKEY_CURRENT_USER\Software\ITProCloud\WVDAdmin\NoTags to 1 (NoTags is REG_DWORD32)1. 7. 34. 0Add: Having custom script for imaging and deployment based on the tenant friendly name if running in the multi-AAD-tenancy mode Follow this link1. 7. 33. 0Add: Dark-mode. Set HKEY_CURRENT_USER\Software\ITProCloud\WVDAdmin\DarkMode to 1 (DarkMode is REG_DWORD32)1. 7. 32. 0Fix: Using AAD-only expected the unnecessary field domain FQDN and the rollout button was greyed out in some situations1. 7. 31. 0Add: Support for NVadsA10v5 VM types1. 7. 30. 0Add: You can now deploy a host in a named availability zone (normally, the zone is (optional) automatically calculate to spread hosts around different zones1. 7. 29. 0Add: WVDAdmin stores the last rollout configuration and now (that is new), the last image, host pool, VM-size, storage type, etc. 1. 7. 28. 0Fix: Gettting the diagnostic setting on a host pool changed (updated API)1. 7. 25. 0Change: Configure diagnostic settings now enables all logs1. 7. 24. 0Add: You can directly re-assign a user to a VDI session host or delete an assignment (on the session host tab change or delete the user asssignment)1. 7. 23. 0Add: A new tab shows the name of the current background processes (Jobs)1. 7. 22. 0Fix: In some cases a VM-Scale-Set Instances where not shown and crashes the application1. 7. 21. 0Fix: VM Scale Set rollout issue1. 7. 20. 0Experimental support for building session hosts based on a secure boot Golden Master1. 7. 19. 0Add: VM sizes for D and E series V51. 7. 18. 0Add: Change the VM size for multiple VMs (Azure -&gt; Virtual Machines); New images are created with tags including the timestamp and resource ID of the master VM1. 7. 17. 0Change: The API permission for Azure AD Graph is no longer needed for the service principal if you are using WVDAdmin for AVD (spring edition)1. 7. 16. 0Add: Session host rollout will set an additional tag to VM, Nic and Disk: WVD. Host=1. 7. 15. 0Fix: If you deallocate a VM without tags, the VM is deallocate but an error message is/was shown (Changing power state of Azure vm was not successful Object reference not set to an instance of an object. )1. 7. 14. 0Change: Uninstallation of th RDAgent (if you capture a session host is now faster)1. 7. 13. 0Add: Join MEM/Intune while rolling out session hosts; Add: Function to shrink a disk of a VM to 32 GByte to rollout cheaper instances and/or use smaller instances with ephemeral disks1. 7. 11. 0Add: Optimization to capture a session host for a new image1. 7. 09. 0Change: Change the rollout process to be more reliable if you deploy a lot of hosts at once; Fix: Secrets can now have special characters1. 7. 05. 0Fix: The windows can now be resized to full-screen1. 7. 01. 0Add: Support to show subscription name in rollout and imaging tab (set HKEY_CURRENT_USER\SOFTWARE\ITProCloud\WVDAdmin\ShowSubscriptionName to (reg-dword))1. 7. 00. 0Add: Support to deploy AAD-only session hosts; Fix: Resize of V2 VM disks1. 6. 99. 0Add: Meta-data location for Canada and the UK1. 6. 98. 0Fix: Resize the application window height in case you have a smaller resolution (&lt;828 px)1. 6. 97. 0Add: Remove a Customer Managed Key (CMK) from a VM / Disk1. 6. 96. 0Add: Support for the Edv4- and Edsv4-Serie1. 6. 95. 0Add: You can now use CTRL+C in each table to copy the content of the selected column1. 6. 94. 0Fix: An import of the registry settings failed if the windows decryption key is other than the user who exported the settings1. 6. 92. 0Fix: A session host could be visible in the session host tab of anonter hostpool if the resource id of the host pools starts with the same string1. 6. 91. 0Add: Create and restore snapshots of a VM (right click the VM in the Azure node)1. 6. 90. 0Add: Function to shrink a disk of a VM to 64 GByte to rollout cheaper instances and/or use smaller instances with ephemeral disks1. 6. 89. 0Add: Workaround to fix an issue in the Azure API querying VM. In subscriptions with a lot of VMs an error message could given back from the API which will be workaround with this version. Original error message from Azure: Resource provider ‘Microsoft. Compute’ failed to return collection response for type ‘virtualMachines’1. 6. 88. 0Add: Option to rollout virtual machines based on an image without joining to WVD/AVD (for servers, new golden masters, …), Update: Newest PowerShell script for generalizing and deployment to 3. 0: ITPC-WVD-Image-Processing. ps11. 6. 87. 0Add: Option to switch on “Power on connect” for pooled (and assigned) host pools (preview feature)1. 6. 86. 0Add: Option to directly roll-out new session hosts with actice Azure Disk Encryption (ADE) - See “secret features” below1. 6. 83. 0Fix: Update of ITPC-WVD-Image-Processing. ps1 - if you run it from a share with prepared MSIs, the MSIs are ignored and downloaded directly from Microsoft1. 6. 82. 0Add: Script to enable screen capture protection per session host1. 6. 81. 0Add: Localized time for the session list (WVD classic)1. 6. 80. 0Add: Message box before logging users off1. 6. 79. 0Add: VM list in the “Virtual Machines” node are now showing the private IP1. 6. 77. 0Add: Official support for meta-data regions: West Europe and North Europe1. 6. 76. 0Fix: New applications failed to create in an existing application group1. 6. 75. 0Fix: In some cases session hosts are not displayed in the session hosts node (no matching resource id - upper-case / lower-case issue)1. 6. 73. 0Add: Automatically change the disk type on start/stop: Add a tag “WVD. AdvDiskType” to a VM with the value “StandardSSD_LRS” or “Premium_LRS”. On the stop, the disk is converted to HDD (lowes costs), and on start, the disk is converted to the named type.  Works only with WVDAdmin (not from the Azure Portal or scaling solutions)1. 6. 72. 0Add: Fix for a sysprep failure (Sysprep data was marked corrupt; cannot proceed) in the ITPC-WVD-Image-Processing. ps1 script; Add: Better handling for shutdown/start/delete VM tasks in the Virtual Machines node1. 6. 71. 0Add: The disk size for new session hosts can be selected (optional) to have a higher IOPS performance1. 6. 70. 0Add: For preview only: Checkbox to enable upcoming “Start on connect feature”1. 6. 69. 0Fix: Open files are not shown if different storage accounts in different subscriptions are used under some circumstances1. 6. 68. 0Add: West Europe as metadata location (can only be used if the subscription is in an appropriate preview program); Add: Some scroll bars to list boxes1. 6. 66. 0Fix: Rollout from session hosts based on a share image gallery item failed in another subscription then the subscription containing the gallery image1. 6. 65. 0Add: Security query before hosts are started, stopped or restarted1. 6. 64. 0Add: Install session host optionally with Azure Monitor Extension or sepago Azure Monitor (for Azure Monitor Extension: Make sure that you have configured the target host pool correctly once: Right-click -&gt; Configure Diagnostic settings)1. 6. 62. 0Add: You can now terminate file handles to an Azure Storage (orphaned handles avoiding a user to log in with its FSLogix profile) - Service Principal needs contributor permissions to the storage account1. 6. 61. 0Add: VC++ runtime if you use the destkop installer1. 6. 60. 0Add: Manage your Virtual Machines like session hosts: Click on Azure - Virtual Machines to list all VMs in your subscriptions (note: data for the VMs are are delayed (resource graph))1. 6. 59. 0Change: Rollback of advanced logging of create VM / create Image Powershell script: Shows unimportand messages as an error with existing images1. 6. 57. 0Add: You can enable diagnostic settings directly on a host pool, appgroup and workspace (right-click); Fix: Sometimes reading the state of a script extension is not directly possible. This cause that the WVDAdmin log shows an error even if everything works as expected1. 6. 56. 0Change: Single session nodes are not listed under the session host node if more then 100 sessions exist to speed up WVDAdmin - all sessions are still in the session list1. 6. 54. 0Add: Function to delete unused disks and nics; Add: More logging for the rollout of session hosts; Add: New VM-types, like L4s_v2, …1. 6. 53. 0Add: Add session hosts automatically to Loadbalancer Backend Pools; Add: If a VM resource is unavailable, the first alternative VM size will be tried1. 6. 51. 0Add: Custom script to install Azure Monitor for WVD from sepago to existing session hosts1. 6. 50. 0Add: Support for Dhsv31. 6. 46. 0Add: You can now rollout new session hosts with accelerated network configuration, Change: NICs are now created with the name of the VM1. 6. 45. 0Add: Add session hosts automatically to ASGs1. 6. 42. 0Add: Support for Dasv4-series1. 6. 41. 0Add: Experimental feature: Add applications to session hosts from Windows Package Manager repository1. 6. 40. 0Change: Having a script-path for building images is no longer needed. If you leave the text box empty, the local script coming with WVDAdmin will be used and directly send to the VM1. 6. 35. 0Add: On a session host &gt; State &gt; Mouse over will show the health report of the host1. 6. 34. 0Fix: The drop-down list “Feature release” was not shown correctly. Feature release is the selector between the different WVD/AVD versions like Fall (WVD classic) and Spring (WVD modern on ARM)1. 6. 32. 0Add: You can run scripts on multiple classic session hosts: Win Updates: Install new available updates; Custom script: Custom script located in the program files folder of WVDAdmin1. 6. 30. 0Add: Sorting order for WVD/AVD resources1. 6. 29. 0Add: Support for Eav4 and Easv4-series1. 6. 28. 0Add: Speed up adding a lot of VMs to the treeview1. 6. 27. 0Add: Support for using availability zones. Select it from the drop-down list right to the resource group list1. 6. 26. 0Add: You can run scripts on multiple ARM session hosts: Win Updates: Install new available updates; Custom script: Custom script located in the program files folder of WVDAdmin1. 6. 24. 0Add: Multi selection and action on session hosts for ARM if you select a session host container; Fix: Scale Set instances wasn’t shown in 1. 6. 231. 6. 23. 0Fix: New image was not visualized in the tree view after creation1. 6. 22. 0Add: Support for shared image galleries: Add a shared image gallery from the Azure Portal into a resource group managed by WVDAdmin. In WVDAdmin right-click an existing image and select “copy to shared image gallery”. An image can be rolled-out right clicking the shared image1. 6. 21. 0Add: Double-click on the tag Logs, Sessions or Sessions V2 enlarge the part of the windows (double-click again to revert)1. 6. 18. 0Fix: API change from Microsoft cause that updating a host pool property fails if the location is written like “Central US” (centralus is no problem); Add: First version able to deploy session hosts from images in a image gallery1. 6. 16. 0Add: Session hosts icons are now based on the availability state; Fix: Enumerating thousands of sessions with thousands of session hosts takes longer as expected (&gt; 4 minutes)1. 6. 14. 0Add: Support US Government Cloud. Activate: Add a new string Reg_SZ “Environment” with value “US” to HKCU\SOFTWARE\ITProCloud\WVDAdmin”1. 6. 12. 0Add: Support for VM types: Dv4 and Dsv4-series, Ev4 and Esv4-series1. 6. 11. 0Fix: WVD/AVD ARM resources are deployed with the tags; Workspaces and host pools are separated by subscription name1. 6. 9. 00Fix: Generating toke for Spring host pool fails sometimes (Error: ExpirationTime value must be between one hour and 30 days from now” - An error occurred while gathering an WVD2 token from backend: Object reference not set to an instance of an object. )1. 6. 5. 00Add: Support for DD_v2 and DDS_V4 virtual machine types; Fix: Forwarding from the WVD/AVD API cause a authentication lost (error 401, 403 reading resources in the FALL update)1. 6. 4. 00Add: Support for GEN2 virtual machines1. 6. 2. 00Add: New naming feature for new session host. Default (is): Name for a session host is the highest matching name +1; new concept (must be enabled): Name for a session host is the next free name. To enable add a reg dword to HKCU\Software\ITProCloud\WVDAdmin Name:NamingMode and value to “1”1. 6. 1. 00Fix: Default session limit for V2 host pool is now 9999991. 6. 0. 00Change: The tag WVD. Path is aligned to Microsoft naming of “tenant” and “host pool” for the spring update. Tenant=resource group name and no longer subscription name1. 5. 9. 00Add: Load assigned users button to the app group tab (fall update)1. 5. 7. 00Add: You can join existing VM’ to a host pool (VMs must be domain joined and not in a host pool right now)1. 5. 6. 00Add: You can now move session host around host pools not created with WVDAdmin (it downloads the necessary files automatically); you can join existing VM’ to a host pool (VMs must be domain joined)1. 5. 5. 00Fix: Enumerating VMs was endless in some circumstance1. 5. 4. 00Add: Migration from Fall to Spring Update; moving session hosts to another host pool1. 5. 3. 00Fix: Improvement updating the treeview1. 5. 0. 00Add: Supporting the WVD Spring Release / Spring Update ; Some user operations from the session grid are now async; Fix: Spontaneous resize of the windows if data are reloaded1. 4. 9. 00Add: Filter users, session hosts and host pools in the overview of sessions1. 4. 8. 00Add: Support to add users by groups from Azure Active Directory, including an AAD browser (check my blog post and configure the service principal to use this feature)1. 4. 6. 00Add: New VM sizes; all new scale sets are deployed as really scalable version (up to 600 instances each)1. 4. 4. 00Fix: Service Principal Keys with some special characters are working now; Add: Faster loading of resources from WVD/AVD and Azure backend1. 4. 2. 00Add: Support for NVv4 VM sizes (based on AMD Radeon Instinct MI25-GPU); support to set custom Azure tags for resources while deploying resources1. 4. 0. 00Fix: From an older version, disks are deployed as standard-hdd even if premium-disk was selected; Change: Connection views are now located parallel to the logging list on the bottom (tenant-view); Add: Function to check for an updated version via https://blog. itprocloud. de/assets/files/WVDAdmin. xml1. 3. 6. 00Add: New tag for session hosts: WVD. Path - used by Azure Monitor for WVD and Azure Autoscale for WVD - aka Project MySmartScale if an installed language pack conflicts with the Microsoft RDAgent (read this post to learn more)1. 3. 5. 00Add: Allow an local admin to shadow a user session (WVDAdmin needs direct access to the session host via RDP)1. 3. 4. 00Add: Networks are now listed as VNET/SUBNET in the rollout tab1. 3. 3. 00Add: Support for a special mode if your WVD/AVD tenant and the session hosts in two different Azure Active Directory tenants1. 3. 1. 00Fix: WVDAdmin crashed if 1. 3. 0 is your first version of WVDAdmin (HKEY_CURRENT_USER\Software\ITProCloud doesn’t exist while checking for multi-tenancy mode)1. 3. 0. 00Add: AAD multi-tenancy mode (drop down list to handle different AADs) - https://blog. itprocloud. de/Windows-Virtual-Desktop-Windows-Virtual-Desktop-Administration-for-CSP-and-Consulting-Partners1. 2. 8. 00Add: If you click a tenant a tenant wide list of sessions is listed.  Logoff or send messages to multiple sessions1. 2. 7. 00Add: The main window of the application is now resizeable1. 2. 5. 00Add: Support for Scale Sets (with normal and ephemeral disks) -&gt; see below1. 2. 4. 00Add: Support for availability sets1. 2. 3. 00Add: Support for automatic and static assigned host pools1. 2. 1. 00Fix: Logging of rollout parameter by Azure custom extension is removed to avoid logging secrets1. 0. 0. 30Fix: Rollout - OU can now be empty to join the default OU1. 0. 0. 29Add: Supporting “special license mode” to save up to 50% on compute-cost (https://docs. microsoft. com/en-us/azure/virtual-desktop/apply-windows-license)1. 0. 0. 26Add: Template VM can now be a VM with a standard disk (non-managed)1. 0. 0. 25Fix: If you delete a VM the OS disk will deleted as well1. 0. 0. 23Support for ephemeral disks1. 0. 0. 22First published version - without auto-update of WVDAdminConfiguration: Service principal (functional account): To work with the GUI, you need a service principal (function account) with permission to administrate access to the AVD and Azure resources. I decide to use a service principal to avoid confusion if my Azure AD user is only a guest account in the AVD tenant I have to administrate and easily switch between different tenants. To create a service principal, go to your Azure AD -&gt; App registration -&gt; New registration and type a name for your principal like “ svc_WVDAdmin” and press “register”.  Click on “certificates &amp; secrets”. Click “new client secret”, select a validity period and a description (like “Key01”). Press “add”.  Copy the generated key directly - it will never be displayed again. Note the key for later.  To assign users to app groups, the service principal needs one API permissions to get the users and groups from Azure AD (optional): Add the permission “Microsoft Graph” -&gt; Application Permission -&gt; Directory. Read. All To consent, the permission and administrator of Azure AD have to grant this: Go to “Overview”. Note the “Application (client) ID” and the “Directory (tenant) ID” as well.  You now have all data for your service principal: Tenant idService principal id (application id)Service principal keyAVD permissions: This chapter is for AVD ARM / Spring. Skip this chapter if you only work with WVD Classic (Fall). The service principal needs permission to add and modify AVD resource objects (host pools, workspaces, app groups). To assign users and groups to app groups, the service principal needs the owner role on the resource groups you want to use for your AVD environment. Add the service principal in the next step and use the owner role. Register Resource Provider: If you have never worked with AVD, you have to register the AVD resource provider once. To do that, go to the Azure portal -&gt; subscriptions -&gt; select your subscription -&gt; Resource providers Search for “Microsoft. DesktopVirtualization” and click on “Register”. Azure resource permissions: The service principal needs permission to subscriptions or resource groups to manage your AVD resources, imaging template VM and rollout session hosts. Open the Azure portal and go to the resource groups you want to use or to the subscriptions. In each resource group/subscription, click “Access control (IAM)” -&gt; select “Add” -&gt; Add role assignment. Select “owner” and search in “Select” for your service principal name. Click on the principal and save the settings. Note: Owner is needed to assign users to app groups. For other resources, “contributor” is fine.  The service principal must have permissions to your virtual network (vnet) to assign new VMs to the right subnet. Go to your vnet, click “Access control (IAM)” -&gt; select “Add” -&gt; Add role assignment. Select “contributor” and search in “select” for your service principal name. Click the principal and save the settings. You could skip this step if you assigned the service principal to the subscription or to the resource group containing your vnet.  Prepare your “native” Active Directory: Today each session host must be part of a “native” active directory domain (or have to use the domain services). To add new session hosts unattended, we need an administrative user account to add a computer object to the active directory domain. You can use an existing one, or you can create a new service user: Open “Active Directory Users and Computers” and create a user object with a complex password, and set a password to “never expire” (if you fine with this). I added the user srv_WVD-Join@itprocloud. de. Delegate permission for the user to an OU. I found a really good blog post from Prajwal Desai. Check out hist post on (external web site): Method 2 – Delegate rights to user/group using Active Directory Users and Computers In my case I added my function account to: “OU=WVD,OU=Azure,OU=Site,OU=Servers,OU=Sys,OU=Organisation,DC=ITProCloud,DC=test” Optional: Create a file share: In earlier versions (&lt;1. 6. 40), you had to provide the deployment script and the AVD agent binaries on a custom file share or blob storage. With WVDAdmin 1. 6. 40 or newer, this no longer mandatory. In some cases, where virtual machines don’t have access to the internet to download the AVD agent binaries, you can use a custom file share. Read more. Hint: Alternatively, you can use Azure blob storage to store the script. Make the blob storage read-only and use the URL as rollout script-path. E. g. : https://sharedservices01. blob. core. windows. net/wvd Create a file share for the configuration script (which adds new session hosts to the domain and install the AVD agent). Give everyone at least read permissions. Set the NTFS permissions to everyone and read. This is necessary while during the first startup, the VM extension tries to execute the script. In this process, the file share is accessed anonymously.  Place the following files in this share: ITPC-WVD-Image-Processing. ps1 (rename the download to . ps1)Microsoft. RDInfra. RDAgent. msi (rename the file)Microsoft. RDInfra. RDAgentBootLoader. msi (rename the file)Make sure that you rename the files to fit the list above (without version numbers).  Important: If you are using Windows Server 2019 as file share, make sure that anonymous file share access is enabled. Create a GPO for the session hosts containing the following configurations: Security Options:Accounts: Guest Account Status: EnabledNetwork access: Let Everyone permissions apply to anonymous users: EnabledNetwork access: Do not allow anonymous enumeration of SAM accounts and shares: DisabledConfigure WVDAdminPlease start WVDAdmin. Before you load AVD and Azure data, copy the Azure tenant id, service principal id, and service principal key into the welcome tab. Press save and load the data by clicking “Reload all”. You are now able to administrate WVD, create images from template VMs and rollout new session hosts. The first time you want to roll out new session hosts, you have to enter some information from your Active Directory and file share configuration from above: Local Admin and local pw. are the local administrator account credentials which you can enter at this time.  Build an imageYou can rollout VMs and VM Scale Set with images created by WVDAdmin. These images contain the logic to join the AD domain and WVD. You can simple create an image from a template VM. The template VM must part of your AD like a standard client. You have not to sysprep or to normalize this template VM. Use the same template VM for Windows and application updates. Following these steps to build your template: Install a VM in the Azure portal. Select the right OS (like Windows 10 Enterprise for Virtual Desktops)Make all Windows updatesJoin the VM to your ADInstall your applicationMake your customizing (like installing language packages)Shutdown the template VMTo create the image, open WVDAdmin and Navigate to the Azure template VM (Azure -&gt; Virtual Machines -&gt; RG -&gt; VM)Right-click -&gt; “Create a template image”Select the resource group to store the imagePress “Capture”You can and should reuse the template VM for new updates and applications. After these changes, shut down the template VM and create a new image. Tipps &amp; TricksVM Scale Sets: First node: VM Scale Sets cannot autoscale AVD session hosts. Auto-scaling only works for stateless services like a web server. But if you need hundreds of session hosts, then VM Scale Set allows you to work with these numbers efficiently. Read moreFrom version 1. 2. 5, WVDAdmin support VM Scale Sets. A Scale Set can have several instances, which are the VMs / session hosts. There are some essential things you have to know if you use VM Scale Set with WVDAdmin and AVD itself:Build a Scale Set with WVDAdmin. Select an image, right-click and select “Create session host from image”. Check “Rollout as VM Scale Set”You can use regular disks and ephemeral disks. If you use ephemeral disks, you cannot deallocate the instances of your Scale Set. You have to delete the instancesToday, you can not use ultra disksYou can add and remove instances with WVDAdmin or in the Azure Portal. New instances will join the domain and WVDA new instance can only join AVD if the session host with the new name doesn’t exist. If you delete instances, the session host entry will also be removedYou can re-image single instances or all instances of a Scale Set. After that, the instances are “clean” as at the first rolloutAdding instances or re-imaging assumes that the Scale Set configuration (which is a custom script extension) has a valid AVD token to join new instances to WVD. While AVD provides only one token per host pool and that the token can be expiring, you can update the token with a right-click on the Scale Set and select “Update WVD token”. The max. lifetime of a token is 59 daysUnfortunately, WVDAdmin cannot change the source image for a VM Scale Set. So if you want to update the image for a host pool, take these steps:Rollout a new Scale Set based on the new imageDisable new logons for the old session host from the previous Scale SetTest the host pool based on the new Scale SetIf no user logged on to the ancient Scale Set, remove all instances from the Scale Set (this deletes the session hosts in AVD as well)Remove the Scale SetEphemeral disks: Ephemeral disks are awesome. They give you a high performance free of charge. Especially in a AVD multiuser environment where no data a stored permanently on the session hosts, this kind of disk can give you some value add. Read moreEphemeral disks are running on the Azure hypervisor and not stored. This has some advantages:There are no storage costs (!)A very high data throughput because the disks exist on the hypervisorSee @MichaWets  blog post for more information: https://www. cloud-architect. be/2019/07/15/windows-virtual-desktop-running-on-ephemeral-os-disks/Please note: You can not deallocate a VM with this disk type - you have to delete the VM (and roll out a new one instead of starting a “normal” VM)Not each VM size is available, and there are limitations of the disk size (image size for rollout) based on the VM size: Max ephemeral disk size for Standard_D4s_v3 is 64 GByte while a Standard_D8s_v3 can have up to 128 GByte. See https://docs. microsoft. com/en-us/azure/virtual-machines/linux/sizes-generalIf the Azure hypervisor fails, your session host will fail as well and can not be re-deployed automatically Secret Features: WVDAdmin has some features not directly visible but configurable via registry keys. All settings in the registry are in the current user part under HKEY_CURRENT_USER\SOFTWARE\ITProCloud\WVDAdmin. Keep in mind to restart WVDAdmin after changing the registry settings. Read moreDark-mode: From version 1. 7. 33 WVDAdmin can be run in dark-mode. Set the following reg value and restart WVDAdmin: HKEY_CURRENT_USER\Software\ITProCloud\WVDAdmin\DarkMode to 1 (DarkMode is REG_DWORD32) Multi-Tenant-Mode: From version 1. 3. 0 WVDAdmin will support a multi-AAD-tenancy mode allowing to switch the Azure AD tenant very easily. Follow this link Having multiple Service Principals for a single Tenant: In the Multi-Tenant-Mode, you can add one service principal per tenant. Sometimes you need more service principals for the same tenant. You can add more service principals for a tenant if you append #1 directly behind the tenant id (or #2, …). Naming of the Session Hosts: If you deploy session hosts to a host pool, WVDAdmin counts up the names from the highest available VM. E. g. , if you have a session host with the name “WVD-PROD-012” and you rollout new hosts (WVD-PROD-###), the first new hostname is “WVD-PROD-013” - even if you have gaps in the existing numeration. You can force WVDAdmin to fill this gaps (non-existing hosts in the naming schema) if you set the following registry key:Reg-DWord: NamingMode = 1 Split-Tenant: Usually, the AVD tenant and the resources (sessions hosts) are in the same AAD tenant. If you have two Azure AD tenant, you can use WVDAdmin with a second service principal for the session hosts (resource tenant). Follow this link US-Government Cloud: WVDAdmin can be used to deploy AVD in the Azure Government Cloud. You can enable WVDAdmin to work in the US Government Cloud via registry:Reg-SZ: Environment = US Run custom actions simultaneously: From version 1. 6. 15, WVDAdmin supports custom scripts to run administrative tasks simultaneously on different session hosts. And that is easy to use and to extend. Follow this link Add a session host automatically to an ASG: You can add a session host automatically to application security groups (ASG) within the rollout process. To achieve this, add one or more tags to the host pool containing your new session hosts. Name WVD. Default. ASG. X and add the azure resource id of an existing asg. X can be numbers to assign more ASGs. You can copy the id from an ASG from your browser. It looks like this: /subscriptions/&lt;subscription-id&gt;/resourcegroups/&lt;resourcegroup-name&gt;/providers/Microsoft. Network/applicationSecurityGroups/&lt;asg-name&gt; Add a session host automatically to a Loadbalancer Backend Pool: You can add a session host automatically to a loadbalancer backend pool within the rollout process. To achieve this, add one or more tags to the host pool containing your new session hosts. Name WVD. Default. LBPool. X and add the azure resource id of an existing loadbalancer backend pool. X can be numbers to assign more ASGs. You can copy the id from a pool from your browser. It looks like this: /subscriptions/&lt;subscription-id&gt;/resourcegroups/&lt;resourcegroup-name&gt;/providers/Microsoft. Network/loadBalancers/&lt;loadbalancer-name&gt;/backendAddressPools/&lt;pool-name&gt;Keep in mind to use availability sets for each rollout to use this feature. Rollout session hosts with Azure Disk Encryption (ADE): Set two tags to the host pool to use it: “WVD. Default. KeyVault. Id” with the resource id of the KeyVault, “WVD. Default. KeyVault. KeyUri” with the URI (including the version) of the prepared key to wrap the secret. TroubleshootingCreate an Image: The image is not created. An error message occurs:Check if your template VM part of the ADIf your file server Windows Server 2019, read aboveCheck if you have set the NTFS and share permission correctlyAzure portal: Go to the temp VM (next to the template VM) and check the extension installation state. There should be an error message like script not found, access denied, etc. Have you renamed the RD agent and bootloader?Is the script saved correctly: ITPC-WVD-Image-Processing. ps1, not ITPC-WVD-Image-Processing. ps1. txtDon’t forget to delete the temp VM and temp disk to avoid costsMake sure that your template VM uses managed diskThe script generates additional log files in %WinDir%\System32\LogFilesWindows 7: Make sure to install PowerShell 5. 1 and all Windows updates (including the optional updates without the language packages) to the template VM and restart the VM to take effect: https://www. microsoft. com/en-us/download/details. aspx?id=54616 Makes sure that you use the newest script file from 09/2020: ITPC-WVD-Image-Processing. ps1NEW: An endless loop of “Waiting for the temporary vm (power off)” : Update to the newest PowerShell script for generalizing: ITPC-WVD-Image-Processing. ps1Others: You have created a host pool, an app group, and assigned a user to the app group, but the user cannot see the apps/desktop. For AVD ARM: Don’t forget to create a workspace and link the app group in the workspace. The workspace is mandatory to show the users’ resources. For the HTML5 web site: Check the correct web address:ARM/Spring: https://aka. ms/wvdarmwebClassic/Fall: http://aka. ms/wvdweb Download the latest release from 10/13/2023 "
    }, {
    "id": 20,
    "url": "https://blog.itprocloud.de/AVD-Azure-Virtual-Desktop-Error-Drill-Down-Workbook/",
    "title": "Debugging Azure Virtual Desktop errors/issues/network latency and bandwidth with an interactive Workbook",
    "body": "2023/10/13 - Correctly configured, Azure Virtual Desktop sends diagnostic data to a log analytics workspace (Azure Monitor). There are several logs containing data about the events in the backend: Log TypeNoteWVDAgentHealthStatusDetails about the session hostsWVDConnectionsAll about connections from a user to a session hostWVDErrorsError message from different sources (client, RDGateway, Loadbalancer, …)WVDFeedsLog about clients downloading information about the AVD resourcesWVDHostRegistrationsLogs if a host tries to register to a host poolWVDManagementLog about administrative tasksWVDCheckpointsDetailed information related to logins, errors, …WVDConnectionNetworkDataNetwork information (bandwidth and RTT)To get the logs, configure at least the host pool to send log information to a log analytics workspace. You can do this on a host pool level -&gt; Diagnostic settings -&gt; Add diagnostic settings -&gt; Select all Logs and target a log analytics workspace.  Alternatively, you can use WVDAdmin to do that (use version 1. 7. 25 or higher): It will take a while before you can see the first data. The data can be queried with the KUSTO language or analyzed with custom workbooks. I prepared a workbook to dig into the data. Most visualizations are interactive. So you can drill down by selecting users, networks, agent versions, and more.   You can install the workbook directly as a template into your subscription: Install the workbook After a while, the workbook is visible as a new template in: Log Analytics -&gt; Workbooks -&gt; Azure Virtual Desktop -&gt; AVD - Deep-Insights You can select the time frame and host pool from the drop-down list. The other drop-down lists are optional. Please ensure that you have included the essential errors from the error selector. Remember that not all errors are making issues (e. g. , “ConnectionFailedClientDisconnected” occurs if a session goes in the disconnected mode while the users close its notebook). Please let me know if you have ideas to extend the workbook. VersionDateNote1. 101/28/2022Initial1. 202/17/2022Include RTT and bandwidth (right now, host pool must be in the validation environment and diagnostic data must include NetworkData); see https://techcommunity. microsoft. com/t5/azure-virtual-desktop/collect-and-query-network-data-for-azure-virtual-desktop/m-p/3140397 Name changed to AVD - Deep-Insights1. 303/16/2022Include Logon timing (GPO, FSLogix, Authentication, etc. )1. 404/14/2022In Session Bandwidths &amp; Latencies: The connection type is shown if RDP Short Path is used (Public, Private). See: https://docs. microsoft. com/en-us/azure/virtual-desktop/shortpath-public1. 505/03/2022New visualization: Logon timing per day and category over the time1. 610/11/2022New visualization: Connections over time, unhealthy session hosts, graphic performance1. 711/03/2022Optimization for charts to show data over a large time frame1. 811/14/2022A new tab “Resources”, to show orphan session hosts; Fix: Number of active and inactive sessions - timeselector was not correct1. 911/18/2022A new tab “Resources”, to show orphan VMs (where the session host object is missing)2. 012/01/2022Changed the description for the estimated available bandwidth2. 112/09/2022Added orphan disks and orphan nics to the “Resources” tab (note: All orphand devices will also shown and could be removed in Hydra for Azure Virtual Desktop, version 1. 0. 1. 84 (comming soon))2. 202/02/2023Added “Water Markings” to query session information by the feature WaterMarking2. 302/20/2023Added “Unresponding AVD Agents” in the tab “Resources” to identify running VM with a non responding AVD agent2. 402/21/2023Added new tab “FSLogix” to show the size, usage and free space of the FSLogix profiles2. 503/08/2023Fix in the time selector; allow to selecte multiple host pools; show active sessions with user name and started desktop/remote app2. 603/31/2023Add: Show office container size and usage (ODFC) in the FSLogix tab (additional to the profile container)2. 707/01/2023Fix/Workaround: VHDFreeSpace is stored as text in MByte and not in GByte if the value is less then 1 GByte2. 810/13/2023Add: Show the last heart beat time in the Orphan session hosts view and warns, if the heart beat is longer then 90 days ago Please click twice on create to accept the Microsoft Agreement of terms - Workbooks don’t generate costs "
    }, {
    "id": 21,
    "url": "https://blog.itprocloud.de/Update-Windows-10-Multi-user-to-Windows-11-Multi-user/",
    "title": "Updating a Golden Master VM from Windows 10 multi-user to Windows 11 multi-user",
    "body": "2023/10/07 - The Golden-Master approach is a common way to deploy applications and desktops as session hosts in Azure Virtual Desktop. The approach is very simple, and the rollout of new session hosts is very fast - while applications are installed and the host configured. Using PowerShell, WVDAdmin, or Hydra simplifies the process while the original Golden Master VM survives and can be updated with OS and application updates over time. The process looks like this: Installing the Golden Master VM in Azure with Windows multi-userRunning Windows UpdateInstalling the applicationsConfiguring the VMGrabbing an image with PowerShell, WVDAdmin, Hydra, etc. , without destroying the Golden Master VMUsing the image to deploy multiple session hostsIt is a very easy approach, and often, the applications and the configuration of the master are done with a software deployment solution (like Intune, ECM). But there are also deployments where the master was customized manually, including the configuration and applications. In this case, changing the underlying OS can be a challenge. Windows 10 multi-user: There are a lot of manual customized Golden Masters with Windows 10 multi-user. Unfortunately, Windows Update mostly does not offer an in-place-upgrade to Windows 11 multi-user. Even the following approaches are not working for Windows 10 multi-user: Downloading Windows 11 and trying to upgrade the VM -&gt; Doesn’t work, while the ISO files of Windows 11 are not multi-userForcing Windows Update to install Windows 11 -&gt; That is mostly not enough (see below)Preparing your VM: To update to Windows 11 multi-user, your VM must have trusted launch-, secure boot-enabled, and a vTPM. You can do this in the following ways: Your VM is Generation V1:Creating a Windows Azure VM Generation V2 from a V1 VMYour VM is Generation V2 without a trusted launch-enabled security type:Updating or cloning a Azure VM with standard security to trusted launch with secure boot and vTPM orCreating a Windows Azure VM Generation V2 from a V1 VMForcing Windows Update: You can force Windows Update to show Windows 11 as an option. Log in to the new Golden MasterModify the local policy to force Windows Update to install Windows 11 22h2: Local Computer Policy\Computer Configuration\Administrative Templates\Windows Components\Windows Update\Windows Updates for Business\Select the target Feature Update versionRun Windows UpdateUpdate to Windows 11RebootRemove the local policy entriesYour Golden Master is ready and converted from Windows 10 to 11 multi-userLink to the YouTube video.  If you got the following error message: The PC must support TPM 2. 0. , you have forgotten to migrate your VM to a V2 Generation with trusted lauch-enabled. "
    }, {
    "id": 22,
    "url": "https://blog.itprocloud.de/Migrate-Azure-VM-To-Trusted-Launch/",
    "title": "Updating or cloning a Azure VM with standard security to trusted launch with secure boot and vTPM",
    "body": "2023/10/07 - Note: If your source VM is based on the VM generation V1, follow this post to convert your VM: Creating a Windows Azure VM Generation V2 from a V2 VM. Also, follow the link if you want to have an exact copy (and not a clone) of your VM. If you once installed an Azure VM with the standard of security, you can not convert this VM into a trusted launch-enabled VM with secure boot and vTPM. But that is sometimes necessary, e. g. , if you want to upgrade from Windows 10 multi-user to Windows 11 multi-user. But there is a way to do that. You could capture your existing VM and store the image in a secure boot enabled. Compute Gallery definition in Azure. From this image version, you can create a new VM with a security-type trusted launch. Prepare an Azure Compute Gallery: Create an Azure Compute Gallery “Conversion_Gallery” in the same resource group of your VMAdd an Image Definition “Secure-VM”Security Type: Trusted LaunchOS state: GeneralizedTick “Accelerated networking” if this is enabled on your original VMFill Publisher, Offer, SKU with some informationClick Review+Create, Create Capturing the original VM: I’m using WVDAdmin to prevent that I must sysprep my original VM. WVDAdmin first makes a clone of the original VM and runs sysprep on the clone. In the end, I have an image in a compute gallery and the untouched original VM. In WVDAdmin: Azure -&gt; Virtual Machines -&gt; Resource Group -&gt; Right-click the VM and select “Create a template image”Enter an image name (no spaces)Select the resource group of the VM as Target RGTick “Use Azure Compute Galleries”Select your Gallery and Gallery definitionYour region from the listHit “Capture”This will take a while to clone the VM, create an image and upload it to the image gallery. Note: You can delete the also-created custom image (we only need the gallery image) Deploying a new secure boot-enabled VM from the image: With WVDAdmin or in the Azure Portal, you can create a new VM from that image containing all the applications. Please note that the new VM has a new name and compute identity. Go to the gallery definition in the Azure Portal and select your uploaded version. Hit + Create VMFill out all parameters and ensure that you select the security type “Trusted Launch” After the deployment, you have a new trusted launch-enabled VM based on your - still existing - original VM. "
    }, {
    "id": 23,
    "url": "https://blog.itprocloud.de/Migrate-Azure-V1-VM-to-Azure-V2-VM-In-A-Safe-Way/",
    "title": "Creating a Windows Azure VM Generation V2 from a V1 VM",
    "body": "2023/10/07 - Microsoft has provided different VM sizes over the last years and also introduced the VM Generation V2 at the end of 2019. V2 VMs are different from V1 VMs and have the following advantages: UEFI based (no longer bios-based)Enhanced OS supportFaster boot and disk supportAdvanced Security Features, like Secure Boot, which ensures the integrity of the boot process, and BitLocker encryption, which enhances data protectionToday, I expect that the most deployed VMs are V2, but I still see older V1 versions - including in my own environment. For example, I have several Golden Masters for Azure Virtual Desktop running Windows 10 22/h2 Multi-User. We still see V1 types because of the missing simple migration path. There is no native way in the Azure Portal to do this. While I wanted to upgrade my Windows 10 Golden Masters to Windows 11, I came to the point of discovering that Windows 11 needs a V2 generation VM (for upgrading, trusted launch, vTPM, and secure boot must also be enabled). After some research, I figured out that this is really not simple. I found a good blog post from Charbel Nemnom, who provides a step-by-step solution. The solution is still complex, so I decided to write a PowerShell script to handle this complex process more easily. How does it work: We have our V1 virtual machine we want to convert. Instead of converting, we are building a new virtual machine (V2) with the converted OS disk of our V1 VM. So, in the end, we have two identical VMs: The original V1 VM and the V2 VM. If anything doesn’t work, we still have our original VM. But takes some time, and the full process takes hours (for the script). After configuring the script, the script enters the following steps: Deallocates the V1 VMCreates the new V2 VM with the same size in the same network, optional with trusted launch, secure boot, and vTPMMakes a snapshot of the V1 OS disk and, from the snapshot, a cloned OS disk (still V1)Creates an empty V2 disk with the same size and type as the V1 OS disk(this disk is supposed to be our converted OS disk)Attaches the empty V2 disk and the cloned V1 OS disk to the new V2 VMThe script runs itself on the V2 VMPreparing the partitions of the attached disksFormatting the partitionsCapturing the cloned V1 OS partition using DISM (that takes some time; in my last conversion, it took nearly 4 hours)Apply the captured image to the prepared partition of the empty V2 diskWrite the UEFI partition of the formerly empty V2 diskDeallocates the V2 VMDetach the attached disksSwap the OS disk with the no longer empty V2 disk (the now converted OS disk of the V1 VM)Starting the V2 VMDoing some cleanup: Deleting the snapshot, the old V2 OS disk, the cloned V1 OS diskDone How to use the script: Open the script in a PowerShell editor like ISE (or VS Code). Connect to your Azure subscription using Connect-AzAccount Modify the script to match your: Your subscription IdYour source V1 VM (name and resource group)Your new V2 VM (name and resource group - ensure to have a different name or resource group; another name of the VM doesn’t reflect the computer name after the process)Set $enabledTrustedLaunch = $true to also create your V2 VM trusted launch enabled, incl. secure boot and vTPMThe tempDiskSizeGb must be large enough to contain the temporary OS (Server 2022) and the content of the OS disk of the V1 VM (512 should be fine if the disk of the V1 VM is 128 GByte)That’s all. You can run the script and come back after some hours to see the result. Hints: If the VM size doesn’t support V2, modify the target VM size in the scriptIf something fails: Cleanup the temporarily created resources manually (snapshot, empty V2 disk, cloned V1 disk, and V2 VM)Upgrading to Windows 11 multi-user: Check-out this videoWhere is the script: You can find the script on github: Create-V2-From-V1-VM. ps1 "
    }, {
    "id": 24,
    "url": "https://blog.itprocloud.de/Rollout-AVD-SessionHost-To-Defender-Automatically-with-a-script/",
    "title": "Onboard AVD pooled session hosts to Defender automatically with a script",
    "body": "2023/08/22 - Onboarding session hosts to Defender is very important for security reasons. Microsoft has documented the way to onboard these devices in different scenarios here: https://learn. microsoft. com/en-us/microsoft-365/security/defender-endpoint/configure-endpoints-vdi While I often work with Hydra for Azure Virtual Desktop and also have some AAD native deployment, I decided to prepare an easy script to onboard this device automatically after the rollout. The script is generic, so it can also be used with other automation. To start, we need the VDI onboarding script for non-persistent devices from htps://defender. microsoft. com/securitysettings/endpoints/onboarding - Make sure to download the right package. To install Defender without the need to store the package (zip file) to share, we can encode the package to a base64 encoded string. After that, we can grab the string from the text file WindowsDefenderATPOnboardingPackage. zip. txt and put it into quotes in line 30. Step-by-step: Save the PowerShell script to your local diskChange $false into $true in line 22Download the onboarding script and store it in the same folderRun the PowerShell scriptOpen the text file WindowsDefenderATPOnboardingPackage. zip. txt and put it into quotes in line 30The script can then be run after the rollout to join the device to Defender. In Hydra, you can add the script as a new script into Scripts and Collections (with your onboarding script encoded in line 25 and $false in line 22). Add the script to the Deployment Configuration -&gt; Run script or script collection after deployment: The next device is automatically onboarded to Defender. The script:: # Script to prepare and onboard AVD non-persistent hosts to Microsoft Defendertest if fuction LogWriter availableif (!(Test-Path function:LogWriter)) {function LogWriter($message) {Write-Host $message}}Add-Type -AssemblyName System. IO. Compression. FileSystem $DefenderFile=&quot;WindowsDefenderATPOnboardingPackage. zip&quot;$ScriptPath = Split-Path -Path $MyInvocation. MyCommand. Definition -Parent function UnzipFile{param([string]$zipfile, [string]$out)[System. IO. Compression. ZipFile]::ExtractToDirectory($zipfile, $out)} set it to $true to generate the base64 string from your dowloaded WindowsDefenderATPOnboardingPackage. zip - that must run locallyif ($false) {# Generate base64 file fron DefenderFile# Download VDI onboarding script for non-persistent devices from: https://defender. microsoft. com/securitysettings/endpoints/onboardingLogWriter(&quot;Generate base64 file fron DefenderFile&quot;)$WindowsDefenderATPOnboardingPackage=[System. Convert]::ToBase64String((Get-Content -Path &quot;$ScriptPath$DefenderFile&quot; -Encoding Byte))$WindowsDefenderATPOnboardingPackage | Out-File &quot;$ScriptPath$($DefenderFile). txt&quot; -Encoding UTF8} else {LogWriter(&quot;Read base64 file fron DefenderFile&quot;)$WindowsDefenderATPOnboardingPackage =&quot;&lt;put your base64 encoded string here&gt;&quot;# Clean up the temp folderLogWriter(&quot;Cleaning up the temp folder&quot;)Remove-Item -Path &quot;$env:temp\WindowsDefenderATPOnboardingPackage. zip&quot; -Force -ErrorAction SilentlyContinueRemove-Item -Path &quot;$env:temp\WindowsDefenderATPOnboardingPackage&quot; -Recurse -Force -ErrorAction SilentlyContinueLogWriter(&quot;Create the Defender files&quot;)Set-Content -Path &quot;$env:temp\WindowsDefenderATPOnboardingPackage. zip&quot; -Value ([System. Convert]::FromBase64String($WindowsDefenderATPOnboardingPackage)) -Encoding ByteUnzipFile &quot;$env:temp\WindowsDefenderATPOnboardingPackage. zip&quot; &quot;$env:temp\WindowsDefenderATPOnboardingPackage&quot; # start the test. cmd with cmd. exe in the extracted folderLogWriter(&amp;quot;Starting the onboarding&amp;quot;)Start-Process -FilePath &amp;quot;$env:windir\system32\cmd. exe&amp;quot; -ArgumentList &amp;quot;/c WindowsDefenderATPOnboardingScript. cmd&amp;quot; -WorkingDirectory &amp;quot;$env:temp\WindowsDefenderATPOnboardingPackage&amp;quot; -Wait -PassThru# Clean up the temp folderLogWriter(&amp;quot;Cleaning up the temp folder&amp;quot;)Remove-Item -Path &amp;quot;$env:temp\WindowsDefenderATPOnboardingPackage. zip&amp;quot; -Force -ErrorAction SilentlyContinueRemove-Item -Path &amp;quot;$env:temp\WindowsDefenderATPOnboardingPackage&amp;quot; -Recurse -Force -ErrorAction SilentlyContinue} "
    }, {
    "id": 25,
    "url": "https://blog.itprocloud.de/Session-Hosts-are-unavailable-or-shutdown-even-if-the-VMs-are-running/",
    "title": "Session hosts are not available in Azure Virtual Desktop, but VMs are running. ",
    "body": "2023/06/28 - During June/July, I got several emails that session hosts were not available in AVD, but the VMs were in a running state. Rebooting the host sometimes helps, and the host was shown as available. We figured out that the issue was caused by a not running RDAgentBootLoader service on affected hosts. Starting the service (or the host) resolved the issue. Right now, I don’t know the root cause of why the RDAgentBootLoader was not started or failed. To workaround this behavior by implementing a scheduled task, start with the host and monitors the service for the first 30 minutes. The service will be started if it’s not running. The scheduled task will automatically be created for new deployments with Hydra for Azure Virtual Desktop or WVDAdmin) from version 06/27/2023. If you want to build your own scheduled task, you can use this script: 	$interval=30	$run=$true	$counter=0	$serviceName=&quot;RDAgentBootLoader&quot;	do {		Start-Sleep -Seconds $interval		$service=Get-Service -Name $serviceName -ErrorAction SilentlyContinue		if ($service -ne $null -and $service. Status -ne [System. ServiceProcess. ServiceControllerStatus](4)) {			Write-Host &quot;Starting service: $serviceName&quot;			Start-Service -Name $serviceName -ErrorAction SilentlyContinue		}		$counter++		if ($counter -gt 10) {$interval=90}		if ($counter -gt 20) {$run=$false}	} while ($run)PS: Maybe it makes sense to monitor the service during the runtime of the VM in the future. "
    }, {
    "id": 26,
    "url": "https://blog.itprocloud.de/CountrySwitch-Select-Language-on-first-start-and-an-appstarter-for-remoteapps/",
    "title": "CountrySwitch - First Logon Experience and language selector and an app starter for remote apps on network paths for AVD",
    "body": "2023/05/11 - First Logon Experience and language selector and an app starter for remote apps on network paths: Download the latest release from 05/11/2023 Select the language (users): In some environments, customers are running Azure on Windows 10/11 with multiple language packs installed. After the first login, users have to choose their language to customize the environment - that is not so easy, while users have to open the language settings and select the language. The first steps are outside the user’s language and are not easy to do for everyone. I built a tool that makes it easier for users to select their language by clicking on the right flag. Currently, the following features are available: Feature regarding the language selection: The tool shows the installed language packages by a flag of the countries. A welcome message in the present language welcomes the users. The user selects the language settings with a click on the flag. Hovering the mouse over a flag shows the country and language name. The app configures the language settings (and does one logoff to apply the setting). The PowerShell script CountrySwitch-User. ps1 in the program files folder is started to do some optional customizing (language code is in $languageTag)CountrySwitch is linked in all users’ start menu: Startup: With parameter /RunOnce - Starts CountrySwitch at logon. The user will see the language selector only if the user is new and didn’t select a language once (HKCU:\SOFTWARE\ITProCloud\CountrySwitch\Completed is set to 1 )Direct: Without parameters - Users can star CountrySwitch manually to select the languageNote on Remote Apps: Remote apps are ignoring the autostart folder. To have CountrySwitch enabled for remote app, please configure a local Startup script (local policy for users) with the following parameters:Name of script: “C:\Program Files\ITProCloud. de\CountrySwitch\CountrySwitch. exe”Parameters:	/runonce App Starter for remote apps: CountrySwitch can also start a local or an application on a file share (which normally does not work directly with AVD). Publish CountrySwitch as a remote app with the following parameters: CountrySwitch. exe /remoteapp &quot;&lt;path to executable with parameters&gt;&quot; &quot;&lt;Working directory&gt;&quot;CountrySwitch. exe /remoteapp &quot;\\&lt;path&gt;\&lt;share&gt;\finance. exe /db=vm1&quot; &quot;\\&lt;path&gt;\&lt;share&gt;&quot;If a remote app is started with CountrySwitch, CountrySwitch first starts the PowerShell script CountrySwitch-App. ps1 in the program files folder to do some optional customization. The following parameters are set in the script: Example: $languageTag = &quot;unknown&quot;,$appCommandline = &quot;\\&lt;path&gt;\&lt;share&gt;\finance. exe /db=vm1&quot;,$appWorkingDir = &quot;\\&lt;path&gt;\&lt;share&gt;&quot;,$appParameter = &quot;/db=vm1&quot;,$appExecutable = &quot;finance. exe&quot;The application starts after the PowerShell script finishes (CountrySwitch will run hidden and terminates after the start of the application (e. g. , finance. exe). Logging and configuration: CountrySwitch logs into %AppData%\ITProCloud There are the following reg keys to optionally configure CountrySwitch: HKLM:\SOFTWARE\Policies\ITProCloud\CountrySwitch (alls values are dword - 1 is true; 0 is false) KeyValueDefault valueEnabledIf false, the application will not show up (except for /remoteapp (App starter mode))trueExitOnRunOnceCompletedIf the app is started with /runonce and the user has already completed the process, the application will not show uptrueExitOnSingleLanguageIf only one language is installed, don’t show upLogoffUserAfterSelectingNewLanguage logoff user after selecting a new languagetrueLogoffUserAfterSelectingSameLanguageLogoff user after selecting the same language as the user is still usingfalseRunUserScriptAfterSelectingLanguageRuns the ps script CountrySwitch-User. ps1 -languageTag {xx-YY} after the user selects a languagetrueDisableUserScriptForAppStarterModeIf true, the app starter mode for a remote app will no longer trigger CountrySwitch-App before starting the applicationtrueRelease notes: ReleaseDateChanges &amp; Notes1. 1. 32023-05-04Initial1. 1. 42023-05-10Update: CountrySwitch-User. ps1 had a typo1. 1. 72023-05-11Fix: Avoid showing MSI installation screen for users if package unaccessible Download the latest release from 05/11/2023 Please feel free to send me ideas for improvements. "
    }, {
    "id": 27,
    "url": "https://blog.itprocloud.de/Azure-Virtual-Desktop-Login-error-Protocol-Error-Code-0x112f-Windows-11/",
    "title": "Azure Virtual Desktop - Login error Protocol Error Code 0x112f - Windows 11",
    "body": "2023/04/07 - Login error: Protocol Error Code 0x112f There are a lot of posts regarding this issue. I figured out that this old issue comes back in a specific combination with RDS settings and Windows 11. If a user has multiple monitors and connecting to AVD, an error message is raised, if:The session uses all of the monitorsAVCHardwareEncodePreferred is set to 1 (e. g. , by using the GPO “Configure H. 264/AVC hardware encoding for Remote Desktop Connections”)The operating system is Windows 11 (22H2) - I was not able to reproduce the issue with Windows 10 and with the same configuration Solution:If policies are used: Unconfigure all protocol-related settings in Administrative Templates\Windows Components\Remote Desktop Services\Remote Desktop Session Host\Remote Session Environment. Configure the protocol-related settings through the registry on the hosts or on the Golden Master (e. g. , with a script in Hydra for Azure Virtual Desktop or WVDAdmin). Important is the value for AVCHardwareEncodePreferred. That should be 2 (which cannot be set with the GPO). The teams optimization is optional: Write-Host &quot;RDS Settings&quot;New-Item -Path &quot;HKLM:\SOFTWARE&quot; -Name &quot;Policies&quot; -ErrorAction IgnoreNew-Item -Path &quot;HKLM:\SOFTWARE\Policies&quot; -Name &quot;Microsoft&quot; -ErrorAction IgnoreNew-Item -Path &quot;HKLM:\SOFTWARE\Policies\Microsoft&quot; -Name &quot;Windows NT&quot; -ErrorAction IgnoreNew-Item -Path &quot;HKLM:\SOFTWARE\Policies\Microsoft\Windows NT&quot; -Name &quot;Terminal Services&quot; -ErrorAction IgnoreNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\Policies\Microsoft\Windows NT\Terminal Services&quot; -Name &quot;AVC444ModePreferred&quot; -Value 0 -force # if 1 - browser mm redirection is not workuingNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\Policies\Microsoft\Windows NT\Terminal Services&quot; -Name &quot;AVCHardwareEncodePreferred&quot; -Value 2 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\Policies\Microsoft\Windows NT\Terminal Services&quot; -Name &quot;bEnumerateHWBeforeSW&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\Policies\Microsoft\Windows NT\Terminal Services&quot; -Name &quot;fEnableRemoteFXAdvancedRemoteApp&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\Policies\Microsoft\Windows NT\Terminal Services&quot; -Name &quot;fEnableTimeZoneRedirection&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\Policies\Microsoft\Windows NT\Terminal Services&quot; -Name &quot;KeepAliveEnable&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\Policies\Microsoft\Windows NT\Terminal Services&quot; -Name &quot;KeepAliveInterval&quot; -Value 1 -forceWrite-Host &quot;Teams Optimization&quot;New-Item -Path &quot;HKLM:\SYSTEM\CurrentControlSet\Control\Terminal Server&quot; -Name &quot;AddIns&quot; -ErrorAction IgnoreNew-Item -Path &quot;HKLM:\SYSTEM\CurrentControlSet\Control\Terminal Server\AddIns&quot; -Name &quot;WebRTC Redirector&quot; -ErrorAction IgnoreNew-Item -Path &quot;HKLM:\SYSTEM\CurrentControlSet\Control\Terminal Server\AddIns\WebRTC Redirector&quot; -Name &quot;Policy&quot; -ErrorAction IgnoreNew-ItemProperty -Path &quot;HKLM:\SYSTEM\CurrentControlSet\Control\Terminal Server\AddIns\WebRTC Redirector\Policy&quot; -Name &quot;ShareClientDesktop &quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SYSTEM\CurrentControlSet\Control\Terminal Server\AddIns\WebRTC Redirector\Policy&quot; -Name &quot;DisableRAILScreensharing &quot; -Value 0 -forceNew-ItemProperty -Path &quot;HKLM:\SYSTEM\CurrentControlSet\Control\Terminal Server\AddIns\WebRTC Redirector\Policy&quot; -Name &quot;DisableRAILAppSharing&quot; -Value 0 -force "
    }, {
    "id": 28,
    "url": "https://blog.itprocloud.de/WVDAdmin-Hydra-Package-Manager-Install-and-Update-apps/",
    "title": "Deploying and updating standard applications with Microsoft Package Manager / Winget automatically",
    "body": "2023/03/28 - Around 2. 5 years ago, I introduced a feature in WVDAdmin to install applications from a list of thousands of VM and hosts. That was based on the Microsoft Package Manager / Winget - at this time, probably in preview. During the last week, I updated the process of how WVDAdmin gets the newest data about available package and also implemented this feature in Hydra for Azure Virtual Desktop. In WVDAdmin you select session hosts or VMs and then select the package do you want to install: Select Hosts / VMs -&gt; Run script: Microsoft Package Manager / Winget -&gt; Click on Run script -&gt; Select the applications and go.  I also recorded a video to show how to use it in Hydra for Azure Virtual Desktop: "
    }, {
    "id": 29,
    "url": "https://blog.itprocloud.de/Using-FSLogix-file-shares-with-Azure-AD-cloud-identities-in-Azure-Virtual-Desktop-AVD/",
    "title": "Using FSLogix file shares with Azure AD cloud identities in Azure Virtual Desktop - cloud-only, AVD",
    "body": "2023/03/02 - With AAD-Kerberos, you can use AAD-only joined session hosts with FSLogix. This is a great approach to working more cloud-native. With AAD-Kerberos, the session hosts don’t need to have network line-of-sight to the domain controller. However, the user identities must still be hybrid / synchronized from a legacy AD right now. And that prevents having AAD-only users in a multi-user pool in AVD where a profile is mostly mandatory. Update 2023-03-02: There was an issue in the script/parameter for cmdkey. The parameter we need is /add not /generic Update 2023-02-15: Change of the script to work with Windows 11 22H2Windows 11 22H2 removes the cmdkey entry if the host is deallocated and started again. The additional registry key prevents this behavior. Workaround: I found a nice workaround to do the same with cloud-only users in Azure AD - including the use of FSLogix file shares. Today, an Azure file share cannot be configured to use the AAD like an AD to set NTFS permissions. This is necessary to give the users the right permissions to create a profile folder on the share and have full access only to their own created files (the profile disk). Users should never have access to the profile disks of other users - to prevent data theft or to modify other users’ data). But how to handle this? For this workaround, I use a technic I have often used in the past to cover similar challenges (like this post). In Windows, you can configure on a resource level what credential should be used - and that on a per-user level. This also works for the system account and, therefore, also for services. So, we are able to “teach” the system account to use specific credentials to access an Azure storage account. In our case, we need credentials to have full access to an Azure file share. And there are credentials to do that: The storage account credentials. Each storage account has credentials that can be used to have full access. You can grab the credentials from the “Access Key” menu in the storage account: Collect the right values: TypeValueUser name:localhost\&lt;storageAccountName&gt;Secret:&lt;Key&gt;StorageAccountFqdn:&lt;storageAccountName&gt;. file. core. net (the files endpoint)In my example, the user name is “localhost\avdaadstorage” and &lt;StorageAccountFqdn&gt; is “avdaadstorage. file. core. windows. net” To “teach” the system account to use these credentials, we have to run the following command in the context of the system account: cmdkey. exe /add:&lt;StorageAccountFqdn&gt; /user:localhost\&lt;StorageAccountName&gt; /pass:&lt;Key&gt;Example: cmdkey. exe /add:avdaadstorage. file. core. windows. net /user:localhost\avdaadstorage /pass:xxxxxxxxxxxxxxxxAfter running the command on a host/VM, any access in the context of the system account to the storage runs with the configured credentials - to every share! Great, our system can now access the shares on the storage account and has full permission. Window 11 22H2 and Credential Guard with UEFI lock: To prevent that Windows 11 22H2 removes the cmdkey entry if the host is deallocated and started again. The additional registry key is needed: New-ItemProperty -Path &quot;HKLM:\SYSTEM\CurrentControlSet\Control\Lsa&quot; -Name &quot;LsaCfgFlags&quot; -Value 0 -force # Only needed for Windows 11 22H2Remember that this disables Windows Defender Credential Guard. Configuring FSLogix: Next step: Configure FSLogix to use the system account. Normally, FSLogix will access the share to store and read profiles in the user context. That is normally fine if users are able to authenticate with their own identity. In our case, we want to use the system account. The following reg-key configures FSLogix to use the system account: TypeValuePath:HKLM:\SOFTWARE\FSLogix\ProfilesName:AccessNetworkAsComputerObjectType:DWordValue:1This value can be set via registry or PowerShell: New-Item -Path &quot;HKLM:\SOFTWARE&quot; -Name &quot;FSLogix&quot; -ErrorAction IgnoreNew-Item -Path &quot;HKLM:\SOFTWARE\FSLogix&quot; -Name &quot;Profiles&quot; -ErrorAction IgnoreNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;AccessNetworkAsComputerObject&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SYSTEM\CurrentControlSet\Control\Lsa&quot; -Name &quot;LsaCfgFlags&quot; -Value 0 -force # Only needed for Windows 11 22H2If not already done, configure the file share: Create a share on your storage account (e. g. , profiles)Configure FSLogix to use the share on each host:TypeValuePath:HKLM:\SOFTWARE\FSLogix\ProfilesName:VHDLocationsType:Reg_SZValue:\\&lt;StorageAccountFqdn&gt;\&lt;ProfileShareName&gt;And enable FSLogix profile service: TypeValuePath:HKLM:\SOFTWARE\FSLogix\ProfilesName:EnabledType:DWordValue:1After that, users can log in to the hosts, and the profile is stored on the file share on the storage account: Security: How secure is that? Users cannot access their own or other profiles by entering the path to the share while they don’t have the storage account credentials. Users can also not run programs in the system context (if they are not local admins on the host - what I expect). Every local administrator of a host can run processes in the system context: So the local admin permissions/role must be secured to prevent admins from accessing the profile storage indirectly or reading the storage account credentials. Azure Administrator with the permission Microsoft. Compute/virtualMachines/runCommand/action can send scripts running in the system context to a host/VM (like a contributor). That is comparable to local administrator permission. The system has permission to access all shares on the storage account with the credentials. Not only the profile share. It makes sense to have a separate share for the profiles. Summary: Users with non-admin permissions can not access other users’ profiles. Local admins are able to do this, but local admins are able to compromise users in other ways. So local admin privileges should be considered carefully. Same for privileged access in Azure. Do the full configuration with a script: Let me share a script you can use to do the full configuration with a script. In the script, I also set some other basic configurations I mostly use for FSLogix. Keep in mind that the user name is part of the path and profile disk name. If you rename the display name of a user, the user will get a new profile. The script must be executed directly after the rollout of a new host in the system context. It’s not possible to do that on the Master VM while the credential store is reset during sysprep. To run the script in the system context, use PSEXEC to open PowerShell in the system context (psexec /s powershell. exe). WARNING: The script contains a secret. Delete the script from the host write-host &quot;Configuring FSLogix&quot;$fileServer=&quot;avdaadstorage. file. core. windows. net&quot;$profileShare=&quot;\\$($fileServer)\profiles&quot;$user=&quot;localhost\avdaadstorage&quot;$secret=&quot;###################&quot; New-Item -Path &quot;HKLM:\SOFTWARE&quot; -Name &quot;FSLogix&quot; -ErrorAction IgnoreNew-Item -Path &quot;HKLM:\SOFTWARE\FSLogix&quot; -Name &quot;Profiles&quot; -ErrorAction IgnoreNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;Enabled&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;VHDLocations&quot; -Value $profileShare -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;ConcurrentUserSessions&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;DeleteLocalProfileWhenVHDShouldApply&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;FlipFlopProfileDirectoryName&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;IsDynamic&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;KeepLocalDir&quot; -Value 0 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;ProfileType&quot; -Value 0 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;SizeInMBs&quot; -Value 40000 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;VolumeType&quot; -Value &quot;VHDX&quot; -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;AccessNetworkAsComputerObject&quot; -Value 1 -force Store credentials to access the storage accountcmdkey. exe /add:$fileServer /user:$($user) /pass:$($secret) Disable Windows Defender Credential Guard (only needed for Windows 11 22H2)New-ItemProperty -Path &quot;HKLM:\SYSTEM\CurrentControlSet\Control\Lsa&quot; -Name &quot;LsaCfgFlags&quot; -Value 0 -force write-host &quot;The script has finished. &quot; Use Hydra to run the script on-demand or automatically after each rollout: You can use Hydra for Azure Virtual Desktop to apply the script automatically after rolling out a new host. Open the host pool configuration in Hydra -&gt; Base and configure the service account: Service account name: localhost\avdaadstorageService account password: &lt;key of the storage account&gt;Save Scripts and Collections -&gt; Scripts Duplicate an existing script to have a new oneCheck “Service Account”Give it a good name (e. g. , “FSLogix and Cloud Accounts - Hydra integrated”)Copy the following script into the code fieldSaveScript: # Check, if service account availableif ($global:Hydra_ServiceAccount_PSC -eq $null) {  throw &quot;Failed: Service account missing - The script needs a configured service account. You can configure the service account (having full access to the FSLogix profile share on the host pool configuration. &quot;}LogWriter(&quot;Configuring FSLogix&quot;)$fileServer=&quot;avdaadstorage. file. core. windows. net&quot;$profileShare=&quot;\$($fileServer)\profiles&quot; New-Item -Path &quot;HKLM:\SOFTWARE&quot; -Name &quot;FSLogix&quot; -ErrorAction IgnoreNew-Item -Path &quot;HKLM:\SOFTWARE\FSLogix&quot; -Name &quot;Profiles&quot; -ErrorAction IgnoreNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;Enabled&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;VHDLocations&quot; -Value $profileShare -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;ConcurrentUserSessions&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;DeleteLocalProfileWhenVHDShouldApply&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;FlipFlopProfileDirectoryName&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;IsDynamic&quot; -Value 1 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;KeepLocalDir&quot; -Value 0 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;ProfileType&quot; -Value 0 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;SizeInMBs&quot; -Value 40000 -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;VolumeType&quot; -Value &quot;VHDX&quot; -forceNew-ItemProperty -Path &quot;HKLM:\SOFTWARE\FSLogix\Profiles&quot; -Name &quot;AccessNetworkAsComputerObject&quot; -Value 1 -force LogWriter(&quot;Setting credentials to access the storage account of the system&quot;)cmdkey. exe /add:$fileServer /user:$($global:Hydra_ServiceAccount_PSC. UserName) /pass:([System. Net. NetworkCredential]::new(&quot;&quot;,$global:Hydra_ServiceAccount_PSC. password). Password)LogWriter(&quot;Disable Windows Defender Credential Guard (only needed for Windows 11 22H2)&quot;)New-ItemProperty -Path &quot;HKLM:\SYSTEM\CurrentControlSet\Control\Lsa&quot; -Name &quot;LsaCfgFlags&quot; -Value 0 -force OutputWriter(&quot;The script has finished. &quot;) After that, you can trigger the script on a host or let it run automatically after each deployment: Open the host pool configuration in Hydra -&gt; New Session Host RolloutConfigure the rollout parameterSelect the script in “Run script or script collection after deployment” After that a new rollout looks like this: Others: And yes, there are other options to run the script in the system context automatically. Please ensure that the password/secret is not stored on the host’s disk. Hint: You can create another share for MSIX App-Attach packages. The system account also has permission to load the packages. Note: It’s a nice workaround to bridge the time until there is a native solution in Azure. Please use it at your own risk. "
    }, {
    "id": 30,
    "url": "https://blog.itprocloud.de/Automatically-remove-a-computer-object-from-AD-while-removing-a-session-host/",
    "title": "Automatically remove a computer object from AD while removing a session host in AVD",
    "body": "2023/02/21 - With my tools WVDAdmin and Hydra for Azure Virtual Desktop, you can easily manage Azure Virtual Desktop. It also includes the deletion of session hosts and VMs with a single click - or automated. If the host - or computer object - is AD domain-joined, the compute object is usually not deleted and re-used on the next deployment. In some circumstances, it would make sense to also delete the computer object: If you are running the environment hybrid-joined, the orphan computer objects are synced to AAD - even if you delete the AAD device of the computer. To clean up the AD and AAD, I use a script running on the session host shortly before deleting the host (ok, the host must be started to do that). While the script runs on the session host, the host can remove itself easily from Azure AD. To remove it also from AD, a service account is used. You can put a service account to Hydra on a host pool level (Base settings). If the service account has the proper permission to remove the computer object, we can leave both ADs with one script. For that, create a script in Scripts and Collections -&gt; Scrips with the name “Remove computer from AD and AAD”: With the following script (please tick the checkbox “Service Account”): # Each PowerShell script can use internal logging to store logging data to the local disk. The log is stored in %Windir%\System32\LogFiles\Hydra. Logging. logCheck, if service account availableif ($global:Hydra_ServiceAccount_PSC -eq $null) {throw &quot;Failed: Service account missing - The script needs a configured service account. You can configure the service account (having the proper permissions to the OU in the base settings of the pool). &quot;} $outMessage=&quot;Script finished&quot; LogWriter(&quot;Try to remove computer account from domain&quot;) $root = &quot;LDAP://$((Get-WmiObject -Namespace root\cimv2 -Class Win32_ComputerSystem | Select Name, Domain). Domain)&quot;LogWriter(&quot;Domain root is: $root&quot;) $domain = New-Object System. DirectoryServices. DirectoryEntry($root, $global:Hydra_ServiceAccount_PSC. UserName,$global:Hydra_ServiceAccount_PSC. GetNetworkCredential(). Password)$search = New-Object -TypeName System. DirectoryServices. DirectorySearcher($domain) $search. filter = &quot;(&amp;(ObjectCategory=Computer)(ObjectClass=Computer)((cn=$($env:computername))))&quot;$computer=$search. FindOne() if ($computer -eq $null) {$outMessage=&quot;Could find computer object in AD&quot;LogWriter($outMessage)} else {$dnc = $computer. GetDirectoryEntry()LogWriter(&quot;DN of the computer object: $($dnc. Path)&quot;)LogWriter(&quot;Try to remove computer object with user $($global:Hydra_ServiceAccount_PSC. UserName)&quot;) $dnc = $computer. GetDirectoryEntry()$dnc. DeleteTree()LogWriter(&amp;quot;Computer object deleted&amp;quot;)} LogWriter(&quot;Try to remove computer account from AAD&quot;)dsregcmd /leave OutputWriter($outMessage) Do run the script automatically on delete, go to the host pool configuration in Hydra: Base -&gt; Run script or collection on specific events -&gt; On-Delete and select your script If you then delete a host, the computer account in AD and the device in AAD are deleted: "
    }, {
    "id": 31,
    "url": "https://blog.itprocloud.de/Azure-Virtual-Desktop-AAD-Only-hostnames-property-exist/",
    "title": "Azure AD only joined hosts in Azure Virtual Desktop: Join and re-join hosts",
    "body": "2023/01/17 - Azure AD-only joined are getting more common in Azure Virtual Desktop. There are some challenges running AVD hosts as AAD-only. One challenge is that you can roll out a new session host in AAD only if a device with the same name doesn’t exist. In the past, that was possible, but that may be changed over the last few months. If you roll out a new session host with AAD-only integration and a device with the same exist, you get an error message: Another object with the same value for property hostnames already exists. So, if you roll out session hosts after an update of the image again and you try to reuse the names, you have to remove the older - no longer existing devices - from AAD first. To make this a bit easier, I added two options to do this with Hydra for Azure Virtual Desktop in an automated way: If you added the service principal Hydra used to the role “Cloud Device Administrator” and ticked the box “Azure Active Directory: Try to delete old device” in the rollout configuration, Hydra will delete existing devices with the same name from Azure AD. Note: “Cloud Device Administrator” is a highly privileged role. Alternatively, the 2nd option doesn’t need this role. Run a script shortly before deleting a session host to remove the device. Running dsregcmd. exe locally on a device will remove the device from AAD. To automate this, a script collection can be selected in the base settings of the host pool configuration: Run script or collection on specific events -&gt; On-Delete -&gt; Select the collection “BuiltIn: Remove device from Azure Active Directory before deleting host”. The collection moves the host into the drain mode and runs the script shortly before the host is deleted. (Note: If the script collection is not visible, update the build-in scripts by clicking on the update button in the upper right corner of the script menu). The on-delete option can also be used for other aspects. Note: In WVDAdmin the script to remove a host can be triggered with: “Remove device from Azure Active Directory” "
    }, {
    "id": 32,
    "url": "https://blog.itprocloud.de/AVD-Azure-Virtual-Desktop-User-Sessions-Dashboard/",
    "title": "Working interactively with user sessions in Azure Virtual Desktop",
    "body": "2022/12/01 - Handling user sessions in AVD could be more intuitive in the Azure Portal. Luckily, some tools (like WVDAdmin, Hydra, and others) are available to make it easier. I made a new approach without the need to install an application or tool: I published an Angular client application that displays user sessions for Azure Virtual Desktop - including an autorefresh. Additionally, sessions can be disconnected or logged out, or messages can be sent to them. The Angular application runs in the user’s browser and communicates directly with the Azure API. There is no processing of data on the web server. The application runs in the context and with the logged-in user’s permissions (similar to a PowerShell application). The application is automatically terminated when the browser is closed. Feel free to give it a try. Please use the least needed permissions to log in at your own risk. https://avd. itprocloud. com PS: There are no plans to rebuild WVDAdmin or Hydra as an angular application ;-) "
    }, {
    "id": 33,
    "url": "https://blog.itprocloud.de/SYSPREP_and_rollout_deploy_WINDOWS_11_22H2_in_Azure/",
    "title": "Sysprep and deploy Windows 11 22H2 in Azure with a custom image and a workaround",
    "body": "2022/11/10 - A common way to build virtual machines based on an image in Azure (e. g. , as Session hosts for Azure Virtual Desktop) can be done by the “Golden Image” approach. The golden image approach is pretty simple. First install your “Golden Master” Create a VM in Azure (e. g. , Windows 11 multi-session)Install all hotfixes and updatesInstall the applicationOptional: Join a domainTest the applicationIn the next step, create an image from the master Sysprep the Golden MasterCapture the VM in the Azure Portal and create a custom imageOptional: Copy the custom image to an Azure compute gallery to deploy VMs in different locations, subscriptions, and trusted launch VMsThe bad thing is that your Golden Master is destroyed during the sysprep and capturing process. A bit smarter is to do that on a cloned/temporary VM and later delete the clone. WVDAdmin and Hydra for AVD will do this automatically if you create a new custom image. So, you can reuse the Golden Master. But today, deploying Windows 11 22H2 is the main topic. In Windows 11 22H2 is an issue preventing the rollout of new VMs based on a custom image in s specific case: If you create a custom image based on a Golden Master who is or was domain-joined, you cannot roll out a new VM. The rollout will go into a timeout; if you capture a screenshot, you can see the installation screen and a rotating donut. What I figured out. The setup process stops after handling the following task (found in C:\Windows\Panther\setupact. log):ActionPlatform::LaunchModule: Executing method ‘CryptoSysPrep_Specialize’ from C:\Windows\system32\capisp. dllAfter that, no more happens. Also, the ETL files are not showing any process. I guess the process hangs. **I was able to bring it down to this part. For a workaround, I modified the “C:\windows\system32\Sysprep\ActionFiles\Specialize. xml” on the master VM and removed the actions for ‘CryptoSysPrep_Specialize’. ** Specialize. xml is processed by sysprep after a rollout based on an image on this VM. And: It worked. The deployed VMs are running, and the timeout didn’t happen. As a workaround, you can modify the Specialize. xml on the Golden Master and capture the image. After that, you can roll out new VMs based on that image. I added the workaround to WVDAdmin and Hydra for AVD. If Windows 11 22H2 is detected during the imaging process, the Specialize. xml is automatically patched. Additionally, if you roll out new session hosts with one of the tools, capisp. dll with the entry point CryptoSysPrep_Specialize is called during the rollout. Please note that this is a workaround. Follow the stream also on https://learn. microsoft. com/en-us/answers/questions/1027370/windows-11-sysprep-1. html "
    }, {
    "id": 34,
    "url": "https://blog.itprocloud.de/AVD-German-Language-in-AVD-in-West-Europe/",
    "title": "The challenge of having the correct language in the Edge browser with Azure Virtual Desktop in West Europe",
    "body": "2022/09/21 - If you run Azure Virtual Desktop in a data center in another country, you maybe know that the browsers are showing some websites in the data center location language. For example: If you have AVD running in West Europe (Amsterdam, Netherlands), some websites - like Google and Bing - are responding in Dutch. That is often unexpected for users connecting from Germany. The reason is that web servers often use the client’s IP address to guess where the user is connecting. In this case, the client’s IP address is from the host running in Amsterdam and not the IP address of the endpoint in Germany. To workaround this issue, I only found one way: Deploy a web proxy into Germany West Central in a single vnet and use peering to connect the proxy vnet with the vnet hosting your Azure Virtual Desktop session hosts (or use one of the proxy service providers around the world). In my case, I deployed a small Ubuntu VM with Squid as a proxy system. I configured (e. g. , GPO, Intune) Windows to use the proxy in the paired proxy vnet. As expected: Using the proxy over the peered network showed Bing and Google in German instead of Dutch. To do it more professionally, I recommend only redirecting http/https traffic for the browser and configuring the Microsoft Endpoint URLs to use the default way (using a proxy. pac file). Note: Additional costs applied for proxy VMs and inter-region-traffic "
    }, {
    "id": 35,
    "url": "https://blog.itprocloud.de/AVD-Logging-Session-Host-State-and-Sessions-To-LogAnalytics/",
    "title": "Azure Virtual Desktop: Logging session host state to Log Analytics to show state and sessions over time",
    "body": "2022/09/20 - Update October 2022: Check out the following Workbook to use diagnostic logging to get and visualize the data I had some presentations over the last weeks where I showed how to create images with PowerShell and how to deploy these images as new session hosts - also with PowerShell. Additionally, I showed how to log the state of the Azure Virtual Desktop session hosts each minute to a log analytics workspace. This post covers the why and how. Today, you can manage Azure Virtual Desktop differently (Portal, PowerShell, WVDAdmin, Hydra for AVD, etc. ). Also, monitoring is covered using Azure Monitor and the Diagnostic Logging, and my free Workbook. But some parts are missing regarding monitoring: If you want to show available hosts and sessions over time (e. g. , for the last month), you have no native solution. Also, the state of a specific host at any time would be interesting to find issues in the past. But it’s easy to solve. You can do the following steps with PowerShell to store this data in a Log Analytics workspace: Each minute: Query all host pools in a resource groupRead the session hosts objects of each poolExtend a property to the session hosts with the current timestamp (do not rely on the generated timestamp to later group the hosts in time)Upload the data to Log AnalyticsThe most efficient and economical way is to use an Azure Function. The function can be used to trigger the script each minute. To do it more professional, we can build this solution with a few Azure resources: Azure Function for the PowerShell scriptAzure Key Vault to store the Log Analytics workspace id and keyA new or existing Log Analytics workspaceCreate or select a Log Analytics workspace: You can create a new Log Analytics workspace to store the data or you can use an existing one. If you have done this, copy the WorkspaceId and WorkspaceKey (primary key) for later use (can be found in Agents Management -&gt; Log Analytics agent instructions).  Create an Azure Key Vault: Create a standard Key Vault and add two secrets to the vault: WorkspaceId, containing the WorkspaceId of the Log Analytics workspaceWorkspaceKey, containing the WorkspaceKey of the Log Analytics workspace Configuring the Azure Function: Rollout a new Azure Function with a consumption plan (or an existing App Service Plan). Open the function -&gt; Identity and set the “System assigned” identity to on. This creates immediatily an identity for the Azure Function to give the Function permission to access the Key Vault and the Host Pool/resource group containing the host pools. In functions, select create -&gt; Time Trigger and set the time trigger to “*/60 * * * * *” to run the script each minute. Give the function a good name. In “code”, insert the content of run. ps1. Modify line 28 and insert the name of the resource group of your host pools.  In the Function -&gt; App Files, copy the content from https://gist. github. com/MarcelMeurer/8347eb527a6fdb4839ee428bf0e6eee0 to the files “requierements. psd1” and “profile. ps1”. That is needed to load the Azure modules of AVD and the authentication with the managed identity. Finally, open configuration in the Azure Function, and create new application settings: WorkspaceId: @Microsoft. KeyVault(SecretUri=https://xxxx. vault. azure. net/secrets/WorkspaceId/)WorkspaceKey: @Microsoft. KeyVault(SecretUri=https://xxxx. vault. azure. net/secrets/WorkspaceKey/)Use the correct URL to reflect the correct Key Vault Do give the Azure Function permission to read the secrets, open the Key Vault again and go to: Access configuration -&gt; Go to access policies and create new permission with “Secret Get” for the identity of the function (use the name of the function to find the identity). Go to the resource group containing your host pools -&gt; Access Control -&gt; Add role assignment: Add the role “Desktop Virtualization Host Pool Reader” for the member “Managed Identity” and the name of the Azure Function. If everything is working fine, the first data are written to the Log Analytics workspace. You can check the output of the function in Monitor: It takes one time a couple of minutes to build the data schema in Log Analytics. After that, a new table is shown in Logs: To start showing some data, we can run the following Kusto queries to show the data: Queries: // sessions per host pool over timeAvdBehind_v2_CL| extend HostPool=tostring(split(Id_s,&quot;/&quot;)[8])| summarize sum(Session_d) by HostPool, TimeGenerated| render timechart// available hosts per pool over timeAvdBehind_v2_CL| extend HostPool=tostring(split(Id_s,&quot;/&quot;)[8])| where Status_s=~&quot;Available&quot;| summarize count() by HostPool, TimeGenerated| render timechart // assigned hosts by state (now)AvdBehind_v2_CL| extend HostPool=tostring(split(Id_s,&quot;/&quot;)[8])| summarize arg_max(TimeGenerated,*) by Id_s  // get the newest data set by resource id of the session hosts| where AssignedUser_s !=&quot;&quot;| project HostPool, SessionHost=Name_s, AssignedUser_s // # hosts by state (now)AvdBehind_v2_CL| extend HostPool=tostring(split(Id_s,&quot;/&quot;)[8])| summarize arg_max(TimeGenerated,*) by Id_s  // get the newest data set by resource id of the session hosts| summarize Count=count() by Status=Status_s,HostPool| project HostPool, Status, Count Let me know if everything is working as expected or if it makes sense to create a “Deploy to Azure Button” to deploy the solution. "
    }, {
    "id": 36,
    "url": "https://blog.itprocloud.de/Azure-Virtual-Desktop-with-ADE-Azure-Disk-Encryption-Session-Host/",
    "title": "Azure Virtual Desktop Session Hosts with Azure Disk Encryption",
    "body": "2022/08/30 - Hydra for Azure Virtual Desktop and WVDAdmin are supporting ADE for AVD Session Hosts. Azure Disk Encryption (ADE) encrypts the OS and data disks of Azure virtual machines (VMs) inside your VMs by using BitLocker. ADE cannot be combined with a disk encryption set. To roll out session hosts with ADE in Hydra, some resources must be prepared to work: Azure Key Vault with an encryption key, and Azure Key Vault to store the secrets of the disks (can be the same vault) First, create a Key Vault in the Azure PortalGive the service principal (from the tenant configuration) contributor permission to the vault (access and control)In Access Policies, give the service principal the following permissions:– Key permissions: Get, Encrypt, Wrap Key– Secret permissions: SetCheck the boxes: Azure Virtual Machines for deployment and Azure Disk Encryption for volume encryptionGive yourself permissions: Key and secret managementGo to Keys and click on Generate. Type a name and select RSA and 2048Click on the generate key and on the current version. Copy the Key identifier (must include the version). E. g. , https://. vault. azure. net/keys/ADE-Encryption/bf270e977a574813a87bb637d57a6675In Hydra, configure “New Session Host Rollout”:In “Advanced settings” select the Key Vault in ADE Key VaultCopy the Key Identifier to ADE Encryption Key Url Do a deployment to verify that the disk is ADE encrypted: To rollout hosts with ADE with WVDAdmin, add tags to the host pool: WVD. Default. KeyVault. Id: resource id of the KeyVault (/subscriptions//resourceGroups//providers/Microsoft. KeyVault/vaults/)WVD. Default. KeyVault. KeyUri: key for the vaul (https://. vault. azure. net/keys/ADE-Encryption/bf270e977a574813a87bb637d57a6675) "
    }, {
    "id": 37,
    "url": "https://blog.itprocloud.de/Azure-AD-Connect-Auto-Sync-On-Device-Add-or-Change-Powershell/",
    "title": "Automatically add or change Azure Active Directory computer objects on-demand",
    "body": "2022/07/28 - Hybrid joined AVD session hosts are great for working with conditional access, Intune (MEM), access to Azure files, and other AAD integrated services. But there are some challenges: One challenge is that it takes a while to see new session hosts after the deployment in AAD - which avoids that AAD services (like ca) can be used directly. One reason for the delay is that AD objects are synced every 30 minutes by default using ADConnect. In the worst case, it takes 30 minutes before the computer object is visible in AAD. My approach to lowering the delay is to pimp ADConnect with a custom PowerShell tool (SyncOnDemand. ps1): The tool checks every 3 seconds for computer objects in AD. The tool triggers ADConnect to start a differential sync if a computer object is new or updated after the last 30 minutes. To avoid the sync being triggered for the same computer object multiple times, already detected computer objects are ignored for the next 30 minutes. This should bring down the time for a host before the host is also visible in AAD. How does it work? Copy the script to the ADConnect server. Modify line 31 ($OuPath = …) to match your OU and domain. Run the script in an administrative PowerShell. The script checks every 3 seconds for changed computer objects. Change one of the computer objects in the right OU to test it (e. g. , change the description). The script detects the change and triggers a delta sync to AAD. If everything works as expected, you can install the script with: SyncOnDemand. ps1 -InstallThat creates a scheduled task to run the script on the startup of the ADConnect server. The scheduled task is started directly and runs in the background. Update: To speed up the replication between AD sites, you can use (“Use Notify”)[https://social. technet. microsoft. com/wiki/contents/articles/16929. set-active-directory-to-use-notify-replication. aspx] Note: This is a workaround. Use at your own risk Script (must be run as an administrator): param(  [Parameter(Mandatory=$false)]  [Switch]$Install)[Net. ServicePointManager]::SecurityProtocol = [Net. SecurityProtocolType]::Tls12if ($Install) {Write-Host &quot;Installing script to $env:windir&quot;Copy-Item &quot;$($MyInvocation. InvocationName)&quot; -Destination (&quot;$($env:windir)\SyncOnDemand. ps1&quot;) $action = New-ScheduledTaskAction -Execute &amp;quot;$env:windir\System32\WindowsPowerShell\v1. 0\Powershell. exe&amp;quot; -Argument &amp;quot;-executionPolicy Unrestricted -File `&amp;quot;$($env:windir)\SyncOnDemand. ps1`&amp;quot;&amp;quot;$trigger = New-ScheduledTaskTrigger	-AtStartup$principal = New-ScheduledTaskPrincipal 'NT Authority\SYSTEM'$settingsSet = New-ScheduledTaskSettingsSet$settingsSet. Enabled=$true#$settingsSet. IdleSettings. IdleDuration=0$settingsSet. StopIfGoingOnBatteries=$false$settingsSet. DisallowStartIfOnBatteries=$false$settingsSet. ExecutionTimeLimit=&amp;quot;PT0H&amp;quot;$task = New-ScheduledTask -Action $action -Principal $principal -Trigger $trigger -Settings $settingsSet Register-ScheduledTask -TaskName 'ITPC-ADConnect-OnDemand' -InputObject $task -ErrorAction Ignore | Out-NullStart-ScheduledTask -TaskName 'ITPC-ADConnect-OnDemand'Write-Host &amp;quot;Starting the task&amp;quot;return} Parameter$OuPath = &quot;LDAP://OU=Servers,OU=Sys,OU=Organisation,DC=ITProCloud,DC=test&quot;$AcceptChangesForTheLastMinutes=30$RunEachSeconds = 3 Initialize$cycle = Get-Date$table=@{} try {Get-ADSyncScheduler | Out-Null} catch {Write-Error &quot;Command Get-ADSyncScheduler not exist. Please check your configuration. This script must run on a computer with AD-Connect installed&quot;return} do {$lastStart = Get-Date$dt=($lastStart. AddMinutes(-$AcceptChangesForTheLastMinutes)). ToUniversalTime(). ToString(&quot;yyyyMMddHHmmss. 0Z&quot;)$newObjects=0# cleanup ignore-list$table. clone(). GetEnumerator() | foreach {if ($. Value -le $lastStart. AddMinutes(-$AcceptChangesForTheLastMinutes)) {Write-Host &quot;Removing computer from the ignore-list: $($. Name)&quot;$table. Remove($_. Name)}} $search=[adsisearcher]&amp;quot;(&amp;amp;(ObjectCategory=computer)(|(whenchanged&amp;gt;=$dt)(whencreated&amp;gt;=$dt)))&amp;quot;$search. SearchScope = &amp;quot;Subtree&amp;quot;$search. PageSize=150000$search. SearchRoot = $OuPath$obj2=$search. FindAll()Write-Host &amp;quot;Computer objects found: $($obj2. Count)&amp;quot;$obj2 | foreach {  $le=$table[$_. Path]  if ($le -eq $null) {    $table. Add($_. Path,$lastStart)    Write-Host &amp;quot;Found an updated computer: $($_. Path)&amp;quot;    $newObjects++  } else {    Write-Host &amp;quot;Skipping computer while object is in the ignore-list for a while: $($_. Path)&amp;quot;  }}Write-Host &amp;quot;Ignore list: $($table. Count)&amp;quot;Write-Host &amp;quot;New objects: $newObjects&amp;quot;if ($newObjects -gt 0) {  Write-Host &amp;quot;Starting delta sync&amp;quot;  try {    do {      Sleep -Seconds 1    } while ((Get-ADSyncScheduler). SyncCycleInProgress)    Start-ADSyncSyncCycle -PolicyType Delta | Out-Null  } catch {    Write-Error &amp;quot;Delta sync failed&amp;quot;    $table=@{}  }  do {    Sleep -Seconds 1  } while ((Get-ADSyncScheduler). SyncCycleInProgress)  Write-Host &amp;quot;Delta sync done&amp;quot;}Write-Host &amp;quot;Waiting for the next cycle&amp;quot;Write-HostSleep -Seconds $RunEachSeconds} while ($true) "
    }, {
    "id": 38,
    "url": "https://blog.itprocloud.de/Honey-Pot-in-Azure-and-Unfavorable-Account-Names-Login-RDP/",
    "title": "Honey-Potting in Azure and Unfavorable Account Names",
    "body": "2022/07/07 - As everybody knows, running a Windows system in Azure unprotected is not a good idea. To get access to an Azure VM, Azure Bastion or VPN are recommended. But what happens if you deploy a Windows VM in Azure with an unprotected public IP? Several bots try to log on to get access to the VM. For an experiment, I deployed a test VM to Azure with the public IP (my honey pot) to see what happens. Additionally, I wrote a short PowerShell script to search the security log for the logon attempts to get information about the used login names. It is interesting and good to avoid the (sometimes) common terms. Script (must be run as a local administrator): $table=@{}$ev=Get-EventLog -LogName Security -InstanceId 4625$ev | foreach {$user=$_. ReplacementStrings[5]$le=$table[$user]if ($le -eq $null) {$table. Add($user,1)} else {$table[$user]=$le+1}}Write-Host &quot;FAILED LOGONS&quot;Write-Host &quot;===========================================================&quot;$table. GetEnumerator() | sort Value -Descending $table=@{}$ev=Get-EventLog -LogName Security -InstanceId 4624$ev | foreach {$user=$_. ReplacementStrings[5]$le=$table[$user]if ($le -eq $null) {$table. Add($user,1)} else {$table[$user]=$le+1}}Write-Host &quot;SUCCESSFUL LOGONS&quot;Write-Host &quot;===========================================================&quot;$table. GetEnumerator() | sort Value -Descending Here is the list of login attempts: "
    }, {
    "id": 39,
    "url": "https://blog.itprocloud.de/Securing-an-app-service,-a-key-vault,-and-a-database-with-private-endpoints/",
    "title": "Securing an app service, a key vault, and a database with private endpoints",
    "body": "2022/05/30 - A typical Azure application uses an app service representing the front end, a database to store the data and configuration settings, and a key vault to keep secrets (like the connection string to the database). Kommunikation is done encrypted, and the app service has to authenticate to the vault (mostly done via managed identity) and to the database (often done with a connection string). The key vaults and database endpoints are reachable over the public internet. The strong authentication from the app services ensures that the app service gets access. In some cases, it’s mandatory to avoid public access to the vault and the database. Luckily, that can be easily done using private endpoints in Azure. Neither the application nor the configuration of the application needs to be adjusted. So, we can increase the security of any Azure app working with a vault and database (Azure SQL as a service). I recorded a short video to show the steps. Watch it to the end and avoid my mistake of putting the full IP-range into one subnet (you need two subnets: one for the vault and database and another for the app service). Check out the video on Youtube: How to secure the database and key vault of an app service / web app in Azure "
    }, {
    "id": 40,
    "url": "https://blog.itprocloud.de/AVD-Azure-Trusted-Launch-and-Custom-Images/",
    "title": "Azure Trusted Launch and Custom Images - even for AVD",
    "body": "2022/05/13 - Trusted launch for Azure virtual machines is currently in public preview (https://docs. microsoft. com/en-us/azure/virtual-machines/trusted-launch). The trusted launch has some benefits, like: Securely deploy virtual machines with verified boot loaders, OS kernels, and drivers. Securely protect keys, certificates, and secrets in virtual machines. Gain insights and confidence in the entire boot chain’s integrity. Ensure workloads are trusted and verifiable. (Source: Microsoft website) Technology-based, the trusted launch cannot be activated on existing VMs. Additionally, the VM size must support this feature. More importantly, a trusted launch VM can only be created from vanilla Microsoft Marketplace images. Deployment from a custom image is not working and is not supported. Update 20/01/2022: A native and supported process to rollout VMs and session hosts based on a custom image is expected in Feburary 2022 and will be added to WVDAdmin and Hydra to show on Hydras’ Update 13/05/2022: You can enable “Secure Boot” for marketplace images and for Custom Images in an Azure Compute Gallery (configure the VM image definition to support Secure Boot before copying a captured image to the gallery definition). #WVDAdmin and #Hydra are supporting this new feature right now Check out the video on Youtube: Deploy secure boot-enabled custom images as AVD session hosts If you use the current version of #WVDAdmin or #Hydra you can skip the next part That’s not pretty, while in AVD, most deployments are based on images from Golden Masters. That is also the approach I’m using with my solutions (like WVDAdmin): Rolling out a Windows 10/11 VMDomain join the VMUpdate the VM and install applicationsGrabbing an image (with WVDAdmin, the Master survives)Rolling out session hosts based on the imageI spent some time finding a workaround for deploying session hosts based on a Golden Master with secure boot enabled. I was successful, and I built this as an experimental feature into WVDAdmin (v1. 7. 20). How does it work: Preparing the Golden Master Rolling out a Windows 10/11 VM from the marketplace and configuring the secure boot featureDomain join the VMUpdate the VM and install applicationsShutdown the VMCreating session hosts from the Master Navigate in WVDAdmin to the VM (Azure -&gt; Virtual Machines -&gt; Resource Group -&gt; VM)Right-click the VM and select: “Instantly build session hosts (experimental)”Configure the settings for the deployment (VM size, host pool, etc. )Start the rolloutAfter a while, session hosts with secure boot enabled are part of the host pool. While the rollout process is more complex, it will take longer than the classic approach (the new approach is based on a snap-shot technology).   Note: This feature is very experimental, and I’m looking forward to a native and supported way to deploy secure boot hosts based on a custom image. Please use it at your own risk. Note: If anybody finds an easier way - please let me know "
    }, {
    "id": 41,
    "url": "https://blog.itprocloud.de/Windows-Virtual-Desktop-Windows-Virtual-Desktop-Administration-for-CSP-and-Consulting-Partners/",
    "title": "WVDAdmin - Azure Windows Virtual Desktop Administration for CSP and Consulting Partners",
    "body": "2022/03/17 - Azure Windows Virtual Desktop Administration for CSP and Consulting PartnersLast year I released my windows-based GUI for administrating WVD/AVD to the community called WVDAdmin. I had a bunch of updates to share more features. This week I will release version 1. 3. 0 with will add another feature, especially for providers and consulting companies. From version 1. 3. 0 WVDAdmin will support a multi-AAD-tenancy mode allowing to switch the Azure AD tenant very easily.  To enable the multi-AAD-tenancy mode, you must set a registry key. Add the following dword32 to your registry: >HKEY_CURRENT_USER\Software\ITProCloud\WVDAdminName:	AadMultiTenantType:	DWORD32Value:	1 (or 0 to disable this mode) If you start WVDAdmin with this setting, a drop-down list will be visible at the welcome screen (see above). If you save a new service principal configuration, it happens to the drop-down list with the friendly name. All other settings for the image creation or rollout of new session hosts are saved to the context of the selected AAD tenant. The authentication settings and other settings are saved in different trees in the registry starting from HKEY_CURRENT_USER\Software\ITProCloud\WVDAdmin\AadMultiTenantIf you had already used WVDAdmin in the “normal” mode, you could copy the settings from the root of the registry path to the new path for your AAD tenant. To delete a no longer needed AAD-tenant in WVDAdmin, remove the registry key of this one.  Don’t change the AAD tenant while an operation is in progress. This could result in an error. If you change the AAD tenant, click “Reload all” to read the configuration for the new tenant. The AAD multi-tenancy mode helps a lot if you have (like me) multiple clients you are working with. Feel free to use it and download the 64-bit Windows application “WVDAdmin” (AVDAdmin) from here: WVDAdmin Preview Update from version 1. 7. 34. 0: You can use a custom script file for imaging and deployment in the program files folder of WVDAdmin (optionally). Place a copy in the program files folder with the AAD tenant friendly name like this (v7 is the current highest version and itprocloud. de the friendly tenant name):ITPC-WVD-Image-Processing. itprocloud. de. v7. ps1 Read the original blog post about WVDAdmin here: https://blog. itprocloud. de/Windows-Virtual-Desktop-Admin "
    }, {
    "id": 42,
    "url": "https://blog.itprocloud.de/AVD-Azure-Monitor-Connection-Errors-With-Notification-KUSTO/",
    "title": "Get alerted if Azure Virtual Desktop fails - AVD Monitoring and alerting with Loganalytics / Azure Monitor",
    "body": "2022/01/19 - Monitoring Azure Virtual Desktop is important to get insights into the performance and resource usage and alert if something generally goes wrong. Especially, getting alerted if something goes wrong is essential - independent from the cause. If I get an alert, I can directly start to find the root cause and resolve or workaround it. For that reason, I implement a general alerting in my projects. And that is very easy: I measure specific error messages from the AVD platform service and send an alert if the number of errors exceeds a particular limit (e. g. , &gt;5 error messages per 10 minutes). Important to know is that not all error messages in the platform service are “errors”. For example, Microsoft records the disconnection of a session as an error (ConnectionFailedClientDisconnect) - what happens very often in the evening. Other examples are AuthenticationLogonFailed, PasswordExpired, and much more. We have to exclude the non-issue error messages and count the others for an alert. If we have done this, we are alerted in many cases - independent of the root cause. These could be: Autoscaling or Power-On-Connect is not working for reasons (ConnectionFailedNoHealthyRdshAvailable)Automatic deployment of session hosts is not working (ConnectionFailedNoHealthyRdshAvailable)Domain Controller not reachable or computer object was overwritten (ConnectionFailedAdTrustedRelationshipFailure)Session Host is not available - maybe a broken resource id (SessionHostResourceNotAvailable)Orphan sessions (ConnectionFailedUserHasValidSessionButRdshIsUnhealthy)…This alerting helped me a lot in the past to get notified when a problem occurs (especially in the morning if many people try to log on ;-). Build the alert: First, configure all host pools’ diagnostic settings to store their logs into a log analytics workspace: Alternatively, you can use WVDAdmin to do that: Open the log analytics workspace -&gt; Alerts and create an action group. Action groups are used to define what should happen in an alert. In our case, we configure to get alerted by mail. Give the action group a name: Configure the notification type, including the recipients of the mail: Configure the alert. Select “Log Query” to enter a custom search query to filter for the errors causing issues. Use the following parameters:Query: >WVDErrors | where not(CodeSymbolic in~(&quot;ActivityTimeout&quot;,&quot;ConnectionFailedClientDisconnect&quot;,&quot;SavedCredentialsNotAllowed&quot;,&quot;ConnectionBrokenMissedHeartbeatThresholdExceeded&quot;,&quot;AuthenticationLogonFailed&quot;,&quot;FreshCredsRequired&quot;,&quot;CM_ERR_MISSED_HEARTBEAT_THRESHOLD_EXCEEDED&quot;,&quot;NL_DISCONNECT_ERROR&quot;,&quot;PasswordExpired&quot;,&quot;AccountLockedOut&quot;,&quot;AccountExpired&quot;,&quot;InvalidCredentials&quot;,&quot;AutoReconnectNoCookie&quot;,&quot;LogonFailed&quot;))FieldValueMeasureTable rowsAggregation typeCountAggregation granularity10Alert logicGreater thanThreshold5Frequency of evaluation10 minutesThis configuration sends an alert if the number of filtered errors is higher than five over the last 10 minutes. Correct this for your environment (threshold and maybe exclude other non-issue errors): Add the action group: Give the alert rule a severity and a name: Done.  If an alert is triggered, you will get a mail like this: I plan to have this alerting soon available in Hydra to show on Hydras’ dashboard if host pools are having trouble. Tip: You can count all the errors in your environment with a KUSTO query. This is very useful to figure out other non-issue error messages: WVDErrors| summarize count() by CodeSymbolic, Message| order by count_ desc"
    }, {
    "id": 43,
    "url": "https://blog.itprocloud.de/AVD-Reserved-Instance-or-scaling-Copy/",
    "title": "Azure Virtual Desktop: Reserved Instances or Scaling",
    "body": "2021/12/13 - A while ago, I wrote a blog post about saving money by smartly switching the disk types of Azure VMs. But what’s about using reserved instances instead of switching VMs on or off (autoscaling)? I used the same data as in the previews blog post to figure out the best amount of reserved instances for this specific customer environment. The charts below show the data of a host pool for seven days. Less load on the weekend and more than 400 user sessions on the weekdays: The maximum number of running hosts was 89 on Thursday. The VM types are D4 v4, and the current costs in west europe for one hour are: Pay-as-you-go: € 0. 201315Reserved (1y): € 0. 121219Reserved (3y): € 0. 078055 I calculated the costs for this week for different numbers of reserved instances: From 0% to 100% in 5% steps. The results are surprising: The best value is with 5% reserved instances: €   981. 77 The best value is with 25% reserved instances: €   886. 42 So, in this case, 25% reserved instances (23 hosts) are an excellent way to go. But it can change from customer to customer even if people work in a shift. "
    }, {
    "id": 44,
    "url": "https://blog.itprocloud.de/How-to-use-MSIX-AppAttach-without-having-computer-accounts-synced-for-Azure-Virtual-Desktop-AD-synced-Azure-Files/",
    "title": "How to use MSIX AppAttach without having computer accounts synced for Azure Virtual Desktop (AD synced and Azure Files)",
    "body": "2021/11/26 - Using MSIX AppAttach in Azure Virtual Desktop is great. To stage the MSIX AppAttach packages, the session host needs permission to read the package. If the package is placed on a “normal” file server, everything works as expected. But if the image on an Azure Files share, it would not work directly. In this case, the computer object has no permission to read data. You got the following error message: SessionHost unhealthy: The following MSIX packages have failed to properly stage: [xxxxxxxxxxxx_yyyyyy, System. IO. FileNotFoundException: File not found. The default approach: Add the AVD computer objects in a global groupSync the group and the computer objects for the hostsAdd the group with the RBAC Role “Storage File Data SMB Share Contributor” to the file share or storage accountGive the global group NTFS read permissionAfter that, the hosts can access with their computer account the share. The disadvantage is that if you deploy a new host, you have to add the computer object to the group and wait for the synchronization to AAD (for the group and the computer object). Meanwhile, the host cannot stage the package and cannot provide the application to the users :-( Another approach or workaround: The issue is that the computer/system account cannot access the share. Another approach is to convince the system account to use a domain user for accessing Azure Files. Create a user account in AD and wait for replicationAdd the user with the RBAC Role “Storage File Data SMB Share Contributor” to the file share or storage accountGive the user NTFS read permissionTo convince the system account to use a specific user account accessing a specific Azure Files storage account. That can be tested with these two lines: psexec -s cmdcmdkey /add:wvdmsixdata. file. core. windows. net /user:msix@itprocloud. de /pass:passwordOfMsixUser Now, every time the host access wvdmsixdata. file. core. windows. net in the system context, the named user account is used - even for staging the MSIX AppAttach packages. This step can be automized via a script directly after the rollout of a new session host. This allows the host to stage the packages directly. You could use WVDAdmin, modify the deployment script, and run the cmdkey part after the domain join (psexec is not needed). Another way to go is using Hydra with a script after the deployment. In this case, you could use the service account on a host pool level. Example script: # Check, if service account is availableif ($global:Hydra_ServiceAccount_PSC -eq $null) { throw  Failed: Service account missing - The script needs a configured service account.  }$fileServer=“wvdmsixdata. file. core. windows. net” $secret=[System. Net. NetworkCredential]::new(””,$($global:Hydra_ServiceAccount_PSC. Password)). Passwordcmdkey. exe /add:$fileServer /user:$($global:Hydra_ServiceAccount_PSC. UserName) /pass:$($secret) $count=(Get-ChildItem ”\wvduserdata. file. core. windows. net\msix”). CountOutputWriter(“The script has finished. Existing files: $count”) Note: This is a workaround!Make sure that the users’ password does not expire. "
    }, {
    "id": 45,
    "url": "https://blog.itprocloud.de/Upcoming-features-of-Hydra-or-other-3rd-AVD-solutions/",
    "title": "Directly connect session hosts with a 3rd party management environment",
    "body": "2021/11/17 - While working with Azure Virtual Desktop, I still miss some features that seem unavailable through Microsoft or maybe a 3rd party vendor. One of the features is that an admin/helpdesk can see the users’ processes, CPU, and memory usage and terminate a hanging or crazy process. To build this feature, a fast connection to the session host from the management platform (in my case, Hydra) is needed. The approach using the RunCommandExtension is not fast enough and doesn’t allow duplex communication. While web-based management platforms normally do not have a direct IP connection to the session hosts, the typical remote administration approaches won’t work. Therefore, I see no other way to have a small agent running on the session hosts connecting to the web-based management platform. One approach is that the agents connect via https to the management platform - the better way is using Web-Sockets to connect. Websockets (WS) are faster and scale better than sending an http-request each second from each host to the platform. WS also directly supports a communication strategy. In the preview version of Hydra, the agents connect securely (via a secret) to the platform and identify themselves via the FQDN and VM resource Id. That allows being referenced as a session host as well. In my case, only the platform can ask the client (session host). For that, I build several classes. In each case, the platform asked a specific client for information (GetProcessList for session “2”), and the client response after a short time with the data (SetProcessList and SessionHostProcess[] as JSON in the content property). For this example, asking for the process list is initiated by a management platform admin with the right permissions. The admin can also initiate a kill process to stop a process. While this works fast, the process list can be refreshed every few seconds automatically and shown on the website of the management platform. The fast communication between the platform and session hosts allows additional or improved features: Showing CPU/MEM per session host faster than using the Azure API (Azure agent) A general fast monitoring De-prioritized processes Fast chat with the user Improve scaling: Avoid logging off a disconnected session if a particular application is running (Excel, SAP - may be based on the CPU usage) Improve scaling: Avoid logoff VIP users Get more data from the native AD via this connection Join computer objects fast into groups in a native AD Trigger a garbage collector Running scripts on the hosts - concurrently with duplex communication (to show a now written log file) Configure application Get data about FSLogix issues Get data about FSLogix disk sizes … Using WS makes a solution more flexible and avoids the limits of the RunCommandAPI. The price for this is another agent (not a service), which must be deployed during the rollout or afterward. From the first researches and implementation, there is no low limit regarding the number of hosts. The current version of Hydra has the preview feature (to be released) showing the process list if an admin clicks on the user name in the session list. While this feature is in preview, test users must ask to switch on this feature for a specific Hydra instance). Check out the video on YouTube: https://youtu. be/aNiNbEukVVc The final question: Are the features worth that an agent is needed? Update from 4/1/2022: Using an agent would be perfect to manage Windows 365 as well. W365 is missing some API to work directly with the VM (like the RunCommandAPI). An agent would solve the missing APIs and would allows to manage W365 users and hosts with some features mentioned above. First classes for the duplex-communication: public class Communication {​  public CommunicationType Type { get; set; }​  public string Content { get; set; } }public enum CommunicationType{​  GetHostIdentifier,​  SetHostIdentifier,​  GetProcessList,​  SetProcessList,​	KillProcess,} public class HostIdentifier{​  public string SessionHostResourceId { get; set; }} public class SessionHostProcess{​  public int ProcesId { get; set; }​  public string Caption{ get; set; }​  public int SessionId { get; set; }​  public long WorkingSet { get; set; }​  public double CpuPercent{ get; set; }} "
    }, {
    "id": 46,
    "url": "https://blog.itprocloud.de/AVD-and-error-SessionHost-unhealthy-SxsStack-listener-is-not-ready-Code-2147467259/",
    "title": "AVD issue: SessionHost unhealthy SxsStack listener is not ready - Code -2147467259",
    "body": "2021/11/16 - A few days ago, I got an email from a customer concerning that a lot of Azure Virtual Desktop (AVD) session hosts showing an error message from the internal health check: SessionHost unhealthy SxSStack listener is not ready - Code -2147467259 Unfortunately, there was no failed event log from the WVDAgent in the application log. But the RemoteDesktopServices log shows some issues with the SxSStack as expected. Reinstalling the AVD agents doesn’t resolve the issue. But we found an easier way to bring the hosts back to life: Uninstalling the SxS Stack package and rebooting the host. We used PowerShell to create a single-line script and Hydra to execute it on all affected session host: Uninstall-Package -Name &quot;Remote Desktop Services SxS Network Stack&quot; -AllVersions -Force The short script can be deployed with #WVDAdmin, #Hydra, or any other solution having access to the hosts. "
    }, {
    "id": 47,
    "url": "https://blog.itprocloud.de/Save-money-while-changing-disk-type-on-demand-with-Hydra-AVD/",
    "title": "Why switching disk types can save a bunch of money running Azure Virtual Desktop",
    "body": "2021/11/13 - In March 2021, I introduced a new feature for #WVDAdmin to change the disk type of a VM to automatically change the disk type before starting a VM and after the deallocation of a VM. The purpose was clear: Having a more expensive high-performance disk for the runtime of a VM and a cheap disk while the VM is off. This is especially important because hard disks always cost - regardless of whether the associated VM is on or off. The implementation was straightforward, while changing the disk type takes only a few seconds. I guess that Microsoft only regulates the performance of disks and is not copying the disks from one storage to another. I use the same feature in my #AVD solution, “Hydra”. If configured, Hydra changes the disk type on start and stop, triggered by an administrator or Hydras’ autoscaling. But what does this saves in a real-world scenario? I used the data from a deployment serving more than 400 concurrent users per day. The charts below show the data of a host pool for seven days. Less load on the weekend and more than 400 user sessions on the weekdays: The maximum number of running hosts was 89 on Thursday. So I have at least 89 disks for the hosts. 89 exiting disks for seven days results that I have to pay for 14,952 hours of disks (89 disks * 24h/day * 7day). As known, it makes a difference if you have to pay for cheap HDD or high-performance Premium Disks like recommended for AVD. Today the costs of a 128 GByte managed disk are: HHD5. 04 € per month0. 007 € per hour (with 30 days a month)Premium18. 70 € per month0. 025972 € per hour (with 30 days a month)If all of the 89 hosts in the pool use Premium Disks, the customer must pay 388. 34 € a week. We know that not all hosts are running 24h, which means that even the disks are not Premium the whole time. With log analytics, we can measure the runtime in hours overall hosts in the pool: For the whole week, the runtime for the hosts (and Premium Disks) was 4,998 hours. The rest of the time, the disks type are the cheaper HHD. With this number we can calculate the real disk costs for the pool for a week: 4,998h * 0. 025972 €/h + (14,952h - 4,998h) * 0. 007 €/h = 199. 49 € a week. And that is more than interesting: In this real case scenario, the customer only saves at least 188. 85 € a week for the disks - more then 800 € a month. That is tremendous and results in a saving of 49%. PS: The saving is higher while more than 89 hosts are in the pool to handle more users. Additional strategies to save money while using AVD: Automatic provisioning of new hosts in the morning to handle the first logon storm (scheduled)Usage of ephemeral disksCheck-out Hydra: Azure Marketplace "
    }, {
    "id": 48,
    "url": "https://blog.itprocloud.de/The-secret-about-disappearing-appx-UWP-applications-in-an-environment-using-FSLogix/",
    "title": "The secret about disappearing appx / UWP applications in an environment using FSLogix",
    "body": "2021/10/20 - Intro: A few weeks ago, a customer told me about a particular behavior in their Azure Virtual Desktop environment. The users are using a dedicated session host, and the profile is managed with FSLogix to save user data on a file server additionally. Some of the users install applications from the Windows Store (Appx, Universal Apps). If the user logs off at the end of the day and logs in the next day, the applications are gone, and only a dead item is left in the start menu. The users have to install the app again from the Windows Store. Luckily, the applications settings are in the user profiles, so the applications are still configured after reinstallation. What does this cause? If a user installs an application from the Windows Store, the binaries are saved in “C:\Program Files\WindowsApps”. If the user logs off in a non-FSLogix environment, the users’ profile stays on the computer and binaries as well. If the user logs off in an FSLogix environment, the users’ profile is removed from the computer. While apparently, no user is using the application, Windows removes the binaries. This exactly happens in the customers’ environment. Workaround: But how to deal with it? First: If anybody has a better solution as my workaround, please let me know. Install the application from the Windows Store. E. g. , WhatsApp Launch the application Pin the icon to the taskbar Figure out the full package name using PowerShell: Get-AppxPackage | Where-Object {$_. Name -like  *WhatsApp* }For this case: 5319275A. WhatsAppDesktop_2. 2140. 5. 0_x64__cv1g1gvanyjgmIf you don’t find the app, check the full list of Get-AppxPackage Add the full package name as a key to: HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Appx\AppxAllUserStore\Applications After that, you can log off and log in without reinstalling the application. Unfortunately, the pinned icon is invisible as long as you click it. "
    }, {
    "id": 49,
    "url": "https://blog.itprocloud.de/Shrink-FSLogix-Disks-automatically-with-Hydra/",
    "title": "Shrink FSLogix profiles automatically with Hydra",
    "body": "2021/09/25 - Intro: FSLogix profile disks increase their size over time - even if a user deletes data and the data amount goes down. Like Jim Moyle wrote: “Dynamically Expanding disks do not natively shrink when the volume of data within them reduces, they stay at the ‘High water mark’ of historical data volume within them. ” While you are paying for usage or allocated storage, having the profile disk small is a good way to go. Jim provides a script to shrink the FSLogix profiles. Excellent work from Jim. I added a script in Hydra to download and run the script from Jim to shrink FSLogix disk. This script can be used in a script schedule on a host pool to shrink the disk maybe one time a week. Update Hydra to the newest versionHaving the host target “A single host in the pool” Hydra version 1. 0. 1. 16 is needed. You can update Hydra in the Azure portal -&gt; Your Hydra web app -&gt; Deployment Center -&gt; Sync Download the newest build-in scripts: Open the Hydra portal -&gt; Scripts -&gt; Click the button in the upper right corner: Service Account: Like the feature deleting FSLogix profile, the shrink method needs a service account configured on the host pool level. The account must have read/write permission to the FSLogix file share: Test shrinking: Make a first test for shrinking the profile disk from the session host view. Select one session host -&gt; Run script or collection -&gt; BuiltIn: Shrink FSLogix Disk Create a script schedule to shrink the disks automatically. : If everything works fine, a script schedule can be configured to run the optimization maybe every week. It’s important to run the script only on a single host. Get Hydra: Azure Marketplace "
    }, {
    "id": 50,
    "url": "https://blog.itprocloud.de/Hydra-for-Azure-Virtual-Desktop-AVD-is-available-in-the-Azure-Marketplace/",
    "title": "Hydra is publicly available and listed on the Azure Marketplace",
    "body": "2021/09/02 - I’m pleased that my project Hydra is now listed in the Azure Marketplace as a deployable solution into the customers’ subscription - which is essential to make sure that no personal data cross the customers’ boundaries. In short:Hydra is the solution to manage Azure Virtual Desktop for one or more tenants. Hydra’s web platform allows administrators to deploy new session hosts, configure an auto-adapt scaling, maintain session hosts and pools automatically, and much more.  Start it right now - it’s entirely free for environments having up to six-session hosts per pool. And even the commercial licensing is very favorable. Azure Marketplace More about Hydra "
    }, {
    "id": 51,
    "url": "https://blog.itprocloud.de/Scripts-and-Script-Collections-available-in-Hydra-for-the-automation-of-Windows-Azure-Virtual-Desktop-AVD-WVD/",
    "title": "Hydra: Scripts and Script Collections for the operation and automation of Azure Virtual Desktop (AVD) / Windows Virtual Desktop (WVD)",
    "body": "2021/08/10 - Intro: Project Hydra for Azure Virtual DesktopSix months ago, I started a new project to provide a solution to manage Azure Virtual Desktop / Windows Virtual Desktop in an automated way. It was thought of as a complement to #WVDAdmin and focused on doing some tasks automatically. For example: Autoscale– Multi-Session hosts– Power-on-connect support– Schedules– Autopilot: Automatically scales up/down/create/remove based on the usage of a host pool– Deploy hosts on-demand - including ephemeral VMs based on a custom imageVDI– Auto deallocate session hostsGranular session timeoutsAuto Healthand a lot moreThe last days, I added another essential feature to the project Hydra: Scripts and script collections. Both are intended to automize Azure VMs, and Azure Virtual Desktop (AVD) from the management perspective. Scripts and Script Collections (Updated): Scripts and script collections. Both are intended to automize Azure VMs, and Azure Virtual Desktop (AVD) from the management perspective. Script: A Powershell script for a session host. The script runs in the system context with system permissions, variables containing data about the host pool, session hosts, etc. Optionally, a Powershell credential object (PSC) can be used to connect to other services, like files shares (the service account can be configured on the host pool level).  Script Collections: A script collection is a collection of scripts and tasks in any sequence. E. g. : Drain mode on -&gt; Logoff users -&gt; Start the VM -&gt; Run a script -&gt; Restart -&gt; Drain mode off Additionally, parameters can be set for a script, and error handling is built-in. Script collections are very useful to orchestrate several tasks and scripts to session hosts. Built-in scripts and collections: There are several built-in scripts and collections, and new scripts and collections are provided continuously. Built-in scripts can be updated with the “Update” button in the upper-right corner.  To add a custom script or script collection, copy the “BuiltIn: 1st Template Script” or “BuiltIn: 1st Template Script Collection”. Then start building the new one. Make sure to save the new script/collection with a click of the disk symbol. There is no warning right now if you close the browser or if you navigate to another site.  Triggering a script or script collection: Scripts and script collections can be triggered by Host pool administrators and edited by Full administrators. Both can be assigned/triggered in different ways: For selected hosts: Automatically after the rollout of a new session host: By a schedule: Schedules can be used on a host pool level to run a script or collection unattended on session hosts of the pool. Comparable to other schedules, weekday(s) and start time define the plan. The following parameters can be used to fine-tune the schedule: Hosts Run on all hostsRun only on hosts without user sessionsRun only on hosts in drain-modeSimultaneously Starts directly on all hostsStart on max. 5 session hosts at the same time (if one finished, the script/collection will be started on the next host)… This example runs Windows Update on all session hosts Sunday, 1:00 am. Including drain mode, start, update, restart, drain mode off. Install Project Hydra in your subscription: https://github. com/marcelmeurer/wvd-hydra "
    }, {
    "id": 52,
    "url": "https://blog.itprocloud.de/Azure-AD-only-for-AVD-session-hosts/",
    "title": "WVDAdmin supports AAD only deployments for AVD / WVD - AAD: Azure AD",
    "body": "2021/07/15 - One of the announcements of the Microsoft Inspire 2021 was the option to join session hosts #AAD only. I’m happy to have the implementation also ready in #WVDAdmin. There are some prerequisites for AAD joined session hosts: Host pool in a validation environmentRDP settings contains targetisaadjoined:i:1User must have RBAC with role Virtual Machine User Login or Virtual Machine Administrator Login to the VM or resource groupClient device must be AAD joined (or use the web interface)Even FSLogix cannot be used. Check the full description here: https://docs. microsoft. com/en-us/azure/virtual-desktop/deploy-azure-ad-joined-vm To rollout a session host AAD only tick “AAD only” in the rollout tab. OU, domain user and password are not needed.  An AAD-only session host shows up with the host name in the session host list - the domain suffix is missing. You can also check Azure AD to verify the connection to the AAD domain.  WVDAdmin: https://blog. itprocloud. de/Windows-Virtual-Desktop-Admin/ What’s about #Hydra? Hydra auto-scales and manages even AAD only joined session host. Early next week, you can deploy AAD only hosts even with #Hydra More about my project “Hydra”: https://github. com/marcelmeurer/wvd-hydra "
    }, {
    "id": 53,
    "url": "https://blog.itprocloud.de/Announcement-of-my-project-Hydra-for-Azure-Windows-Virtual-Desktop-Scale,-Autopilot,-Multi-tenant-and-more/",
    "title": "Hydra: Automize, scale and manage Windows Virtual Desktop / Azure Virtual Desktop like a pro - including multi-tenancy",
    "body": "2021/06/01 - Project Hydra for Azure Virtual DesktopSix months ago, I started a new project to provide a solution to manage Azure Virtual Desktop / Windows Virtual Desktop in an automated way. It was thought of as a complement to #WVDAdmin and focused on doing some tasks automatically. For example: Autoscale– Multi-Session hosts– Power-on-connect support– Schedules– Autopilot: Automatically scales up/down/create/remove based on the usage of a host pool– Deploy hosts on-demand - including ephemeral VMs based on a custom imageVDI– Auto deallocate session hostsGranular session timeoutsAuto Healthand a lot moreEven the autoscaling part works very well. It goes hand-in-hand with Power-On-Connect and can pre-provide temporary session hosts with ephemeral disks. And for sure: It down-scales the environment.  More about my project “Hydra”: https://github. com/marcelmeurer/wvd-hydra "
    }, {
    "id": 54,
    "url": "https://blog.itprocloud.de/Custom-Role-for-Power-On-Connect-Preview/",
    "title": "Power-On-Connect Feature in Azure Windows Virtual Desktop and custom role for Power On Connect preview",
    "body": "2021/05/24 - Power-On-Connect Feature in Windows Virtual DesktopPower-on-connect is in preview for assigned session hosts and pooled session hosts (multi-user host pool). With the new feature, users are triggering the start of the assigned session hosts or of a pooled on demand. That allows scaling up from zero hosts. Shutting down is omitted, but you can check my upcoming project to use power-on-connect with predictive autoscaling, including the shutdown of the hosts (and many other features). Check out my “preview” project “Hydra” at GitHub. You can enable power-on-connect for private host pools in the Azure Portal or with WVDAdmin. WVDAdmin also allows enabling power-on-connect for pooled/multi-user host pools. To use power-on-connect, you have to allow Microsoft to start virtual machines. To do that, create a custom role with the following link and add the user “Windows Virtual Desktop” (update: “Azure Virtual Desktop”) with this role to the resource group containing the virtual machines. Install the power-on-connect role Learn more at:https://docs. microsoft. com/en-us/azure/virtual-desktop/start-virtual-machine-connect "
    }, {
    "id": 55,
    "url": "https://blog.itprocloud.de/WVD-Shrink-the-OS-Disk-in-Azure-to-64-Gbyte/",
    "title": "Shrink and resize an Azure VM disk or session host disk and create smaller images from a Golden Master",
    "body": "2021/05/18 - A Windows 10 image from the marketplace has a size of 128 Gbyte. So, all of your VM based on that image are deployed with a 128 Gbyte disk - even a “Golden Master” - typically used to build Azure Windows Virtual Desktop images. A clean Windows installation has a size of less than 40 Gbyte, and a 64 Gbyte OS disk is usually sufficient - even if FSLogix is used to store personal data. But what are the advantages of smaller disks? First, they are some reason to use smaller disks, like:A smaller disk costs less. Usually 50% less and with the same performance for HDD and standard SSD (the premium disk has more IOPS for the larger size) Ephemeral disks for smaller VM sizes: Ephemeral disks are really good for VM without local user data - like session hosts using FSLogix. VMs with ephemeral disks living on the Azure hypervisor without a network-attached disk - the OS disks are created directly in the cache of the hypervisor. Advantages:No costs for the disk and high performance. Unfortunately, the cache size is limited based on the VM size. To run a 128 Gbyte Windows, (e. g. ) a D8ds_v4 (8 cores, 32 Gbyte RAM, 200 GiB cache) is needed. That is maybe not attractive for a single user session host. If we go with a 64 Gbyte disk image, a D4ds_v4 can be used (4 cores, 16 Gbyte, 100GiB cache), which costs half. My favorite is the ephemeral disk approach for some environments because this offers high performance for a low price and often fits Windows Virtual Desktop. The challenge: The challenge is to resize the Golden Master. There are some good posts about doing that, but it’s not easy and needs many different steps. Therefore, I added this as a feature in WVDAdmin from the release of today. So feel free to resize your Golden Master to 64 Gbyte, grab an image and deploy smaller session hosts - may be as ephemeral with #WVDAdmin / #AVDAdmin I recommend making a snapshot first and keep in mind that the process takes a while (between 20 and 60 minutes). But you only have to do it once. What happens in the background: The Windows partition will be resized to 31 GbyteThe disk is uploaded to a temporary created storage account (that takes a while)The disk is resized, and the signature for a 32 Gbyte disk is writtenA new 32 Gbyte managed disk is createdThe disk is attached to the VMThe temporary storage account is deletedSite node: How to use ephemeral VMs in a very cool way?: I’m currently working on the following solution called “Project Hydra” to managed WVD. In addition, I added an “Autoscale” feature that is going hand-in-hand with Microsoft’s “Power-on-Connect”: In the morning, a bunch of ephemeral session hosts are automatically created to handle the first user stormSome stand-by session hosts (deallocated) with standard SSD are then started with Power-On-Connect if a user tries to log in, and all of the ephemeral hosts are in useAnd for sure: Deallocation of the “normal” hosts and deletion of the ephemeral hosts are part of the autoscalingPreqersits to shrink a disk:: Windows operating system installed on a 128 Gbyte disk or greaterOnly drive C: (exact two partitions: recovery partition and C-drive - default)Check out the newest version of #WVDAdmin / #AVDAdmin and check a short demo video about resizing a disk on YouTube (external Link).  "
    }, {
    "id": 56,
    "url": "https://blog.itprocloud.de/WVD-Fileupload-HTML5/",
    "title": "Azure Windows Virtual Desktop Fileupload with the HTML5 client",
    "body": "2021/05/04 - Microsoft is extending the HTML5 web client. Today (May 2021), there is a new function to allow uploading files directly into the session. The user can select the feature while starting a connection. Inside the HTML5 client, the user can upload a file with the icon in the upper right corner. The file is saved into the virtual drive: \\tsclient\Remote Desktop Virtual Drive\Uploads (the drive only exist in the current session) An administrator can avoid storing files into the virtual drive setting the group policy (per user or per machine) to “Enabled”: Administrative Templates\Windows Components\Remote Desktop Services\Remote Desktop Session\Device and Resource\Do not allow drive redirection"
    }, {
    "id": 57,
    "url": "https://blog.itprocloud.de/Changing-the-disk-type-automatically-while-starting-or-deallocating-a-session-host,-VM-for-WVD/",
    "title": "Changing the disk type automatically while starting or deallocating a session host / VM for WVD",
    "body": "2021/02/27 - The costs of running virtual machines in Azure summarize the costs of their components like VM type (compute), storage, network, and some other parts. While the spendings for the compute stops after deallocating VMs, Microsoft continues charging for the storage (the virtual disks). These make sense while the disks continue using the underlying storage. There are three main types of storage for managed disks with different prices: E. g 128 GByte costs between $5. 89 to $19. 71 per disk per month.  If you have many VMs, the disks’ costs become more important while you have to pay for the disk while the VM is running or not. If you run Windows Virtual Desktops, your session hosts don’t run 24/7 (the same happens for test and demo environments). So, you start and stop the virtual machines to your needs. This lowers the compute costs, but the costs for the disks continue. But if a virtual machine is deallocated, the storage performance is unimportant. Why don’t we change the disk type to the cheapest after deallocating and bringing it back to a higher performance before starting the VM? That is absolutely possible and can be done through the Azure Portal - or using WVDAdmin. With the current version of WVDAdmin you can tag a VM / session host to change the disk type on start and after the deallocation. Simply add a tag to the VMs with the name “WVD. AdvDiskType” and one of the following values: StandardSSD_LRSPremium_LRSAfter this, refresh WVDAdmin, and the disk type changes on start to the named type and goes to standard HDD (the cheapest) after the deallocation.  PS: You can add the tags automatically using the “Custom Tags” tab in WVDAdmin:  Important: Keep in mind that change the disk type on the fly only works in WVDAdmin. If you start/stop a VM in the Azure Portal (or with an autoscaling engine), the disk type will not change. "
    }, {
    "id": 58,
    "url": "https://blog.itprocloud.de/Sysprep-Error-sysprep-data-was-marked-corrupt;-cannot-proceed/",
    "title": "Sysprep error: RunPlatformActions:Sysprep data was marked corrupt; cannot proceed",
    "body": "2021/02/14 - I’m working in the WVD/AVD area and often create golden images to deploy session hosts for WVD/AVD - mainly based on Windows 10 Enterprise multi-session. To do that, I create a template VM in Azure based on Windows 10, joined it to the domain, install updates and applications, and create an image based on that VM. To make my life easier, I use WVDAdmin to generate the template and rolling it out later - but this is independent of the issue with Sysprep. One step of creating an image is to Sysprep the template image. I - or WVDAdmin is doing that - by running: sysprep. exe /generalize /oobe /shutdown /mode:vmIn the last weeks, I got the feedback that Sysprep runs into an error if you sysprep a former syspreped virtual machine again - and if Windows-updates were installed between both preparations. The error is written in C:\Windows\System32\Panther\setupact. log is: 2021-02-09 17:17:55, Error   [0x0f00d6] SYSPRP RunPlatformActions:Sysprep data was marked corrupt; cannot proceed2021-02-09 17:17:55, Error   [0x0f0070] SYSPRP RunDlls:An error occurred while running registry sysprep DLLs, halting sysprep execution. dwRet = 0x27a2021-02-09 17:17:55, Error         SYSPRP WinMain:Hit failure while processing sysprep re-specialize internal providers; hr = 0x8007027aIt took some time, but I found a way to bring sysprep back to work (even if I didn’t find the root cause of this issue). Keep in mind that this workaround doesn’t resolve the unknown reason and maybe bring your image in an unsupported state. Delete the following registry key or set it to 0:HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Setup\Sysprep	SysprepCorrupt Powershell: Remove-ItemProperty -Path &quot;HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Setup\Sysprep&quot; -Name &quot;SysprepCorrupt&quot; -ErrorAction Ignore"
    }, {
    "id": 59,
    "url": "https://blog.itprocloud.de/Push-WVD-Session-Hosts-data-and-status-into-Azure-Monitor-Log-Analytics-to-create-alerts/",
    "title": "Push Azure Windows Virtual Desktop (WVD) Session Host state to Log Analytics to create alerts if hosts become unavailable or failed",
    "body": "2021/01/15 - Microsoft offers an easy way to monitor a WVD/AVD environment’s basic metrics directly integrated into the Azure portal. I mostly extend the monitoring using sepago’s Azure Monitor for WVD (https://www. sepago. de/en/azure-monitor-en/), which is also included in Nerdio Manager for WVD (https://getnerdio. com/nerdio-manager-for-wvd/). The native Microsoft solution shows the session hosts’ state (available, unavailable, failed, …) in a workbook (insights) in the Azure Portal. Unfortunately, the way of showing this state cannot be used to create an alert in Azure Monitor and get notified. To solve this challenge, we have to put the session host states as a custom log into a Log Analytics workspace. The data can be queried and uploaded to Log Analytics with an Azure Logic App Installation and configuration: Deploy the prepared logic app into your subscription using the “Deploy to Azure” button.  To query the Azure Management API, you need a service principal (a function account) with the right permission. Create the service principal in the Azure Portal: Azure Active Directory -&gt; App registrations -&gt; New registration and give it a name (e. g. svc_AzureWvdSessionHostsAvailability4AzureMonitor) and press registerGo to Certificates and secrets -&gt; Add new client secret and type in a name (e. g. Key1) and expiration date (make a note into your calendar) and press addCopy the generated secret for later useGo to overview and copy the application id and directory id for later useGive the service principal permission to the subscription: Access control (IAM) -&gt; Add -&gt; Add role assignment -&gt; “Desktop Virtualization Host Pool Reader” and select the service principalTo upload the data to your Azure Monitor / log analytics workspace, you need the workspace id and key of an existing Log Analytics workspace. Go to your log analytics workspace -&gt; select Advanced settings -&gt; Agents management -&gt; copy the workspace id and primary key for later useGo to your deployed logic app and click edit. Edit the configuration of “Authentication: Tenant Id”, “Authentication: App Id”, “Authentication: App Password” and “Subscription Id”: Enter the data of the service principal and the subscription id (Guid) Expand “For each”, “Until” and open “Send Data (Preview)” Click on Connections and add a new one (Add new) Give a name (e. g. ToLogAnalytics), the primary key and workspace id from log analytics and press create Save the logic app and press run to test it. If everything looks good, our logic app will upload the data to log analytics every 5 minutes (can be changed).  Querying data: You can query the data from log analytics with WVDHostPoolStatistic_CL. Keep in mind that it takes a while (30 minutes) to build the first upload schema. To show the data in a list you can start with this query: WVDHostPoolStatistic_CL| project TimeGenerated, SessionHost=name_s, properties_status_s, properties_allowNewSession_b, properties_updateState_s, properties_assignedUser_s To create an alert you can add an alert to Log Analytics based on the following query (lists unavailable hosts): WVDHostPoolStatistic_CL| project TimeGenerated, SessionHost=name_s, properties_status_s, properties_allowNewSession_b, properties_updateState_s, properties_assignedUser_s| where properties_status_s=~&quot;unavailable&quot;"
    }, {
    "id": 60,
    "url": "https://blog.itprocloud.de/WVDAdmin-for-WVD-management-and-roll-out-videos-on-Youtube/",
    "title": "WVDAdmin videos on YouTube",
    "body": "2021/01/11 - WVDAdmin is my free community solution to manage and work with WVD/AVD / Windows Virtual Desktop. Mainly, building images and rolling out session hosts are key-value-adds. But you can also run parallel tasks on VMs and session hosts. Learn how to use and some tips &amp; tricks showing my YouTube channel about WVDAdmin - I’m continuously adding more videos to the channel. 01: WVDAdmin - Configuring WVDAdmin: 02: WVDAdmin - Building a template image for session hosts: 03: WVDAdmin - Rollout multiple session hosts: "
    }, {
    "id": 61,
    "url": "https://blog.itprocloud.de/Custom-Role-for-Power-On-Connect-Schedules-Preview/",
    "title": "Custom Role for Power On Connect preview",
    "body": "2021/01/11 - Power-On-Connect Role Schedule-Role Hydra-Role "
    }, {
    "id": 62,
    "url": "https://blog.itprocloud.de/Windows-Virtual-Desktop-Admin-CustomScripts/",
    "title": "WVD Admin - Custom Scripts to run administrative tasks",
    "body": "2020/11/18 - Custom Scripts with WVDAdminFrom version 1. 6. 15, WVDAdmin supports custom scripts to run administrative tasks simultaneously on different session hosts. And that is easy to use and to extend. Let me show it with the challenge to enable RDP Shortpath on existing session hosts. In this post, Microsoft describes how to enable this preview feature for WVD/AVD to connect to a WVD/AVD session without crossing the internet. Start copying the file [C:\Program Files\ITProCloud. de\WVDAdmin\CustomScript. ps1](C:\Program Files\ITProCloud. de\WVDAdmin\CustomScript. ps1) to a new name into the same directory. For example EnableRDPShortPath. ps1 Open the file with notepad or the editor of your choice. Edit the first line to give your script a name (that is visible in the drop-down list in WVDAdmin) and a description. The description is shown in the message box where you have to consent to run on the selected session hosts. # {&quot;Name&quot;: &quot;Enable RDP Shortpath&quot;,&quot;Description&quot;:&quot;This script enables the preview function for RDP Shortpath on the selected session hosts&quot;}After that, you can copy the code between lines 22 and 23 (LogWriter(“Custom script start”) and LogWriter(“Custom script end”)). I re-used the example code from Microsoft: LogWriter(&quot;Custom script start&quot;)$WinstationsKey = 'HKLM:\SYSTEM\CurrentControlSet\Control\Terminal Server\WinStations'New-ItemProperty -Path $WinstationsKey -Name 'fUseUdpPortRedirector' -ErrorAction:SilentlyContinue -PropertyType:dword -Value 1 -ForceNew-ItemProperty -Path $WinstationsKey -Name 'UdpPortNumber' -ErrorAction:SilentlyContinue -PropertyType:dword -Value 3390 -ForceNew-NetFirewallRule -DisplayName ‘Remote Desktop - Shortpath (UDP-In)’ -Action Allow -Description ‘Inbound rule for the Remote Desktop service to allow RDP traffic. [UDP 3390]’ -Group ‘@FirewallAPI. dll,-28752’ -Name ‘RemoteDesktop-UserMode-In-Shortpath-UDP’ -PolicyStore PersistentStore -Profile Domain, Private -Service TermService -Protocol udp -LocalPort 3390 -Program ‘%SystemRoot%\system32\svchost. exe’ -Enabled:TrueLogWriter(&quot;Custom script end&quot;) The full script should look like this: # {&quot;Name&quot;: &quot;Enable RDP Shortpath&quot;,&quot;Description&quot;:&quot;This script enables the preview function for RDP Shortpath on the selected session hosts&quot;}param(  [string]$paramLogFileName=&quot;WVD. Custom. log&quot;,	[string]$paramString=&quot;&quot;);This powershell script is part of WVDAdmin - see https://blog. itprocloud. de/Windows-Virtual-Desktop-Admin/ for more informationCurrent Version of this script: 1. 0 - Custom Script ExtensionWrite a return string to WVDAdmin with the example in the last lineDefine logfilen and dir$LogDir=&quot;$env:windir\system32\logfiles&quot;$LogFile=&quot;$LogDir$paramLogFileName&quot; function LogWriter($message){$message=&quot;$(Get-Date ([datetime]::UtcNow) -Format &quot;o&quot;) $message&quot;write-host($message)if ([System. IO. Directory]::Exists($LogDir)) {write-output($message) | Out-File $LogFile -Append}} LogWriter(&quot;Custom script start&quot;)$WinstationsKey = ‘HKLM:\SYSTEM\CurrentControlSet\Control\Terminal Server\WinStations’New-ItemProperty -Path $WinstationsKey -Name ‘fUseUdpPortRedirector’ -ErrorAction:SilentlyContinue -PropertyType:dword -Value 1 -ForceNew-ItemProperty -Path $WinstationsKey -Name ‘UdpPortNumber’ -ErrorAction:SilentlyContinue -PropertyType:dword -Value 3390 -Force New-NetFirewallRule -DisplayName ‘Remote Desktop - Shortpath (UDP-In)’ -Action Allow -Description ‘Inbound rule for the Remote Desktop service to allow RDP traffic. [UDP 3390]’ -Group ‘@FirewallAPI. dll,-28752’ -Name ‘RemoteDesktop-UserMode-In-Shortpath-UDP’ -PolicyStore PersistentStore -Profile Domain, Private -Service TermService -Protocol udp -LocalPort 3390 -Program ‘%SystemRoot%\system32\svchost. exe’ -Enabled:TrueLogWriter(&quot;Custom script end&quot;) Write-host(&quot;ScriptReturnMessage:{RDP Shortpath enabled - reboot the session hosts(s) to take effect}:ScriptReturnMessage&quot;) Alternatively, you can load the script from here and copy it into WVDAdmin’s program file folder. To load the scripts, restart WVDAdmin. You will see multiple “Information Adding scripts for session host management in the log windows: xxxx. ps1” messages, including your new EnableRDPShortPath. ps.  To run the script on multiple hosts, go to a host pool, expand the node and click the “Session hosts” container.  Select the hosts, select your script “Enable RDP Shortpath” and click on “Run script”. After clicking OK, the script will be run in the system context on the session hosts. This will take a few minutes.  After that - and in this case, after the next reboot - RDP Shortpath should be available for WVD/AVD users in directly connected networks. "
    }, {
    "id": 63,
    "url": "https://blog.itprocloud.de/Push-Azure-AD-User-data-into-Azure-Monitor-Log-Analytics-to-query-WVD-data-INTERNAL/",
    "title": "INTERNAL Push Azure AD User properties into Azure Monitor Log Analytics to build Windows Virtual Desktop (WVD) performance data based on these",
    "body": "2020/10/13 - Azure Monitor / Log Analytics is my first choice to store log and usage data. Even for Windows Virtual Desktop (WVD), it is crucial to have an eye on the hosts, users, and single applications’ usage and performance. I do that using Azure Monitor for WVD/AVD (https://www. sepago. de/en/azure-monitor-en/) from sepago, which is also included in Nerdio Manager for WVD (https://getnerdio. com/nerdio-manager-for-wvd/). The solution gives you insight into the performance of the apps and hosts and allows you to build a cost calculation on a per-user base. If you want to query and analyze data by other properties - like the department - you have to include these properties from Azure AD into your log analytics workspace. I found an easy solution doing that with an Azure logic app. The logic app access the Azure AD tenant and queries the users and some defined properties and send it to log analytics. A challenge was to handle the challenge that you have to query multiple times to get all users from Azure AD (a single query gives you only a specific amount of users -&gt; Paging). I solved this using an “Until-loop” to get all users. The logic app pushed the users and their properties to the defined log analytics workspace. After this, the users and properties can be used in a KUSTO query. For example: To query the over-all session runtime by the department. Installation and configuration: Deploy the prepared logic app into your subscription using the “Deploy to Azure” button.  To query the Azure AD unattended, you need a service principal (a function account) with the right permission. Create the service principal in the Azure Portal: Azure Active Directory -&gt; App registrations -&gt; New registration and give it a name (e. g. svc_AzureAdUserReader4AzureMonitor) and press registerGo to Certificates and secrets -&gt; Add new client secret and type in a name (e. g. Key1) and expiration date (make a note into your calendar) and press addCopy the generated secret for later useGo to Api permissions -&gt; Add a permission -&gt; select Microsoft Graph -&gt; Application permissions -&gt; select User. Read. All -&gt; click Add permissionsClick Grant admin consent to allow this setting (you have to be in the right role to do that)Go to overview and copy the application id and directory id for later useTo upload the data to your Azure Monitor / log analytics workspace, you need the workspace id and key. Go to your log analytics workspace -&gt; select Advanced settings -&gt; Agents management -&gt; copy the workspace id and primary key for later useGo to your deployed logic app and click edit. Expand “Until 2” Click on http. Enter the data from your service principal into the fields Tenant (Directory id), client id, and secret Click on Connections and add a new one (Add new) Give a name (e. g. ToLogAnalytics), the primary key and workspace id from log analytics and press createSave the logic app and press run to test it. If everything looks good, our logic app will write the user data to log analytics once a day.  You can query the data from log analytics with “ITPC_CTX_ADUsers_CL”. Keep in mind that it takes a while (30 minutes) to build the first upload schema.  Hint: You can modify the filter and the properties you get back, modifying the query URL. The URL can be modified in “Initialize variable” in the logic app.  The default is: https://graph. microsoft. com/v1. 0/users?$filter=accountEnabled eq true and userType eq 'Member'&amp;$select=userPrincipalName,onPremisesSamAccountName,employeeId,officeLocation,departmentA list of valid properties is here: https://docs. microsoft. com/de-de/graph/api/resources/user?view=graph-rest-1. 0 "
    }, {
    "id": 64,
    "url": "https://blog.itprocloud.de/Push-Azure-AD-User-data-into-Azure-Monitor-Log-Analytics-to-query-WVD-data/",
    "title": "Push Azure AD User properties into Azure Monitor Log Analytics to build Azure Windows Virtual Desktop (WVD) performance data based on these",
    "body": "2020/10/01 - Azure Monitor / Log Analytics is my first choice to store log and usage data. Even for Azure Windows Virtual Desktop (WVD/AVD), it is crucial to have an eye on the hosts, users, and single applications’ usage and performance. I do that using Azure Monitor for WVD/AVD (https://www. sepago. de/en/azure-monitor-en/) from sepago, which is also included in Nerdio Manager for WVD/AVD (https://getnerdio. com/nerdio-manager-for-wvd/). The solution gives you insight into the performance of the apps and hosts and allows you to build a cost calculation on a per-user base. If you want to query and analyze data by other properties - like the department - you have to include these properties from Azure AD into your log analytics workspace. I found an easy solution doing that with an Azure logic app. The logic app access the Azure AD tenant and queries the users and some defined properties and send it to log analytics. A challenge was to handle the challenge that you have to query multiple times to get all users from Azure AD (a single query gives you only a specific amount of users -&gt; Paging). I solved this using an “Until-loop” to get all users. The logic app pushed the users and their properties to the defined log analytics workspace. After this, the users and properties can be used in a KUSTO query. For example: To query the over-all session runtime by the department. Installation and configuration: Deploy the prepared logic app into your subscription using the “Deploy to Azure” button.  To query the Azure AD unattended, you need a service principal (a function account) with the right permission. Create the service principal in the Azure Portal: Azure Active Directory -&gt; App registrations -&gt; New registration and give it a name (e. g. svc_AzureAdUserReader4AzureMonitor) and press registerGo to Certificates and secrets -&gt; Add new client secret and type in a name (e. g. Key1) and expiration date (make a note into your calendar) and press addCopy the generated secret for later useGo to Api permissions -&gt; Add a permission -&gt; select Microsoft Graph -&gt; Application permissions -&gt; select User. Read. All -&gt; click Add permissionsClick Grant admin consent to allow this setting (you have to be in the right role to do that)Go to overview and copy the application id and directory id for later useTo upload the data to your Azure Monitor / log analytics workspace, you need the workspace id and key. Go to your log analytics workspace -&gt; select Advanced settings -&gt; Agents management -&gt; copy the workspace id and primary key for later useGo to your deployed logic app and click edit. Expand “Until 2” Click on http. Enter the data from your service principal into the fields Tenant (Directory id), client id, and secret Click on Connections and add a new one (Add new) Give a name (e. g. ToLogAnalytics), the primary key and workspace id from log analytics and press createSave the logic app and press run to test it. If everything looks good, our logic app will write the user data to log analytics once a day.  You can query the data from log analytics with “ITPC_CTX_ADUsers_CL”. Keep in mind that it takes a while (30 minutes) to build the first upload schema.  Hint: You can modify the filter and the properties you get back, modifying the query URL. The URL can be modified in “Initialize variable” in the logic app.  The default is: https://graph. microsoft. com/v1. 0/users?$filter=accountEnabled eq true and userType eq 'Member'&amp;$select=userPrincipalName,onPremisesSamAccountName,employeeId,officeLocation,departmentA list of valid properties is here: https://docs. microsoft. com/de-de/graph/api/resources/user?view=graph-rest-1. 0 "
    }, {
    "id": 65,
    "url": "https://blog.itprocloud.de/Least-privileges-with-custom-roles-for-Windows-Virtual-Desktop-(WVD)/",
    "title": "Least privileges with custom roles for Azure Windows Virtual Desktop (WVD)",
    "body": "2020/09/10 - Administration, deployment, user support of Azure Windows Virtual Desktop (WVD) needs permission in Azure. But these permissions are depending on the task a group of users/administrators have to do. For example, if the help desk has to log off and send messages to users, they need fewer permissions than the administrator building session hosts. In the first step, the permission for the different groups can be given using the build-in roles in Azure and assigning them to the groups and specific resources. But this doesn’t allow us to assign granular permissions to fulfill the least privileges approach. To do that, we have to go with custom roles. Custom roles allow combining specific permission for different resource types to a new role. Luckily, Azure Windows Virtual Desktop has many additional permissions per resource type (host pool, app group, workspace, etc. ). I combined the permission from WVD/AVD and from other resource types (like Microsoft Compute) to build eight roles I often use in projects to assign the least permission as needed for the different administrator. These roles can be used to assign them to users, groups, and even service principals (important for WVDAdmin). In my opinion, the best way is to assign these roles on a resource group level and not to a subscription level. Before I describe the different new roles, I have to mention one “Specialty”: Assigning users to an app group in Azure Windows Virtual Desktop needs that you have “Owner Permission” (or more precisely: Microsoft. Authorization/roleAssignments/write) to the app group. While Azure doesn’t have the ability to assign owner permission in a role to a specific resource type, I didn’t add this permission to the roles. So, you can easily use the new roles on a resource group level, and you can be sure that the user only has the least permission, but you have to assign appropriate admins as an owner to (only) the app groups. Owner permission on resource groups causes that the user can do and rollout anything in these groups. Note: In a real-world scenario where the least privileges approach for a specific group of admins is not necessary, owner permissions are given to the resource groups containing the WVD/AVD resources (especially the app groups). My common WVD/AVD roles:: WVD - User Session Reader: Allows to read the user session and host pool properties of Windows Virtual Desktop. WVD - VM Start-, Stop- and Restarter: Allows to start, stop and restart virtual machines and VM Scale Set instances WVD - User Session Contributor: Allows to work with the user session and read host pool properties of Azure Windows Virtual Desktop host pools, including to send messages to users and logoff/disconnect user sessions WVD - Infrastructure Reader: Allows to read all properties of a WVD infrastructure: Host pools, session hosts, workspaces, app groups, and user sessions. WVD - Infrastructure Contributor: Allows to read and write all properties of a WVD infrastructure but doesn’t allow to delete resources: Host pools, session hosts, workspaces, app groups, and user sessions. WVD - Infrastructure Administrator: Allows to read and write all properties of a WVD infrastructure and allows to delete resources: Host pools, session hosts, workspaces, app groups, and user sessions. WVD - Infrastructure Administrator &amp; VM Manager: Allows to read and write all properties of a WVD infrastructure and allows to delete resources: Host pools, session hosts, workspaces, app groups, and user sessions. Additionally, the power state of all hosts and VMs can be changed. WVD - Template and Session Host Administrator: Allows to create/modify/delete Virtual Machines, images, rollout new session hosts into host pools, and attach them to a vnet. WVD - Full Administrator: Allows to create/modify/delete Virtual Machines, images, rollout new session hosts into host pools, attach them to a vnet, and all permissions from the role ‘WVD - Infrastructure Administrator &amp; VM Manager’. I’m happy about feedback and give me a ping if you want to have the ‘Microsoft. Authorization/roleAssignments/write’ inside the contributor roles (but that doesn’t prevent users from getting higher permissions on the resource group). Feel free to roll out these WVD roles into your own subscription (ignore the location, the roles are available in the subscription independent from the location - or take a look into the deployment script): "
    }, {
    "id": 66,
    "url": "https://blog.itprocloud.de/Shadow-a-WVD-user-with-least-privileges/",
    "title": "Shadow a WVD/AVD user with least privileges",
    "body": "2020/08/24 - WVD allows local administrators to shadow user sessions. You can do this easily with WVDAdmin or using the command-line like this: >mstsc /v:WVD-DESIGN-404 /control /shadow:2 /promptIn most companies, a help desk agent supports users using applications. For that, local admin privileges are not necessary and not recommended. To allow help desk agents shadowing users in WVD, you have to give these users (or better: a user group) only the needed permission. To do this, execute the following command in an administrative cmd: wmic /namespace:\\root\CIMV2\TerminalServices PATH Win32_TSPermissionsSetting WHERE (TerminalName like 'RDP-sxs%') CALL AddAccount 'ITPROCLOUD\ADM_WVD-Shadowing',2Please also configure the local or group policy: Computer -&gt; Administrative Templates -&gt; Windows Components -&gt; Remote Desktop Services -&gt; Remote Desktop Session Hosts -&gt; Connections -&gt; Set riles for remote control … to “2” (Allow control with user consent) This gives the users of the group ITPROCLOUD\ADM_WVD-Shadowing the needed permission directly on the RDP-SXS stack (you need to reboot the session host). Run this configuration after the deployment and installation of the AVD agent and ensure to run it maybe again, if the RDP-SXS stack is updated. Hint: You can reset this setting with: wmic /namespace:\\root\CIMV2\TerminalServices PATH Win32_TSPermissionsSetting WHERE (TerminalName like 'RDP-sxs%') CALL RestoreDefaultsTake a look how shadowing a user session with WVDAdmin looks like: https://twitter. com/i/status/1229472041423732736 "
    }, {
    "id": 67,
    "url": "https://blog.itprocloud.de/Sysprep-and-WVD-and-UWP/",
    "title": "What's wrong with Windows 10 and UWP and Sysprep?",
    "body": "2020/07/28 - I’m working in the WVD/AVD area and often create golden images to deploy session hosts for WVD/AVD - mainly based on Windows 10 Enterprise multi-session. To do that, I create a template VM in Azure based on Windows 10, joined it to the domain, install updates and applications, and create an image based on that VM. To make my life easier, I use WVDAdmin to generate the template and rolling it out later - but this is independent of the issue with Sysprep. One step of creating an image is to Sysprep the template image. I - or WVDAdmin is doing that - by running: sysprep. exe /generalize /oobe /shutdown /mode:vmSometimes I run into an issue, and Sysprep stops work with an error message: Digging into the log file show the issue: Error: Package XXXXXXX was installed for a user, but not provisioned for all users. The package various. Sometimes I got a part of a language pack or other internal app packages. To run into the problem with certainty, install an app from the Windows Store. Let’s find out what happens, for doing that I installed different applications from the Windows Store into the VM and tried to Sysprep the VM. The first package blocking Sysprep was in this test “5319275A. WhatsAppDesktop_2. 2027. 10. 0_x64__cv1g1gvanyjgm” To get details of the package run the following PowerShell script with administrative privileges: Get-AppxPackage -AllUsers | ? {$_. packagefullname. contains('5319275A. WhatsAppDesktop_2. 2027. 10. 0_x64__cv1g1gvanyjgm')}The returned object shows that this package is only installed for the local administrator (installing the apps from the Windows Store). The user querying this data (mm-admin) doesn’t have this package installed. Okay. Appx packages from the store are personnel and not shared with all users on a VM (to install appx packages for all users, you have to sideload the packages with DISM. exe). So I tried to remove this app from all users:_ Get-AppxPackage -AllUsers | ? {$_. packagefullname. contains('5319275A. WhatsAppDesktop_2. 2027. 10. 0_x64__cv1g1gvanyjgm')} | Remove-AppxPackage -AllUsersOk. Sysprep again. The next issue occurs: Sysprep has the same problem with NetFlix - installed only for one user of the VM. Instead of removing the packages by trial and error, I found another way: Teach Sysprep to ignore this behavior. I guess it’s not a problem having an appx package assigned to only one user - even if it and administrative user. I figured out that Sysprep uses an XML file with a set of rules preparing a VM. The rule-set for generalizing an image is stored in &quot;C:\windows\System32\sysprep\ActionFiles\Generalize. xml&quot; To ignore the installed or update AppX package remove the following lines and save Generalize. xml (you have to take ownership of the file and give yourself permission to do that): &lt;sysprepOrder order=&quot;0x1A00&quot;&gt;&lt;/sysprepOrder&gt;&lt;sysprepValidate methodName=&quot;SysprepGeneralizeValidate&quot; moduleName=&quot;$(runtime. system32)\AppxSysprep. dll&quot;&gt;&lt;/sysprepValidate&gt;&lt;sysprepModule methodName=&quot;SysprepGeneralize&quot; moduleName=&quot;$(runtime. system32)\AppxSysprep. dll&quot;&gt;&lt;/sysprepModule&gt;&lt;/imaging&gt;&lt;imaging exclude=&quot;&quot;&gt;&lt;assemblyIdentity name=&quot;Microsoft-Windows-SecureBoot-FirmwareUpdate&quot; version=&quot;10. 0. 19041. 1&quot; publicKeyToken=&quot;31bf3856ad364e35&quot; processorArchitecture=&quot;amd64&quot; versionScope=&quot;NonSxS&quot;&gt;&lt;/assemblyIdentity&gt; After that Sysprep runs without an issue. Rolling out a session host based on the new image works, and even the user could logon without a problem (and yes: they don’t have the Store apps from the local admin - as expected). Maybe there are some smarter ways to handle UWP and Sysprep (if you know one - let me know it, too). But this solves an issue creating or updating an image for WVD/AVD based on a template VM (golden image approach). "
    }, {
    "id": 68,
    "url": "https://blog.itprocloud.de/Azure-Global-Bootcamp-2020/",
    "title": "PolarConf 2019 - Building own solutions whit Azure Monitor ",
    "body": "2020/05/25 - [Azure Global Bootcamp - WVD/AVD - How to enjoy perfect published apps and desktops. pdf](. . /assets/files/WVD - How to enjoy perfect published apps and desktops. pdf) "
    }, {
    "id": 69,
    "url": "https://blog.itprocloud.de/Windows-Virtual-Desktop-Monitoring-the-Spring-backend/",
    "title": "Azure Windows Virtual Desktop - Monitoring the Spring Backend - WVD",
    "body": "2020/05/05 - The long await update from WVD/AVD is public. It comes with a full ARM integration and is natively useable in the Azure Portal. Some things changed from the Fall to Spring update, and that’s include monitoring. In this post, I’m focused on monitoring the WVD/AVD backend and not monitoring the sessions, applications, session host performance, latency, etc. To exactly monitoring these metrics, check out the solution “Azure Monitor for WVD” which works for Fall and the Spring update - and the new version comes with great Azure workbooks to additionally visualize data by host pool. The Fall update writes logs to Azure Monitor / Log Analytics as custom logs. There is a really good blog post about this. The Spring update writes logs to Log Analytics as well, but they have a different name and schema. To enable logging the backend, you have to enable the diagnostic settings on all involved resources: WorkspaceHost PoolApp GroupMake sure that you select all logs and select your Log Analytics workspace (if you use sepago’s “Azure Monitor for WVD” use the same Log Analytics workspace for the backend logging) ![Registry with values](. . /assets/images/Azure Monitor for WVD/Blog-01-05. png) If you have done this for all resources, the WVD/AVD send logs to the selected workspace. Keep in mind that writing the first entries can take up to 20 minutes to build the data schema initially. After a while, you should have log data in your Log Analytics workspace: ![Registry with values](. . /assets/images/Azure Monitor for WVD/Blog-01-06. png) You can see the following logs (tables): WVDCheckpointsIntermediate steps while establishing and running a connectionWVDConnectionsStart/End of connectionsWVDErrorsErrors while establishing a connection, failures during the administration, failures getting feed informationsWVDHostRegistrationsAbout session host registration to host poolsWVDManagementAdministration logThe logs are internally connectable with their correlation id you have in each log. Let’s start digging some data: Open Log Analytics an go to “Logs” and run your queries based on the KUSTO query language. Count of brokered sessions by state: WVDConnections | where State =~ &quot;Started&quot; and Type =~&quot;WVDConnections&quot; | extend CState=iff(SessionHostOSVersion==&quot;&lt;&gt;&quot;,&quot;Failure&quot;,&quot;Success&quot;) | summarize Count=count() by State=CState| render piechart ![Registry with values](. . /assets/images/Azure Monitor for WVD/Blog-01-02. png) Failed connections: WVDConnections | where State =~ &quot;Started&quot; and Type =~&quot;WVDConnections&quot; | extend Multi=split(_ResourceId, &quot;/&quot;) | extend CState=iff(SessionHostOSVersion==&quot;&lt;&gt;&quot;,&quot;Failure&quot;,&quot;Success&quot;)| where CState=~&quot;Failure&quot; | project TimeStamp=TimeGenerated, UserName, ResourceGroup=Multi[4], HostPool=Multi[8],ResourceAlias, SessionHost=SessionHostName, ClientOS=ClientOS, ClientWvdVersion=ClientVersion, CorrelationId| order by TimeStamp descFailed connection with details: WVDConnections | where State =~ &quot;Started&quot; and Type =~&quot;WVDConnections&quot; | extend Multi=split(_ResourceId, &quot;/&quot;) | extend CState=iff(SessionHostOSVersion==&quot;&lt;&gt;&quot;,&quot;Failure&quot;,&quot;Success&quot;)| where CState =~&quot;Failure&quot;| order by TimeGenerated desc| where State =~ &quot;Started&quot; | extend Multi=split(_ResourceId, &quot;/&quot;) | project ResourceAlias, ResourceGroup=Multi[4], HostPool=Multi[8], SessionHostName ,UserName ,CState=iff(SessionHostOSVersion==&quot;&lt;&gt;&quot;,&quot;Failure&quot;,&quot;Success&quot;), CorrelationId, TimeGenerated| join kind= leftouter (  WVDErrors ) on CorrelationId| extend DurationFromLogon=datetime_diff(&quot;Second&quot;,TimeGenerated1,TimeGenerated)| project TimeStamp=TimeGenerated, DurationFromLogon, UserName, ResourceAlias ,SessionHost=SessionHostName ,Source ,CodeSymbolic , ErrorMessage=Message, ErrorCode=Code, ErrorSource=Source ,ServiceError, CorrelationId| order by TimeStamp descSession logon duration by host pool: WVDConnections | where Type =~&quot;WVDConnections&quot; and State =~ &quot;Started&quot; | extend Multi=split(_ResourceId, &quot;/&quot;) | project ResourceAlias, HostPool=toupper(HP=Multi[8]), SessionHostName , UserName ,CState=iff(SessionHostOSVersion==&quot;&lt;&gt;&quot;,&quot;Failure&quot;,&quot;Success&quot;), CorrelationId, TimeGenerated, ResourceGroup=Multi[4], DesktopGroup_s=toupper(strcat(RG=Multi[4],&quot;. &quot;, HP=Multi[8])) | join kind= leftouter (  WVDCheckpoints ) on CorrelationId| extend DurationFromLogon=datetime_diff(&quot;Second&quot;,TimeGenerated1,TimeGenerated)| where Name=~&quot;RdpStackLogon&quot; | project UserName, ResourceGroup, DesktopGroup_s,SessionHost=SessionHostName, TimeStamp=TimeGenerated1, DurationFromLogon| summarize DurationInSeconds=avg(DurationFromLogon) by HostPool=DesktopGroup_s | render columnchart kind=unstacked ![Registry with values](. . /assets/images/Azure Monitor for WVD/Blog-01-01. png) Session logon duration by user (desc): >WVDConnections | where Type =~&quot;WVDConnections&quot; and State =~ &quot;Started&quot; | extend Multi=split(_ResourceId, &quot;/&quot;) | project ResourceAlias, HostPool=toupper(HP=Multi[8]), SessionHostName , UserName ,CState=iff(SessionHostOSVersion==&quot;&lt;&gt;&quot;,&quot;Failure&quot;,&quot;Success&quot;), CorrelationId, TimeGenerated, ResourceGroup=Multi[4], DesktopGroup_s=toupper(strcat(RG=Multi[4],&quot;. &quot;, HP=Multi[8])) | join kind= leftouter (  WVDCheckpoints ) on CorrelationId| extend DurationFromLogon=datetime_diff(&quot;Second&quot;,TimeGenerated1,TimeGenerated)| where Name=~&quot;RdpStackLogon&quot; | project UserName, ResourceGroup, DesktopGroup_s,SessionHost=SessionHostName, TimeStamp=TimeGenerated1, DurationFromLogon| summarize DurationInSeconds=avg(DurationFromLogon) by HostPool=UserName| order by DurationInSeconds desc Administrative activities over time: WVDManagement | summarize Count=count() by bin(TimeGenerated,15)| render scatterchart ![Registry with values](. . /assets/images/Azure Monitor for WVD/Blog-01-03. png) Good to know: Sepago’s commercial “Azure Monitor for WVD” brings the ready to use Azure workbooks for the session and app monitoring and workbooks for the WVD/AVD backend: ![Registry with values](. . /assets/images/Azure Monitor for WVD/Blog-01-07. png) "
    }, {
    "id": 70,
    "url": "https://blog.itprocloud.de/Windows-Virtual-Desktop-Migrate-from-Fall-to-Spring/",
    "title": "Migrate Azure Windows Virtual Desktop Host Pools from Fall to Spring Release - WVD",
    "body": "2020/05/04 - The long await update from WVD/AVD is public. It comes with a full ARM integration and is natively useable in the Azure Portal. The change from Fall to Spring (the name of both releases) cames without a build-in migration solution right now. You can rebuild your host pools and app groups and manually join your existing session hosts into the new once. With WVDAdmin I added two features to do that directly from the GUI: Migrate a host pool to the Spring update: Creates a new host pool with the same properties as an existing host pool in the Fall updateMove session hosts to another host pool*: Works in each direction and from host pool to host poll in the same version (you can use this additionally to remove an assigned user from a session host). Note: If you are using WVDAdmin V1. 5. 5 or lower (v1. 5. 6 and higher downloads the files from Microsoft if internet access is not blogged): You can only move session hosts from host pool to host pool if you built the session host with WVDAdmin. If not, and you want to use this function with your other deployed session create a folder “ITPC-WVD-PostCustomizing” in C:\ and copy the RDAgent files into this folder and rename the files: Microsoft. RDInfra. RDAgent. msi (rename the file)Microsoft. RDInfra. RDAgentBootLoader. msi (rename the file)Make sure that you rename the files to fit the list above (without version numbers).  But first: If you are new to WVD/AVD Spring update and have never used it before in your subscription, you have to register the service provider Microsoft. DesktopVirtualization (one-time process). You must be the owner of this subscription to do this. Go to your subscription -&gt; Resource providers -&gt; search for “Microsoft. DesktopVirtualization” and click register: The migration process: The easiest way to migrate a Host Pool from Fall to Spring is by using WVDAdmin. If you have not WVDAdmin before, check out this post . Right-click your existing host pool and click: Migrate Host Pool settings to WVD/AVD Spring UpdateSelect a target subscription and resource group (note: be sure not to mix different host pools in one resource group with app groups having the same name. If you do this, you will see that the migration process cannot migrate this app groups)Select a region: The region saved the meta-data and is independent of the region of your session hosts. There are only limited regions todayEnter a name for your new Spring host poolLogoff all usersRight-click a session host and click “Change host pool” (read my note above, if this host was not created with WVDAdmin)Select the target host pool. Spring update host pools are tagged with a ²Check “Keep user assignment” if you migrate aa assigned session hosts and want to keep the assignment. If you uncheck this, the user assignment will be repealedRepeat the step “Right-click your existing host pool and click: Migrate Host Pool settings to WVD/AVD Spring Update” to re-create the icons for your applications. This can only be done if one session host is onlineGive the right user groups permission to the app groups: Click the app group(s) and click the button “Users and groups assignments” and start typing the name of the group(s). Note: I don’t migrate the user permission from the fall update believing that you won’t to add groups instead of single usersCreate a WorkspaceCreate a Workspace right-clicking the workspace note. Create a workspace in the same region as your new host poolRight-click the workspace and add/link the app groups you have createdMove more session hosts to the new host poolRight-click the session host note and select “Change host pool”After that, you should see your resources in the native RD client and in the HTML web site which has a new URL: https://rdweb. wvd. microsoft. com/arm/webclient Debugging/notes:: If you are using WVDAdmin V1. 5. 5 or lower (v1. 5. 6 and higher downloads the files from Microsoft if internet access is not blogged): Moving session host works with host created with WVDAdmin or if you create a folder “ITPC-WVD-PostCustomizing”. Copy the files into it: Microsoft. RDInfra. RDAgent. msi (rename the file) Microsoft. RDInfra. RDAgentBootLoader. msi (rename the file) You cannot have app groups with from different host pools with the same name in one resource group Register Microsoft. DesktopVirtualization service provider The service principal of WVDAdmin needs owner permission to the resource groups containing the app groups to add/remove users The HTML5 client has a new URL: https://rdweb. wvd. microsoft. com/arm/webclient If you “lost” a session host you can add them manually to a host pool by doing: Login to the VMUninstall the RD agent and bootloaderInstall the bootloaderinstall the agent and copy the registration key for the target host pool into the installation screenI record a short video showing the migration process: More details and download: WVDAdmin And get additional information from Freek Berson Official announcement: https://www. microsoft. com/en-us/microsoft-365/blog/2020/04/30/enable-remote-work-faster-new-windows-virtual-desktop-capabilities/ "
    }, {
    "id": 71,
    "url": "https://blog.itprocloud.de/Windows-Virtual-Desktop-Spring-Update,-Spring-Release/",
    "title": "Azure Windows Virtual Desktop - Spring Release / Spring Update with WVDAdmin",
    "body": "2020/04/30 - Azure Windows Virtual Desktop - Spring Release / Spring Update goes public today. I’m tremendously happy about that while this is the next big step that we have eagerly awaited. The spring release gives us some feature and changes that make it even easier to deploy apps and desktops to users: Add groups instead of users to desktops and appsFull integration of the administration of WVD/AVD in the Azure PortalUsing a native ARM deployment instead of the WVD/AVD tenant APILinking app groups and desktops into workspacesand a lot of more thingsEven the administration of WVD/AVD was missing before. This was one reason to build WVDAdmin. I was often asked in the past if WVDAdmin will be unnecessary after the spring release of WVD. My answer: Sure, for the administration, WVDAdmin will not be that important anymore, but some features still add value. That’s why I decided months ago to develop WVDAdmin further and also prepare it for the “Spring Release”. So I am proud to announce that WVDAdmin is ready for the Spring Release starting with the already available version 1. 5. To enable the Spring Release feature set a registry key (the current version will have this enabled by default): HKCU\Software\ITProCloud\WVDAdmin(Reg_DWord) &quot;FeatureSet&quot; = 1 First, register the new service provide Microsoft. DesktopVirtualization on your Azure subscription (one-time process). You must be owner of this subscription to do this. Go to your subscription -&gt; Resource providers -&gt; search for “Microsoft. DesktopVirtualization” and click register: If you restart WVDAdmin you will see the new note “WVD V2” which displays your resources in the Spring Release. Please make sure that your service principal has the right permission to create and administrate your resources (the sp needs owner permission to the resource group containing your host pool, app groups, … to assign users and groups).  But what can you do with WVDAdmin compared to the portal integration? You can (e. g. ): Administrate all resources with a Windows GUICreate “golden images” from template/master VMsRollout several session hosts into differents host pools (in both WVD/AVD releases)Re-use you created WVDAdmin images without any changeHigher flexibility rolling out new session hosts in different ways (you can use different VMSizes and images in one host pool)Easy to use user administration to send messages, logoff, disconnect or shadowing users over the full environment (filterable)…From an architectural perspective, the “Spring Update” is really close to the previews release. But there are a few differences: WVD tenant and tenant groups are no longer used“Workspaces” summarize multiple apps and desktop groups. These apps and desktops are shown in the client grouped by workspacesAll resources like host pools, app groups are ARM resources in the Azure portal. App groups must be in the same region as the host poolsA Workspace can group apps and desktop groups in the same regionThe regions of the session hosts are completely independent of the regions of the host pools (which is great)Today you have only a few regions to roll out host pools and workspaces (which is not so important because you can rollout the  session hosts in any region)And you can assign groups to apps and desktops… Check out my video rolling out session hosts from an existing WVD/AVD image into the spring update (sorry for the bad sound - I will change this later): More details and download: WVDAdmin And get additional information from Freek Berson Official announcement: https://www. microsoft. com/en-us/microsoft-365/blog/2020/04/30/enable-remote-work-faster-new-windows-virtual-desktop-capabilities/ "
    }, {
    "id": 72,
    "url": "https://blog.itprocloud.de/Windows-Virtual-Desktop-Add-Users-and-Groups-to-WVD/",
    "title": "Using Azure AD groups to assign users to Azure Windows Virtual Desktop (WVD)",
    "body": "2020/04/07 - Today (early April), it’s not possible to join groups to application groups or desktop in Windows Virtual Desktop. Users have to be assigned directly with their user principal name (UPN). With WVDAdmin, you can do this by entering or copying the UPN’s into a text field. From Version 1. 4. 7 you have another option: You can now browse the Azure AD for users AND groups to add them.  If you have added users and groups with the new function, WVDAdmin will fill out the text field with the UPN’s of the selected users and group members (only members, no external accounts).  This function doesn’t resolve the missing function in the WVD/AVD but can give you an easier way to handle this until the function is integrated into WVD/AVD itself. Requirement: The service principal needs permission to browse the Azure Active directory. To do this go to the Azure Portal -&gt; Active Directory -&gt; App Registration -&gt; Select your Service Principal -&gt; API PermissionsAdd the permission “Azure Active Directory Graph” -&gt; Application Permission -&gt; Directory. Read. All To be read for the WVD Spring Update you have to give the service principal access to the Graph API: Add the permission “Microsoft Graph” -&gt; Application Permission -&gt; Directory. Read. All To consent the permission and administrator of Azure AD have to grant this: "
    }, {
    "id": 73,
    "url": "https://blog.itprocloud.de/Windows-Virtual-Desktop-Admin-Preview/",
    "title": "WVDAdmin - A native administration Gui for Azure Windows Virtual Desktop - Preview Version",
    "body": "2020/02/26 - Feel free to use it and download the 64-bit Windows application “WVD Admin Preview” from here: WVDAdmin-Preview. msi XML Update file: WVDAdmin. xml "
    }, {
    "id": 74,
    "url": "https://blog.itprocloud.de/Windows-Virtual-Desktop-Language-Packs-Detecting-Host-Pool-and-Tenant-Name/",
    "title": "Azure Windows Virtual Desktop and Language Packs - Detecting Host Pool and Tenant Name issue",
    "body": "2020/02/23 - Language packs on Windows sometimes cause some issues or strange behaviors to some applications. One problem I can reproduce is the impact of the RDAgent from Microsoft - the agent running on a WVD/AVD session host, which makes the connection to the WVD/AVD backend. If no language pack is installed (or not set as the system language), the RDAgent writes some information to the registry naming the Host Pool, Tenant, and more. You can find this data in HKLM:\SOFTWARE\Microsoft\RDMonitoringAgent The RDAgent writes this data at least if the session host at the start: If you have a clean Windows Virtual Machine with an installed and for the whole system activated language pack and if you then install the RDAgent, this information is never written to the registry (the WVD/AVD function itself is working as expected).  If you use this Virtual Machine - or session hosts you built based on this VM - you can no longer detect the WVD-tenant, host pool name from the registry. These also affect my tools using this information: Azure Monitor for WVDAzure Autoscale for WVD (aka “Project MySmartScale”, WorkerAgent)They reference the data to an “unknown” or “staging” host pool path (host pool path is “tenant. hostpool” name). This behavior can lead to misinterpretations. To work-around this peculiar behavior with language packs, I added a new function to both solutions. If the tenant and host pool name can not be discovered by using the registry keys, the agents read the tag “WVD. Path” to get the names. The value in WVD. Path must be in the format: TenantName\TenantGroupName\HostPoolName: The new agents are ready to download: Azure Monitor for WVDAzure Autoscale for WVD (aka “Project MySmartScale”, WorkerAgent)Additionally, WVDAdmin (from version 1. 3. 6) will tag new distributed session hosts automatically. "
    }, {
    "id": 75,
    "url": "https://blog.itprocloud.de/Windows-Virtual-Desktop-Azure-Starter-for-WVD/",
    "title": "Azure Windows Virtual Desktop - Azure Starter for WVD",
    "body": "2020/02/09 - This month I started to build my fourth tool around Microsoft Windows Virtual Desktop. This new one, called “Azure Starter for WVD” is a self-service portal for users using WVD. In this portal, which is a web app with Azure AD authentication, users can start and stop (deallocate) their personal assigned session host - which in this case are VDIs. The user doesn’t need access nor permission to the Azure portal or the virtual machines. The authentication of the web app handles the action itself.  The newest implementation adds a new feature: You can configure that running VMs are deallocated if no user is logged in. That handles in combination with a group policy that personally assigned session hosts to go down after a specific time of idling. A session host can be assigned to a specific user using my admin GUI for WVD: WVDAdmin Go to the documentation and deploy this free solution to Azure: https://github. com/MarcelMeurer/Azure-Starter-for-WVD "
    }, {
    "id": 76,
    "url": "https://blog.itprocloud.de/Windows-Virtual-Desktop-Admin-for-2-tenant-mode/",
    "title": "Using WVDAdmin for Azure Windows Virtual Desktop in 2-AAD-Environment (Microsoft Demo Case)",
    "body": "2020/02/07 - Using Azure Starter for Azure Windows Virtual Desktop in 2-AAD-Environment (Microsoft Demo Case)Usually, the WVD/AVD tenant and the resources (sessions hosts) are in the same AAD tenant. If you have two Azure AD tenant, you can use WVDAdmin with a second service principal to access the session hosts. Example: Azure AD 1 - “my-msft. onMicrosoft. com”Your personal AAD where you have your users, an AD-Controller, AD-Connect (or AD domain services), and other resources. In this AAD you have deployed your WVD/AVD tenant. Azure AD 2 - “microsoft. onMicrosoft. com”You have no high-level permission to the AAD because it’s own by your company and shared with many other users/professionals. In this AAD, you have a subscription (AIR) containing your session hosts. Create the first service principal in “my-msft. onMicrosoft. com”. Configure this service principal as described in the primary guide - except permitting to the resource group containing the session hosts and the vnet (these are in the other tenant). Use the data of this service principal in the welcom dialog of WVDAdmin. Create the second service principal in “microsoft. onMicrosoft. com”. Give the service principal contributor permission to the resource group containing the session hosts and to the vnet for the session host. Open the registry and navigate to HKEY_CURRENT_USER\Software\ITProCloud\WVDAdmin. Add three string value to configure the service principal to access the resource groups AzResAlternativeTenantIdAzResAlternativeAppIdAzResAlternativeAppSecret If you use another tenant group name as “Default Tenant Group” add another string “TenantGroupName” and set your tenant group name. This solution is supported from the current version 1. 3. 3 Read more and download WVDAdmin on the main page "
    }, {
    "id": 77,
    "url": "https://blog.itprocloud.de/Automatic-MSIX-app-attach-scripts/",
    "title": "Automatic MSIX App Attach script for Windows Virtual Desktop",
    "body": "2019/12/01 - Automatic MSIX App Attach script for WVDMicrosoft provides a preview of MSIX app attach for Windows Virtual desktop. MSIX app attach gives you the possibility to only have a few amounts of images and connect your application to them - without installing. That sounds a little bit like App-V, and from a user perspective, this is slightly comparable: You cannot see the application in the file system from outside the app. If you open the app and if you browse to the application folder, you can see this folder. The attaching and links in the start menu “feels” like the use of modern apps from the marketplace. And indeed: The application links in the start menu didn’t refer to the exe-files in the program folder. Configuration of the MSIX packages and assignments: If you are in the Windows Insider program, you can test MSIX app attach in a WVD environment. To do this go to the web site https://docs. microsoft. com/en-us/azure/virtual-desktop/app-attach which explains the process of preparing your Windows insider image and how to stage and register MSIX apps for session hosts und users. If you convert legacy apps to MSIX I recommend the YouTube video of @MSAzureAcademy: https://www. youtube. com/watch?v=6kkPLFgPaN8 Microsoft gives you example scripts to stage, un-stage, register, and un-register MSIX apps. For each app, you have to build these four scripts. While the scrips only differ in a few points, I decided to create one script which does the necessary things for all apps I want to provide. The result is one folder containing a single PowerShell script and a configuration file for my MSIX apps. The structure of the configuration is JSON: {   apps :[  { ​    vhdSrc : \\\\ads01\\Configuration\\WVD\\MSIX\\NotepadPP. vhd ,​    volumeGuid : 9c371391-0000-0000-0000-010000000000 ,​    packageName : notepadpp_7. 8. 1. 0_x64__cqx7y23m1rjgy ,​    parentFolder : MSIX-Apps ,​    sessionTarget :{ ​    hostPools :[ ​     MSIX-Builder ​   ],​    userGroups :[ ​     SW_WVD_All ,​     SW_WVD_NotePadPP ​   ]​   }  },  { ​    vhdSrc : \\\\ads01\\Configuration\\WVD\\MSIX\\FileZilla. vhd ,​    volumeGuid : 2ac99dec-0000-0000-0000-010000000000 ,​    packageName : filezilla_3. 45. 1. 0_x64__cqx7y23m1rjgy ,​    parentFolder : MSIX-Apps ,​    sessionTarget :{ ​    hostPools :[ ​     MSIX-Builder ​   ],​    userGroups :[ ​     SW_WVD_All ,​     SW_WVD_FileZilla ​   ]​   }  } ]}For each application, you have to define the following properties: PropertyNotevhdSrcPath to the expanded MSIX app (as vhd)volumeGuidGuid of the vhdpackageNameName of the MSIX app attach packageparentFolderRoot folder name in your vhdhostPoolsList of host pool names where the package should be applieduserGroupsList of AD groups: Members get the application linked in their start menuProviding the script to users and session hosts: Provide the script AppAttach with the configuration in a folder of a shared network drive. This folder must be readable for all users.  Refer this file by a group policy: Computer Configuration - Policies - Windows Settings - Scripts - Startup Name:    %windir%\System32\WindowsPowerShell\v1. 0\powershell. exe Parameter:  -ExecutionPolicy Unrestricted -File \\ads01\Configuration\WVD\MSIX\AppAttach. ps1 -ConfigFile \\ads01\Configuration\WVD\MSIX\AppAttach. json -Mode VmStart Computer Configuration - Policies - Windows Settings - Scripts - Shutdown Name:    %windir%\System32\WindowsPowerShell\v1. 0\powershell. exe Parameter:  -ExecutionPolicy Unrestricted -File \\ads01\Configuration\WVD\MSIX\AppAttach. ps1 -ConfigFile \\ads01\Configuration\WVD\MSIX\AppAttach. json -Mode VmShutdown User Configuration - Policies - Windows Settings - Scripts - Logon Name:    %windir%\System32\WindowsPowerShell\v1. 0\powershell. exe Parameter:  -ExecutionPolicy Unrestricted -File \\ads01\Configuration\WVD\MSIX\AppAttach. ps1 -ConfigFile \\ads01\Configuration\WVD\MSIX\AppAttach. json -Mode UserLogon User Configuration - Policies - Windows Settings - Scripts - Logoff Name:    %windir%\System32\WindowsPowerShell\v1. 0\powershell. exe Parameter:  -ExecutionPolicy Unrestricted -File \\ads01\Configuration\WVD\MSIX\AppAttach. ps1 -ConfigFile \\ads01\Configuration\WVD\MSIX\AppAttach. json -Mode UserLogoff Where \\ads01\Configuration\WVD\MSIX\ is the path to the script and \\ads01\Configuration\WVD\MSIX\AppAttach. json the JSON-configuration file. Make sure that the GPO is linked to the computer and enable loopback processing: Computer Configuration - Policies - Administrative Templates - System/Group Policy Configure user Group Policy loopback processing mode: Enable - Mode: merge.  Preparing the golden master for the session hosts: To work with MSIX and have the script do the work you have to prepare your golden image: Make sure that you have installed the right version from the insider build Double-check that you have NOT prepared your image with the command line commands described in https://docs. microsoft. com/en-us/azure/virtual-desktop/app-attach#prepare-the-vhd-image-for-azure (Disable Store auto-update and so on). It’s only for the VM concerning the converting process. Copy the PSTools https://docs. microsoft. com/en-us/sysinternals/downloads/psexec to %Windir%\System32 (you need psexec later) Give the service GPSVC the right privileges to mount images: Create a cmd-file with this content: >sc privs gpsvc SeManageVolumePrivilege/SeTcbPrivilege/SeTakeOwnershipPrivilege/SeIncreaseQuotaPrivilege/SeAssignPrimaryTokenPrivilege/SeSecurityPrivilege/SeChangeNotifyPrivilege/SeCreatePermanentPrivilege/SeShutdownPrivilege/SeLoadDriverPrivilege/SeRestorePrivilege/SeBackupPrivilege/SeCreatePagefilePrivilegeOpen an administrative cmd and execute: psexec /s cmd In this service cmd execute the cmd-file to give GPSVC the right permissions (This adds the SeManageVolumePrivilege which allows mounting of images) If you have this done, you can rollout several session hosts (or start with one for testing). If you now log on with different users, each user will see its assigned applications.  Note: If a user logoff the application will be de-registered except if the user an administrator (this will be skipped to avoid unmounting the app package). Download the script and rename it to AppAttach. ps1 "
    }, {
    "id": 78,
    "url": "https://blog.itprocloud.de/PolarConf-2019/",
    "title": "PolarConf 2019 - Building own solutions whit Azure Monitor ",
    "body": "2019/10/16 - In October I visited Finland the very first time to speak at PolarConf and I have to say: It was amazing. A great single track event over two days. It was the first conference where I had a speak with only one track. And I have to say: It’s a really good concept. No half-full tracks and missing the feeling you miss a parallel track (or simple: you have not to decide between two or more tracks). What to say about Finland: It an amazing country in the north of Europe with some touch from the Swedish and Russian cultures. It looks very clear, focused and with a sustainable mindset on the subject of environmental protection. And finally: I love the sauna culture. But back to the conference: I had the chance to talk about building own solutions with Azure Monitor. Finalize the session I put the presentation I held here: [PolarConf 2019 - Build your own Azure Monitor solution. pdf](. . /assets/files/PolarConf 2019 - Build your own Azure Monitor solution. pdf) Site information: One part of my presentation was to show the Tweet count with #PolarConf with Azure Monitor. Thanks to @techmike2kx ![PolarConf Tweets](. . /assets/images/PolarConf Tweets. png) https://polarconf. fi/ "
    }, {
    "id": 79,
    "url": "https://blog.itprocloud.de/Anouncing-Project-MySmartScale/",
    "title": "Announcing the community version of "Project MySmartScale"",
    "body": "2019/10/09 - Windows Virtual Desktop is released and gateways around the world are available - even in Europe which cause in a low latency - perfect. Windows Virtual Desktop supplement the current solutions on the virtualization market like Citrix Application Virtualization and VMware Horizon. It’s focused on running as-a-service in the Azure cloud and it’s very cost-efficient compared to the other vendors. Of course: The tools and the administrative capabilities for WVD/AVD differ from the others - till now. But there is still a niche that is not yet filled - until today. The VMs are running permanently even if no users using the environment which leads to avoidable costs. But there is a solution: Announcement of the community version of Project MySmartScale: “Project MySmartScale” starts and smartly deallocates session hosts for WVD. It learns about the user’s behavior and can actively logoff unused sessions at the right time to save compute power – and money. The solution is 100% based on Azure platform services and fits into the whole “as-a-service” story. But starting and stopping session hosts is not as easy as it sounds: To have the right amount of session hosts ready before users try to login in the morning you must predict the user behavior. And this is what “Project MySmartScale” does: Predict the logon count over time based on historical dataPredict the logon count over time based on the acceleration of logonsStart the sessions hosts a few minutes before they are neededStop/deallocates unused session hosts if they are not needed… Today I make this solution available via GitHub. You can easily deploy the solution into your Azure subscription and start to scale your VWD environment based on the usage. This can save up to 60-70% of the costs compared to a 24/7 pay-as-you-go model. Side-Note: It also scales a Citrix XenApp / Virtual Apps and Desktop environment in Azure without using Citrix Cloud (for IaaS). The free community version supports up to 5 VMs. Feel free to use it: https://github. com/MarcelMeurer/Project-MySmartScale Note:The legal owner of this solution is sepago Gmbh, Dillenburger Str. 83, 51105 Cologne, Germany - https://www. sepago. com "
    }, {
    "id": 80,
    "url": "https://blog.itprocloud.de/Workshop-Azure-Monitor-Examples/",
    "title": "Workshop Azure Monitor - Lessons",
    "body": "2019/09/21 - To get practice in using Azure Monitor, I have prepared some examples. These examples can be recreated with a little PowerShell. I have prepared more complex program parts. These can be found in the “Tools” folder. Finished solutions are stored in the folder “Samples”. GitHub: https://github. com/MarcelMeurer/Workshop-AzureMonitor In the Tools folder there are the following scripts:: . /Add-AzureMonitorData. ps1 -WorpspaceId &lt;WorkSpaceId&gt; -WorpspaceKey &lt;WorpspaceKey&gt; -LogTypeName &lt;LogTypeName&gt; [-TimeStampField &lt;TimeStampField&gt;] -JsonData &lt;JsonData&gt;Send jsonData to the Log Analytics workspace into the given LogTyeName. TimeStampField is not mandatory. If given, it must be the name of the field containing the timestamp of each data set. Missions: Store information about the running processes from your computer: Collect the process information from your computer each 30 seconds and send these data to your Log Analytics workspace. Use PowerShell to automate this mission. Select an app and use this app to “overload” your CPU. If data are visible in Log Analytics, build a custom dashboard by using “Log” to query the data. Find out: Count of distinct processesAverage CPU load over time (all processes). Render a time chartRender a time chart for the app you used to overload the CPUSome useful PowerShell commands: #Get cpu consumption by process(Get-Counter  \process(*)\% Processor Time ). CounterSamples#Convert objects to $json=$object | ConvertTo-Json Store temperature data for multiple cities: Collect data from OpenWeatherMap for three different cities each 30 seconds. Send the data to your Log Analytics workspace using Add-AzureMonitorData. ps1. Use PowerShell to automate this mission. If data are visible in Log Analytics, build a custom dashboard using the View Designer within Log Analytics. Build: One overview tile showing the number of the different citiesTwo dashboards showing the temperature and humidity as a chart and as a list per cityConnect PowerBi Dekstop to your data: Display Line Charts and use a selector/filter for the cities (drop down field)Hints: Collect data from OpenWeatherMap https://openweathermap. org/Create an account and api keyTest your key (it can take some minutes):https://api. openweathermap. org/data/2. 5/weather?q=Bonn&amp;APIKEY=xxxxxxxSome useful PowerShell commands: #Endless-loopdo {  } while ($true)#Sleep $n secondssleep $n #make a http requestInvoke-WebRequest -Uri $uri -Method GET -ContentType “application/json” Build your own log-writer function: Build a log-writer function for your own PowerShell scripts using Log Analytics. There are some request to your solution: Have the following columns:TimeStamp (as TimeGeneratedField)Serverity (Debug|Information|Warning|Error)Message (Text)ScriptName (Name of the script using your function)"
    }, {
    "id": 81,
    "url": "https://blog.itprocloud.de/Speaking-update/",
    "title": "On the road - My next speaking engagements",
    "body": "2019/09/07 - I’m happy to be a part of a great community.  On my journey, I have the possibility to speak at some conferences, meetups and other events. And I loved it. Especially, if I can talk about Azure, IoT, Machine Learning, AI, Azure Monitor, etc. Maybe we will meet personally at one of the next events: "
    }, {
    "id": 82,
    "url": "https://blog.itprocloud.de/CDC-Germany-RDS-&-Windows-Virtual-Desktop-Desktops-in-2019/",
    "title": "CDC Germany: RDS and Windows Virtual Desktop – Desktops in the year 2019 and beyond",
    "body": "2019/05/23 - From 21. to 22. April 2019 the annual Cloud and Datacenter Conference took place in Hanau/Frankfurt in Germany. It’s one of my favorite community events in Germany. This year I was allowed to contribute something to RDS in Windows Server 2019 and Windows Virtual Desktop – including Windows 10 Multi Session Host and FSLogix (an awesome combination). I published my slides to slideshare. net:https://de. slideshare. net/MarcelMeurer/rds-windows-virtual-desktop-desktop-in-2019 The demos are also available via Youtube:: Windows Virtual Desktop - Login to a shared Windows 10 Multi Session Host: https://youtu. be/rgsaQf3hmHw Windows Virtual Desktop - Update the template VM: https://youtu. be/YqrEm3EhbVY Windows Virtual Desktop - Build a new Image from a template VM: https://youtu. be/MOuH482A1co Windows Virtual Desktop - Deploy a VM from a template via PowerShell: https://youtu. be/U9zxyk_HuAM Windows Virtual Desktop - Deploy a Scale Set from an image, re-scale, Azure Monitor: https://youtu. be/_l5P_JeQANM Fist published on: https://www. sepago. de/blog/cdc-germany-rds-windows-virtual-desktop-desktops-in-2019/ "
    }, {
    "id": 83,
    "url": "https://blog.itprocloud.de/Publish-your-solution-to-the-Azure-Marketplace/",
    "title": "Publish your solution to the Azure Marketplace",
    "body": "2019/03/25 - Publishing own solutions to the Azure Marketplace seems to be very easy by using the documentation on https://docs. microsoft. com/en-us/azure/marketplace/marketplace-publishers-guide. To avoid any pitfalls I wrote down some insights about my first approach. In this blog, I will focus on “Azure Applications” The Cloud Partner Dashboard: Make sure that you have access to the Cloud Partner Portal at https://cloudpartner. azure. com. In my case, I use my coopered credentials to log in. Assign your Dev Center account details via Publisher Profile: Hint:I had some trouble doing this. My Dev Center account was not accepted. The reason was that my Dev Center account and my cooperated account names are/aren’t similar. A Dev Center account is always an MSA (former live id). So, I couldn’t invite this account into the Cloud Partner portal. My workaround: Create a new MSA, e. g. myname. dev@outlook. comCreate a new Dev Center account with the new MSA: https://developer. microsoft. comAdd the new MSA into the Cloud Partner PortalAssign your Dev Center accountPrepare your publishing package: Publishing (-) Azure Applications means that you provide an ARM template and other resources, like: mainTemplate. jsoncreateUiDefinition. json (https://docs. microsoft. com/en-us/azure/managed-applications/create-uidefinition-overview)nestedtemplates. …. json (for linked templates)and maybe some other foldersAll the files must be in a zip archive for (-) further upload. The folder structure is important and createUiDefinition. json and mainTemplate. json are mandatory. The ARM templates and the create UI are checked by Microsoft before your offer is available to the public. To avoid some iterations, make sure that you have observed the following things: ARM TemplatesDo not reference external sources like nested templates on GitHub – everything must be in the packagemaintemplate. json must have a “parameters” propertyParameters without defaultValue s. They must have a corresponding output in createUiDefinition. jsonA parameter named “location” must exist and it must have a defaultValue of resourceGroup(). locationUse the correct API versions#VM Image ref must not contain “-preview”Do not concat Ids like:”[Concat(’/subscriptions/’, parameters(‘subscriptionId’), ‘/resourceGroups/’, parameters(‘resourcegroup’), ‘/providers/Microsoft. OperationalInsights/workspaces/’, parameters(‘workspace’))]”use resourceId:”[resourceId(‘Microsoft. OperationalInsights/workspaces’, parameters(‘workspace’))]createUiDefinition. jsonMust have a schema propertyHandler property value should be ‘Microsoft. Compute. MultiVm’Version property value must match schema versionMust have parameters and output(-) propertiesOutput location must be present in mainTemplate parametersOutput workspace must be present in mainTemplate parametersParameters should have basics and steps propertiesLocation must be in outputs and should match [location()]Do not say that a user has to enter a unique name (e. g. for a web app) – generate a unique name with an appendix (use uniqueString()), e. g. :”[concat(parameters(‘resourcename’),’-’, uniqueString(resourceGroup(). id,subscription(). subscriptionId))]”Text boxes (for names) must have a regex constraintText boxes (for names) must have a validationMessagePublish your package for a private test: After you have zipped your package, you can create a new “Azure Application” offer in the Cloud Partner portal. Select a new offer, Azure application and fill out the fields. Publish it for your personal test (add your subscription id to make it visible).  Publish your package to the public: After you have tested your package privately, you can apply to make it public to the world. This takes some time while automatism and a (human) reviewer check your templates. If something is invalid, you get a mail with a link to a pull request where you can check what’s wrong. Fist published on: https://www. sepago. de/blog/publish-your-solution-to-the-azure-marketplace/ "
    }, {
    "id": 84,
    "url": "https://blog.itprocloud.de/Why-configuring-Azure-AD-authentication-with-an-Azure-Web-App-fails/",
    "title": "Why configuring Azure AD authentication with an Azure Web App fails",
    "body": "2019/02/09 - I spent hours today adding Azure AD authentication to an Azure MVC web application with Visual Studio. I always got the same error while adding the preconfigured AD application: “Error: Unable to query for Azure AD applications: An error occurred while processing this request. ” My account has the right permission in Azure AD – I thought. After a while I found out: Visual Studio was connected to my Azure AD with three different accounts: Normally, that’s what I want, even if I have to publish some apps in other tenants/subscriptions. But in this special case two accounts are part of the Azure tenant where my Azure applications should be deployed: Visual Studio uses the first account (marked in red), which does not have the appropriate permissions. My “fast” resolution: I gave this account the right Azure AD role (Application Administrator) for 5 minutes and tried again with success: First published on: https://www. sepago. de/blog/why-configuring-azure-ad-authentication-with-an-azure-web-app-fails/ "
    }, {
    "id": 85,
    "url": "https://blog.itprocloud.de/Deploy-an-Azure-Functional-App-as-an-interface-to-Log-Analytics-Azure-Monitor/",
    "title": "Deploy an Azure Functional App as an interface to Log Analytics / Azure Monitor",
    "body": "2019/01/13 - IntroductionMicrosoft offers with Log Analytics a cloud-based big data service. Log Analytics is used by several services (including Azure itself) to log and analyze data. It’s a core component of Azure Monitor and Application Insights. Log Analytics key facts: Cloud-basedNo data aggregationPay per upload and data retentionPowerful query language (kql: &lt;https://docs. microsoft. com/en-us/azure/kusto/&gt;)Direct support for visualization on portal. azure. comI use Log Analytics for several projects where data aggregation and analyzation are main tasks. If I write code, I push data directly to Log Analytics – including generating a SAS signature for every single upload. The mandatory SAS signature avoids a simple upload via http-post to Log Analytics. But in some cases, it could be very helpful to work with a simple http-post command. For example: If you use Azure Stream Analytics, you cannot push data directly to Log Analytics. To allow pushing data via http-post I built this project. This project deploys an Azure function to your subscription. This function offers a simple http(s) interface (webhook) you can use to post JSON data to it. This data will be processed by the Azure Function and will be posted to your Log Analytics workspace. Examples:With Postman: With PowerShell: $data='{ localTime : 2019-01-02T11:11:12. 013Z , Humi :46. 5, Temp :14. 2}'Invoke-WebRequest -Uri “https://testaf01xx8. azurewebsites. net/api/Send2LogAnalytics?code=xje5aQIMzPxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx==” -Method POST -Body $data With Stream Analytics: Query: INTO[To-Function]FROM[From-IoT-Hub] Output: Enter your Azure Function parameters Results in Log Analytics: For another data series Deploying and configurationDeploy your Azure Function using the deploy to Azure button.  Github: https://github. com/MarcelMeurer/FunctionApp-to-LogAnalytics Configuration: In the next step enter the following parameters: Resource Group:Select an existing or create a new resource group in a location of your choice (the function will be deployed in the Azure region of the resource group)Site name:A unique name of your function (unique means a worldwide unique hostname; the fqdn is: . azurewebsites. com)Workspace_Id:The workspace id of your Log Analytics workspace (Log Analytics resource -&gt; Advanced settings -&gt; Workspace id)Workspace_Key:The workspace id of your Log Analytics workspace (Log Analytics resource -&gt; Advanced settings -&gt; Primary or secondary key)LogType:Name of your type (“table” name). You will see this name with an appended _CL (custom log) later in your workspace with your dataTime Field:Optional. All data sets you send get a new field called “TimeGenerated”. TimeGenerated contains the time the data arrived at the workspace. If you set Time field to a custom field (like localTime from the example above), the time in this field is used as TimeGenerated. Hint: Workspace_Id, Workspace_Key, LogType, Time Field can be changed later in the function app: Your Function app -&gt; Platform features -&gt; Application settings Resources: After the deployment three resources are deployed and configured: ServerFarmPlan:A consumption-based pricing plan for the Azure Functional App. See https://azure. microsoft. com/en-us/pricing/details/functions/ check the estimated costs billed to your subscriptionSite name - Application Insights:Application Insights to monitor the Azure Function itselfSite name - Azure Functional App:The Azure Function containing the codeGet the resource URL of the Azure Function: Open your Azure Function and navigate to Functions -&gt; Send2LogAnalytics -&gt; &lt;/&gt; Get function URL This URL contains your private key. First published on: https://www. sepago. de/blog/deploy-an-azure-functional-app-as-an-interface-to-log-analytics-azure-monitor/ "
    }, {
    "id": 86,
    "url": "https://blog.itprocloud.de/Creating-devices-for-Azure-IoT-Hub-with-SAS-token-automatically/",
    "title": "Creating devices for Azure IoT Hub with SAS token automatically",
    "body": "2018/11/23 - A few weeks ago, I started an IoT project with a company responsible for a huge amount of different buildings around the world. We deployed several virtual and physical sensors in Azure IoT Hub. Doing this we had three challenges: Deploy new IoT devices in Azure IoT hub in a batchGenerate SAS tokens for these IoT devicesGenerate SAS tokens even if a device still exist in Azure IoT HubThe requirement of batch processing avoids the use of the Device Explorer to generate SAS token. Therefore, I wrote a short PowerShell script: function New-SASToken{PARAM([Parameter(Mandatory=$True)][string]$ResourceUri,[Parameter(Mandatory=$True)][string]$Key,[string]$KeyName=  ,[int]$TokenTimeOut=1800 # in seconds)[Reflection. Assembly]::LoadWithPartialName( System. Web )| out-null$Expires=([DateTimeOffset]::Now. ToUnixTimeSeconds())+$TokenTimeOut#Building Token$SignatureString=[System. Web. HttpUtility]::UrlEncode($ResourceUri)+  `n  + [string]$Expires$HMAC = New-Object System. Security. Cryptography. HMACSHA256$HMAC. key = [Convert]::FromBase64String($Key)$Signature = $HMAC. ComputeHash([Text. Encoding]::ASCII. GetBytes($SignatureString))$Signature = [Convert]::ToBase64String($Signature)$SASToken =  SharedAccessSignature sr=  + [System. Web. HttpUtility]::UrlEncode($ResourceUri) +  &amp;sig=  + [System. Web. HttpUtility]::UrlEncode($Signature) +  &amp;se=  + $Expiresif ($KeyName -ne  ){$SASToken=$SASToken+ &amp;skn=$KeyName }return $SASToken}function New-IoTDevice{PARAM([Parameter(Mandatory=$True)][string]$IoTHubConnectionString,[Parameter(Mandatory=$True)][string]$DeviceId)[Reflection. Assembly]::LoadWithPartialName( System. Web )| out-null$strings=$IoTHubConnectionString. split( ; )$keys =@{}for ($i=0; $i -lt $strings. count; $i++){$keys[$strings[$i]. split( = )[0]]=$strings[$i]. split( = )[1]}$keys[ SharedAccessKey ]=$keys[ SharedAccessKey ]+ = $body='{deviceId: '+$DeviceId+' }'try{$webRequest=Invoke-WebRequest -Method PUT -Uri  https://$($keys[ HostName ])/devices/$([System. Web. HttpUtility]::UrlEncode($DeviceId))?api-version=2018-06-30  -ContentType  application/json  -Header @{ Authorization = (New-SASToken -ResourceUri $keys[ HostName ] -Key $keys[ SharedAccessKey ] -KeyName $keys[ SharedAccessKeyName ])} -Body $body -UseBasicParsing} catch [System. Net. WebException]{if ($_. Exception. Response. StatusCode. value__ -eq 409){write-host  Device exists. Getting data from IoT hub $webRequest=Invoke-WebRequest -Method GET -Uri  https://$($keys[ HostName ])/devices/$([System. Web. HttpUtility]::UrlEncode($DeviceId))?api-version=2018-06-30  -ContentType  application/json  -Header @{ Authorization = (New-SASToken -ResourceUri $keys[ HostName ] -Key $keys[ SharedAccessKey ] -KeyName $keys[ SharedAccessKeyName ])} -UseBasicParsing}else{Write-Error  An exception was caught: $($_. Exception. Message) }}return ConvertFrom-Json $webRequest. Content}function Send-IoTDeviceTestString{PARAM([Parameter(Mandatory=$True)][string]$sasToken)[Reflection. Assembly]::LoadWithPartialName( System. Web )| out-null$t1=[System. Web. HttpUtility]::UrlDecode($sasToken)$t2=$t1. Split( = )$t3=$t2[1]. Split( &amp; )[0]$deviceId=$t3. Split( / )[2]$iotHubDeviceHost=$t3$iotHubRestURI = “https://$($iotHubDeviceHost)/messages/events?api-version=2018-04-01”#$iotHubRestURI$Headers = @{“Authorization” = $sasToken; “Content-Type” = “application/json”}# Message Payload$datetime = get-date$body = @{datetime = $datetimedeviceId = $deviceIdMessage = “Sending data to iot hub”}$body = $body | ConvertTo-Jsonreturn Invoke-RestMethod -Uri $iotHubRestURI -Headers $Headers -Method Post -Body $body} #$iotHubName = “Workshop-IoT” # host name of the iot hub$iotManagementConnectionString=“HostName=Workshop-IoT. azure-devices. net;SharedAccessKeyName=iothubowner;SharedAccessKey=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx” # insert the connection string of your iot hub # name of the new devices$array = @(“TestDev1”,“SEPAGO_HBS2. 0_DE_Cologne_HQ_VDEV_ISP08-IO0”,“SEPAGO_HBS2. 0_DE_Cologne_HQ_VDEV_ISP08-RTU”) foreach ($deviceId in $array){Write-Host “New device created: $($deviceId)”$device=New-IoTDevice -IoTHubConnectionString $iotManagementConnectionString -DeviceId $deviceId$sasToken=New-SASToken -ResourceUri ”$($iotHubName). azure-devices. net/devices/$([System. Web. HttpUtility]::UrlEncode($device. deviceId))” -Key $device. authentication. symmetricKey. primaryKey write-host “DeviceId:”,$device. deviceIdwrite-host “SASToken:”,$sasToken$deviceConfigSend-IoTDeviceTestString -sasToken $sasTokenwrite-host(”–––––––––––––”)} Feel free to use it in your projects. Feedback welcome First published on: https://www. sepago. de/blog/creating-devices-for-azure-iot-hub-with-sas-token-automatically/ "
    }, {
    "id": 87,
    "url": "https://blog.itprocloud.de/OneDrive-PowerShell-Module-Added-support-for-OneDrive-for-Business/",
    "title": "OneDrive PowerShell Module - Added support for OneDrive for Business",
    "body": "2018/11/05 - More than two years ago, I created my PowerShell module to access OneDrive. This module can be installed with a one-liner from https://www. powershellgallery. com/packages/OneDrive Again, I was asked to support OneDrive for Business and finally, I’m ready: From version 2. 0. 0 OneDrive for Business is supported. I provide the complete documentation on GitHub, where I will maintain it: https://github. com/MarcelMeurer/PowerShellGallery-OneDrive Here is the summary of version 2. 0. 0: -——————————————— The OneDrive PowerShell module is available via PowerShellGallery. com. If you want to support and work with me feel free to make changes cloning this repo, change and send me and a pull request. This OneDrive version (2. 0. 0 and higher in PowerShellGallery. com) supports: OneDrive personalOneDrive for BusinessInstallation: Open PowerShell and Install-Module -Name OneDrive -Scope CurrentUser -forceYou can update the module to a newer version with the same command (-force). If you don’t use PowerShellGet currently, go to the Gallery on https://www. powershellgallery. com/packages/OneDrive and click “Get Started”. Check your installation with Get-Help -Name OneDrive Authentication: Before you start using the OneDrive module you have registered your script/application. This differs depending on the OneDrive version to be used. OneDrive Personal: Read this on my blog: https://www. sepago. de/blog/onedrive-powershell-module-new-version-with-improved-authentication/ Go to: https://apps. dev. microsoft. com and login with your Microsoft Account (MSA) and “Add an app” in the category “converged applications”Enter a name and press “create”Press “Generate New Password” and save the password (app key)Also, save the “Application id”Press “Add Platforms” and select “Web”Check “Allow implicit Flow” and enter a “Redirect URL”. This is not a real URL. Choose a localhost address and note it. In my case, I chose: http://localhost/loginPress “Save”Now you have all the necessary data for your app/script:Client Id: 5dd40b03-0ead-451b-b5e3-f704550e8ccaAppKey: xqacs8K92MuCJKgciRHQ1CfRedirectURI: http://localhost/loginTo get an authentication token use:$Auth=Get-ODAuthentication -ClientID 5dd40b03-0ead-451b-b5e3-f704550e8cca -AppKey xqacs8K92MuCJKgciRHQ1Cf -RedirectURI http://localhost/login OneDrive for Business: To use OneDrive for business you have to register your script/app to in Azure Active Directory Add an application in Azure Active Directory inside the Azure portal: https://portal. azure. com/#blade/Microsoft_AAD_IAM/ActiveDirectoryMenuBlade/RegisteredApps Chose “New application registration” Give your application a name and a unique sign-on URL. The sign-on URL has to be a valid URL but doesn’t have to exist. E. g. : http://sepago. de/1Drive4Business (make later sure that this URL is in the reply URL list of your application) Within the “Required permissions” add “Office 365 SharePoint Online (Microsoft. Sharepoint)” Select “Read and write user files” below “delegated permissions” for the Office 365 API Generate a secret key for this application and save it for later use. Also, save the application Id You should now have the following parameter: Client Id: 2831fc52-e1b8-4493-9f3a-a3dad74b2081AppKey: TqoSXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX=RedirectURI: http://sepago. de/1Drive4BusinessAdditionally you need the resource URL for OneDrive for Business. Normally: https://-my. sharepoint. com/. In our company this is the URL “ https://sepagogmbh-my. sharepoint. com/ “ (the last one / is important). Resource ID: https://sepagogmbh-my. sharepoint. com/To get an authentication token use: $Auth=Get-ODAuthentication -ClientId  2831fc52-e1b8-4493-9f3a-a3dad74b2081  -AppKey  TqoSXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX= &amp;nbsp; -RedirectURI  http://sepago. de/1Drive4Business  -ResourceId  https://sepagogmbh-my. sharepoint. com/ Renew the authentication with a refresh token: An access token is 1 hour valid. You can get a new access token with the refresh token provided by the last authentication. This is necessary if you are creating a script that will work for a long time without further user input. Renew your access token automatically in the program code. $Auth=Get-ODAuthentication -ClientId 2831fc52-e1b8-4493-9f3a-a3dad74b2081 -AppKey  TqoSXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX=  -RedirectURI  http://sepago. de/1Drive4Business  -ResourceId  https://sepagogmbh-my. sharepoint. com/  -RefreshToken $LastAuth. refresh_tokenWhere $LastAuth is your last authentication result (containing the refresh token)For OneDrive personal leave the ResourceId empty (-ResourceId “”)Working with files and folders: Get an authentication code from above and store it in $Auth List files and folders: Get-ODChildItems -AccessToken $Auth. access_token -ResourceId  https://sepagogmbh-my. sharepoint. com/  -path  / List files and folders: Remove-ODItem -AccessToken $Auth. access_token -ResourceId “https://sepagogmbh-my. sharepoint. com/” -path “/Upload” Creating a folder: New-ODFolder -AccessToken $Auth. access_token -ResourceId  https://sepagogmbh-my. sharepoint. com/  -path  /  -FolderName  Upload Upload local files to OneDrive: Add-ODItem -AccessToken $Auth. access_token -ResourceId  https://sepagogmbh-my. sharepoint. com/  -LocalFile  D:\DEV\PowerShell\PowerShellGallery-OneDrive\Test\Uploads\IoT Workshop. pptx  -Path  /Upload List OneDrive drives: Get-ODDrives -AccessToken $Auth. access_token -ResourceId  https://sepagogmbh-my. sharepoint. com/ Downloading some files: Get-ODItem -AccessToken $Auth. access_token -ResourceId  https://sepagogmbh-my. sharepoint. com/  -Path  /Upload/Doings. txt  -LocalPath  D:\DEV\PowerShell\PowerShellGallery-OneDrive\Test\Downloads Get-ODItem -AccessToken $Auth. access_token -ResourceId “https://sepagogmbh-my. sharepoint. com/” -Path ”/Upload/Doings. txt” -LocalPath “D:\DEV\PowerShell\PowerShellGallery-OneDrive\Test\Downloads” -LocalFileName “Copy from OneDrive. Doings. txt” Delete a file in OneDrive: Remove-ODItem -AccessToken $Auth. access_token -ResourceId  https://sepagogmbh-my. sharepoint. com/  -Path  /Upload/Doings. txt First published on: https://www. sepago. de/blog/onedrive-powershell-module-added-support-for-onedrive-for-business/ "
    }, {
    "id": 88,
    "url": "https://blog.itprocloud.de/Working-with-the-OneDrive-PowerShell-Module/",
    "title": "Working with the OneDrive PowerShell Module",
    "body": "2018/09/29 - Recently I got some questions on how to work with my PowerShell module for OneDrive. Therefore, I put together some examples. Remember: The OneDrive module is for OneDrive personal and doesn’t work with OneDrive business / Sharepoint. First: Register an app (authentication) for OneDrive: https://www. sepago. de/blog/onedrive-powershell-module-new-version-with-improved-authentication/ Authenticate to OneDrive: $Authentication=Get-ODAuthentication -ClientID &quot;xxxxxxxxxxxxxxxxxxxxxxx&quot; -AppKey &quot;yyyyyyyyyyyyyyyy&quot; -RedirectURI &quot;http://localhost/login&quot;$at=$Authentication. access_token Show files and folders: Get-ODChildItems -AccessToken $at -path  /  Create a new folder in OneDrive New-ODFolder -AccessToken $at -FolderName  Images  Copy files from local to OneDrive Add-ODItem -AccessToken $at -LocalFile  . \LA-02. jpg  -Path  /Images  Copy file from OneDrive to local disk Get-ODItem -AccessToken $at -Path  /Images/LA-02. jpg  -LocalPath  D:\Local\downloads Get-ODItem -AccessToken $at -Path  /Images/LA-02. jpg  -LocalPath  D:\Local\downloads  -LocalFileName  Copy from OneDrive. jpg  Delete file in OneDrive Remove-ODItem -AccessToken $at -Path  /Images/LA-02. jpg  First published on: https://www. sepago. de/blog/working-with-the-onedrive-powershell-module/ "
    }, {
    "id": 89,
    "url": "https://blog.itprocloud.de/Adding-Guest-Users-to-Azure-AD-from-Excel-with-PowerShell/",
    "title": "Adding Guest Users to Azure AD from Excel with PowerShell",
    "body": "2018/07/13 - Sharing access across different tenants in one of the key benefits of Azure AD. My customers appreciate that they can provide Azure-based solution to their cooperated users and to guest users as well. Cooperated users include users from the group and subsidiaries. They all can access resources with one identity – on-premises and in the cloud (Same-sign-on, single-sign-on). Guest users can be deployed manually via the Azure portal, via PowerShell or with a connector to another system (like SAP HR). Adding users from an Excel file can be done with PowerShell. To show an example I created an Excel file with some headers: CompanySurnameNameMailJob role To add this user, we must archive these steps: Login into Azure AD with appropriate rightsEnumerate through the excel tableInviting the userAdding the right properties (company, name, surname, …) to the invited user objectTo do this I prepared this script: $invocation = (Get-Variable MyInvocation). Value$directorypath = Split-Path $invocation. MyCommand. Path$directorypath$ExcelFile=$directorypath+”\Users2Invite. xlsx” # Path to the excel file$InviteRedirectURL=“https://mycompany. com” # Redirect url after the first logon$WorkSheetNum=“Tabelle1” # Name of the table in the excel file if (!$lastLogin) {# put your Azure AD tenant id here (Azure portal / Azure Active Directory / Properties / Directory ID)$global:lastLogin=Connect-AzureAD -TenantId “xxxxxxxxxxxxx-xxxxxxxx-xxxxxxxxxxx-xxxxxxxxxxx”} $Excel = New-Object -ComObject Excel. Application $WorkBook = $Excel. Workbooks. Open($ExcelFile)$WorkSheet = $WorkBook. WorkSheets. Item($WorkSheetNum) $RowNum = 2 While ($WorkSheet. Cells. Item($RowNum, 1). Text -ne ””) {# Read the first line from sheet$Company = “Ext: “+$WorkSheet. Cells. Item($RowNum, 1). Text. trim()$Surname = $WorkSheet. Cells. Item($RowNum, 2). Text. trim()$Name = $WorkSheet. Cells. Item($RowNum, 3). Text. trim()$Mailadress = $WorkSheet. Cells. Item($RowNum, 4). Text. trim()$JobTitle = $WorkSheet. Cells. Item($RowNum, 5). Text. trim()$userFullName=$Name+”, “+$Surname Write-Output(“Adding user: “+$userFullName+” (”+$Mailadress+”)”)$invitation=New-AzureADMSInvitation -InvitedUserDisplayName $userFullName -InvitedUserEmailAddress $Mailadress -SendInvitationMessage $true -InviteRedirectURL $InviteRedirectURL$user = Get-AzureADUser -ObjectId $invitation. InvitedUser. IdSet-AzureADUser -ObjectId $invitation. InvitedUser. Id -Surname $NameSet-AzureADUser -ObjectId $invitation. InvitedUser. Id -GivenName $SurnameSet-AzureADUser -ObjectId $invitation. InvitedUser. Id -JobTitle $JobTitleSet-AzureADUser -ObjectId $invitation. InvitedUser. Id -Department $CompanySet-AzureADUser -ObjectId $invitation. InvitedUser. Id -Displayname $user. Displayname$RowNum++} If you run this script all users in the excel file will be invited to your Azure AD tenant. Remark: The company field can not be written to an Azure AD user object (read-only). So I write the company to the department field. First published on: https://www. sepago. de/blog/adding-guest-users-to-azure-ad-from-excel-with-powershell/ "
    }, {
    "id": 90,
    "url": "https://blog.itprocloud.de/Enumerating-Azure-AD-administrative-accounts-with-PowerShell/",
    "title": "Enumerating Azure AD administrative accounts with PowerShell",
    "body": "2018/06/22 - Users can have different administrative roles in Azure Ad. Azure Portal can show these roles and members. Sometimes it can be favorable to get roles and members in a PowerShell object list. To login into your Azure AD tenant use: Connect-AzureAD -TenantId xxxWhere xxx is your tenant id. The -TenantId is optional. But if your account member of different Azure ADs you can select the right one. After login in with your credential you can show the different roles with: Get-AzureADDirectoryRoleOutput: Using PSCustomObject helps to build a list/array of custom objects to save all roles and users. The full code: $roleUsers = @() $roles=Get-AzureADDirectoryRoleForEach($role in $roles) {$users=Get-AzureADDirectoryRoleMember -ObjectId $role. ObjectIdForEach($user in $users) {write-host $role. DisplayName,$user. DisplayName$obj = New-Object PSCustomObject$obj | Add-Member -type NoteProperty -name RoleName -value ””$obj | Add-Member -type NoteProperty -name UserDisplayName -value ””$obj | Add-Member -type NoteProperty -name IsAdSynced -value false$obj. RoleName=$role. DisplayName$obj. UserDisplayName=$user. DisplayName$obj. IsAdSynced=$user. DirSyncEnabled -eq $true$roleUsers+=$obj}}$roleUsers Output: Feel free to extend the custom object with other values form Azure AD user object. First published on: https://www. sepago. de/blog/enumerating-azure-ad-administrative-accounts-with-powershell-2/ "
    }, {
    "id": 91,
    "url": "https://blog.itprocloud.de/Deploying-a-custom-OMS-Log-Analytics-Workspace-via-GitHub-Avoid-problems-with-ARM-templates/",
    "title": "Deploying a custom OMS Log Analytics Workspace via GitHub – Avoid problems with ARM templates",
    "body": "2018/05/03 - Azure is “my” cloud with a lot of platform services allowing users, programmers, and DevOps building powerful and scalable solutions. One of my favorite ones is Azure OMS Log Analytics – a big data platform with a great query language and professional dashboards. In the past, I build a custom agent to collect data from Microsoft RDS and Citrix environment to provide a deep insight into the user experiences and resource usage http://loganalytics. sepago. com/. Additionally, I have built four dashboards and a lot of views to visualize the data:  To make it easier to deploy an OMS Log Analytics workspace including my tiles and views I decided to offer a “Deploy to Azure” solution via GitHub. Finally, an ARM template for an Azure deployment. One ARM template including all resources (doesn’t work well) First, I built an ARM template including the workspace definition and four definitions of the tiles (including their views). But I got some weird effects: Sometimes I got only 2 tiles with a deployment, sometimes 3 and rarely the four I expected. What happens – or what I thought what happened? The tile definition in the ARM files is independent of each other’s, so the ARM engine tried to deploy them parallel. And here is a problem: This didn’t (and don’t) work with the current API. The API didn’t wait for the full deployment and finished after the first tile is deployed. One ARM template for the deployment and one for each tile (works well) It took days to find a reliable solution. The solution I use now works differently: I have one ARM template for each tile and one ARM template for the workspace itself. The ARM template for the workspace references all the four tile ARM templates using the resource type “Microsoft. Resources/deployments”. This deployment type allows a special trick to avoid the parallel processing of all linked templates: A serial mode! The serial mode controls the ARM processing and avoids parallel processing. With this trick, the deployment works reliably. See the ARM templates at GitHub: https://github. com/MarcelMeurer/LogAnalytics-for-Citrix-and-RDS/ To help the community to find this workaround some keywords: “Azure OMS Log Analytics Deployment with ARM some tiles are missing” First published on: https://www. sepago. de/blog/deploying-a-custom-oms-log-analytics-workspace-via-github-avoid-problems-with-arm-templates/ "
    }, {
    "id": 92,
    "url": "https://blog.itprocloud.de/Monitoring-End-User-Computing-Environments-with-Azure-OMS-LogAnalytics-with-Deploy-to-Azure/",
    "title": "Monitoring End-User Computing Environments with Azure OMS LogAnalytics with Deploy to Azure",
    "body": "2018/03/31 - Several months ago, I built a solution focused on monitoring the user experiences on remote desktop environments based on Citrix XenApp, XenDesktop and Microsoft RDS. Particularly RDS/RDP was imported because there is no solution from Microsoft. End-user computing environments are complex and not easy to monitor. The most common monitoring solutions are focused on typical server parameters like CPU and memory consumption, free disk space and so on. But administrators need more insight into the parameters responsible for the user experience like bandwidth, latency, utilization of the virtual hardware by application, etc. To meet these demands, I decided to build a solution considering the following requirements: Storing the raw data without aggregation to an average value per hour. I need the data per minute – for all timesI need a “time back” mode to look back in the RDS environment to each time frame in the pastAvoidance of any Infrastructure-as-a-service like a Windows application server, SQL database or the likeIt was obvious to use an Azure service as a platform for my solution.  And so, I built my solution based on Azure OMS LogAnalytics. Azure OMS offers a “big-data style” platform to save, index, query and visualize data. The core part of this solution is my small agent: Installed on each worker (Citrix or Microsoft) it collects, combines and uploads data to your personal Azure OMS Log Analytics workspace. And of course: It offers monitoring of RDS/Citrix workers in any cloud as well as on-premises / hybrid works. Description of the full solution (incl. download): http://loganalytics. sepago. com/ After several improvements, I can now offer a quicker and saver deployment and update for a prepared OMS workspace directly into your Azure subscription. To do this: Go to https://github. com/MarcelMeurer/LogAnalytics-for-Citrix-and-RDS and deploy your workspace directly. It’s as simple as any other deployment from the Azure marketplace: Just click the right “Deploy to Azure” button and enter a few parameters. You will get a prepared Azure OMS workspace including the tiles and views for this solution. The rollout workspace is a “standalone” pricing tier with a 360 days retention. https://github. com/MarcelMeurer/LogAnalytics-for-Citrix-and-RDS https://www. youtube. com/watch?v=A5ehFVIDotU First published on: https://www. sepago. de/blog/monitoring-end-user-computing-environments-with-azure-oms-loganalytics-with-deploy-to-azure/ "
    }, {
    "id": 93,
    "url": "https://blog.itprocloud.de/Deallocate-an-Azure-VM-from-itself/",
    "title": "Deallocate an Azure VM from itself",
    "body": "2018/01/16 - These days I’m dealing with the automation of starting and stopping Azure virtual machines. I do this to avoid unnecessary costs for customers running Citrix or RDS workers on Azure. I translated a piece of my work into a PowerShell script to de-allocate the VM on which it is running. Azure Instance Metadata Service: To get information about the running VM I use Azure Instance Metadata Service (https://docs. microsoft. com/en-us/azure/virtual-machines/windows/instance-metadata-service). This information contains the public IP address, VM size, os type and a lot more. To identify this Azure VM for later deallocation later, I need some specific information: the vmId. You can get meta data using PowerShell: `$md``=``Invoke-RestMethod` `-Headers` `@{``&quot;Metadata&quot;``=``&quot;true&quot;``}` `-URI` `http://169. 254. 169. 254/metadata/instance``?``api-version=2017-08-01` $md. compute. vmId contains the unique identifier for the running VM. I will use this id later to match the correct VM for deallocating. Service Principal Account: I want to deallocate the VM automatically without logging-in myself. Therefore I have to use a service principal account. It is pretty easy to create a service principal account: Go to the Azure portal, open the Azure Active Directory of your subscription(s) and choose „App registration“ – “New application registration”: Give your app a name (e. g. : PowerShell-Services) and enter a sign-on URL. User http://localhost for this URL and click “Create”.  Select the previously created app, select “Keys” and go on: Enter a name, select an expiration time and save the configuration: Important: copy your key directly after saving it: Also, copy the application id for later use: And last: copy the tenant id from your Azure Active Directory by selecting it and click on “Properties”: You have all the data you need to logon unattended now: App-id: 21acad78-9006-4f22-9156-xxxxxxxxxxxxx App-key: sjsgUk7a5hgaTkZGuOGeLxxxxxxxxxxxxxxxJ0lXs2/o= Tenant-id: 06522f94-0d15-4fba-aac8-xxxxxxxxxxxxxxx Give the right permissions: In my case, I will use this single app/service principal to shut down and deallocate every VM in my Azure subscription (this can be different in your case and can be a security breach if another user gets the logon data from your PowerShell script). To give the app the right to work with VM I added in on subscription level: Select Subscriptions -&gt; subscription -&gt; Access Control (IAM) -&gt; Add Role: Virtual Machine Contributor* Assign to: Azure AD user, group, or application Select: You application/service principal Save * The app/service principal has the permission to start/stop/modify/… all VM’s in the subscription. If you need more granularity you can create custom roles (https://www. sepago. de/blog/2017/07/13/preventing-administrative-users-to-change-critical-network-settings-in-an-azure-hub) The script: To find from your VM the corresponding one in Azure use this PowerShell script with the service principal credentials and deallocate it: $AppId= 21acad78-9006-4f22-9156-xxxxxxxxxxxxx $AppKey= sjsgUk7a5hgaTkZGuOGeLxxxxxxxxxxxxxxxJ0lXs2/o= $TenantId= 06522f94-0d15-4fba-aac8-xxxxxxxxxxxxxxx $md=Invoke-RestMethod -Headers @{“Metadata”=“true”} -URI http://169. 254. 169. 254/metadata/instance?api-version=2017-08-01 $Cred = New-Object System. Management. Automation. PSCredential ($AppId, (ConvertTo-SecureString $AppKey -AsPlainText -Force)) Login-AzureRmAccount -Credential $cred -ServicePrincipal -TenantId $TenantId # enumerate subscriptions$subscritions=Get-AzureRmSubscriptionforeach ($subscription in $subscritions){Write-Host(“Working on subscription: $($subscription. name)”)Get-AzureRmSubscription -SubscriptionId $subscription. Id |Out-Null$vms=Get-AzureRmVMWrite-Host(“Number of VMs: $($vms. Count)”)$vm=@($vms | where vmId -EQ $md. compute. vmId)if ($vm -ne 0){Write-Host(“Deallocating $($vm. Name)”)Stop-AzureRmVM -Id $vm[0]. Id -Name $vm[0]. Name -Force} else{Write-Host(“VM not found in this subscription”)}} Hint: @skillriver wrote a blog shutting to Shutdown and Deallocate an Azure VM using Managed Service Identity. This avoids to create an Azure AD application: https://gotoguy. blog/2018/01/17/shutdown-and-deallocate-an-azure-vm-using-managed-service-identity-and-instance-metadata-service/ First published on: https://www. sepago. de/blog/deallocate-an-azure-vm-from-itself/ "
    }, {
    "id": 94,
    "url": "https://blog.itprocloud.de/How-to-use-http-delete,-put,-head,-connections,-connect-with-an-Azure-Web-App/",
    "title": "How to use http delete, put, head, connections, connect with an Azure Web App",
    "body": "2017/12/27 - I often use Azure Web Apps to deploy tools and programs running serverless. A few weeks ago, I deployed an MVC web site with a controller to handle file uploads to an Azure Storage Account. For the client-side, I used jquery-FileUpload, which also allows triggering a controller to delete a file. If a user tries to delete a file, jquery-FileUpload triggers the controller with the http-request method “DELETE”. In my local environment, this worked as expected but nothing happened in my Azure Web App deployment. If found out that an Azure Web App supports only http-get and post by default. My first attempt was to add the methods DELETE via web. config: &lt;add name=&quot;ExtensionlessUrlHandler-Integrated-4. 0&quot; path=&quot;*. &quot; verb=&quot; DELETE&quot; type=&quot;System. Web. Handlers. TransferRequestHandler&quot; preCondition=&quot;integratedMode,runtimeVersionv4. 0&quot; /&gt;But this didn’t work. The full web site was no longer accessible: The page cannot be displayed because an internal server error has occurred. The right way to add a method/verb is to remove all first and then re-add them: &lt;remove name=&quot;ExtensionlessUrlHandler-Integrated-4. 0&quot; /&gt;&lt;add name=&quot;ExtensionlessUrlHandler-Integrated-4. 0&quot; path=&quot;*. &quot; verb=&quot;GET,POST,PUT,DELETE&quot; type=&quot;System. Web. Handlers. TransferRequestHandler&quot; preCondition=&quot;integratedMode,runtimeVersionv4. 0&quot; /&gt; First published on: https://www. sepago. de/blog/how-to-use-http-delete-put-head-connections-connect-with-an-azure-web-app/ "
    }, {
    "id": 95,
    "url": "https://blog.itprocloud.de/Deploy-a-node.js-script-in-seconds-to-an-Azure-Web-App-with-git-and-run-it-server-less/",
    "title": "Deploy a node.js script in seconds to an Azure Web App with git and run it server-less",
    "body": "2017/09/04 - Deploy a node. js script in seconds to an Azure Web App with git and run it server-less In customer projects, I sometimes develop small applications to collect and process data from different data sources or to offer a web interface. In any case, I try to avoid rolling out a VM to run these apps. I strictly prefer using Platform-as-a-Service and it works nearly 100% if I use an Azure Web App or Azure Functions. The advantages are obvious: No patching of VM’sNo further infrastructure for VM’sNo monitoring of OS specific metricsNo additional monitoring solutionNot involved in release cycles for the operating systemAnd a lot moreIn this post, I will describe how easy it is to deploy a node. js application with git to an Azure Web App. To make it more comprehensible I will describe it with a node. js game called “tanks” from @darthrubens. Tanks is a multi-player game developed in node. js. Tools: Later in this post we will need a few tools to test the game locally and to upload it to an Azure Web App. Install: Node. js: https://nodejs. orgto test the node. js application locallyGit: https://git-for-windows. github. ioto manage the source code and in this case: to upload applicationsThe node. js application for this test: https://github. com/rubentd/tanksdownload the zip file and extract it to a folderCreate an Azure Web App: Create an Azure Web App in the Azure Portal with an App service plan (or use an existing one):  Use at least a standard pricing tier to enable apps to run permanently.  false Configuration of the Azure Web App (save it): Get the publishing information (username and password) by downloading the profile:  Write down the username, password and the web app url for later. Test the application locally (optional): Extract the zip file from tanks to a folder, open a command line and navigate to this folder. At the very first time, you must install the packages and dependencies for the node. js application. Type: npm install To run the node. js application type: npm start The application starts and is accessible by this url: http://localhost:8082/  Upload the node. js application to the Azure Web App: In this post, I use git to manage the source code and upload it to Azure. I recommend learning how to use git. It’s a very powerful tool. I only describe the necessary steps here. First initialize your git project by typing: git init Add the files and directories to your local repository *git add ** Then commit all to git: git commit -m “Init” Add the web app as a remote repository (use your web app url and add scm after the host name): git remote add azure http://deploy-an-app. scm. azurewebsites. net And finally push your application (you will be asked for the username and password) git push azure master Hint: Git ignores node_modules folder. The modules will be installed by the Azure Web App based on the dependencies listed in packages. json   Done: Your Azure Web App is now running your node. js application: First published on: https://www. sepago. de/blog/deploy-a-node-js-script-in-seconds-to-an-azure-web-app-with-git-and-run-it-server-less/ "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});