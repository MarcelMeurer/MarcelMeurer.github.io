
var documents = [{
    "id": 0,
    "url": "/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "/about",
    "title": "About me and about the synonym ITProCloud.de",
    "body": "What is the purpose of this page?: ITProCloud. de is my private blog site. I use this site to store and publish my blog post. In the professional context, I also publish blogs on the homepage of my employer sepago GmbH in Germany (https://www. sepago. de/blog/author/marcel-meurer/). Therefore, a blog post can be found on both sides. What is ITProCloud. de?: ITProCloud. de is the DNS name I use for tests, demos and (of course) my web site. My Biography: Today I’m responsible for the professional IT services business unit at sepago GmbH in Cologne. In this role, I lead a team of consultants who provide their expertise in Microsoft and Citrix Technologies for customers and partners. My technical focuses are Microsoft Azure platform services and I’m a Microsoft Azure MVP since 2016. I started my IT career in the early 1990s with first contacts to personal computers (and before that with the Commodore 64). Assembler and hardware-related programming were in my focus – the IoT of the 90s. In the year 1995, I started studying electrical engineering. During my studies, machine learning and neural networks were one of my favorite topics. In addition to my studies, I worked for a small computer company in Aachen, where I provided operating systems and applications with automated methods on many computers. I graduated as an engineer in electrical engineering from the University of Applied Science Aachen. My last and next sessions: Speaking at your conference: If you are hosting events realted to the Azure Cloud, IoT, Development, Azure Monitor, etc. I would be happy to support this event with content. Feel free to contact me. Get in touch with me: I’d like you to get in touch with me.       												             												      			  												            												      			        												      "
    }, {
    "id": 2,
    "url": "/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 3,
    "url": "/Impressum",
    "title": "Impressum / Imprint",
    "body": "Marcel MeurerEichholzer Weg 3551519 OdenthalDeutschland / Germany Telefon/Telephone: +49 173 7331284E-Mail/Email: marcel. meurer@itprocloud. de "
    }, {
    "id": 4,
    "url": "/",
    "title": "Home",
    "body": "      Featured:                                                                                                                                                                                                           WVD Admin - A native administration Gui for Windows Virtual Desktop                              :               Windows Virtual Desktop is generally available and under continuous improvement. There was the time before Ignite 2019 where no administration GUI was publicly available. This. . . :                                                                                                                                                                       Marcel                                02 Nov 2019                                                                                                                                                                                                                                                                                                                        Announcing the community version of  Project MySmartScale                               :               Windows Virtual Desktop is released and gateways around the world are available - even in Europe which cause in a low latency - perfect. :                                                                                                                                                                       Marcel                                09 Oct 2019                                                                                                                                                                                                                                                                                                                        On the road - My next speaking engagements                              :               I’m happy to be a part of a great community. On my journey, I have the possibility to speak at some conferences, meetups and other. . . :                                                                                                                                                                       Marcel                                07 Sep 2019                                                                                                                                                                                                          All Posts:                                                                                                     WVD Admin - A native administration Gui for Windows Virtual Desktop              :       Windows Virtual Desktop is generally available and under continuous improvement. There was the time before Ignite 2019 where no administration GUI was publicly available. This changed with Ignite. The PG. . . :                                                                               Marcel                02 Nov 2019                                                                                                                                     PolarConf 2019 - Building own solutions whit Azure Monitor               :       In October I visited Finland the very first time to speak at PolarConf and I have to say: It was amazing. A great single track event over two days. It. . . :                                                                               Marcel                16 Oct 2019                                                                                      &lt;img class= img-fluid  src= /assets/images/MySmartScale-01. png  alt= Announcing the community version of  Project MySmartScale  &gt;                                               Announcing the community version of  Project MySmartScale               :       Windows Virtual Desktop is released and gateways around the world are available - even in Europe which cause in a low latency - perfect. :                                                                               Marcel                09 Oct 2019                                                                                                                                     Workshop Azure Monitor - Lessons              :       To get practice in using Azure Monitor, I have prepared some examples. These examples can be recreated with a little PowerShell. I have prepared more complex program parts. These can. . . :                                                                               Marcel                21 Sep 2019                                                                                                                                     On the road - My next speaking engagements              :       I’m happy to be a part of a great community. On my journey, I have the possibility to speak at some conferences, meetups and other events. And I loved it. . . . :                                                                               Marcel                07 Sep 2019                                                                                                                                     CDC Germany: RDS and Windows Virtual Desktop – Desktops in the year 2019 and beyond              :       From 21. to 22. April 2019 the annual Cloud and Datacenter Conference took place in Hanau/Frankfurt in Germany. It’s one of my favorite community events in Germany. This year I. . . :                                                                               Marcel                23 May 2019                                                                                                                                     Publish your solution to the Azure Marketplace              :       Publishing own solutions to the Azure Marketplace seems to be very easy by using the documentation on https://docs. microsoft. com/en-us/azure/marketplace/marketplace-publishers-guide. To avoid any pitfalls I wrote down some insights about my first. . . :                                                                               Marcel                25 Mar 2019                                                                                                                                     Why configuring Azure AD authentication with an Azure Web App fails              :       I spent hours today adding Azure AD authentication to an Azure MVC web application with Visual Studio. I always got the same error while adding the preconfigured AD application::                                                                               Marcel                09 Feb 2019                                                                                                                                     Deploy an Azure Functional App as an interface to Log Analytics / Azure Monitor              :       Introduction:                                                                               Marcel                13 Jan 2019                                                                                                                                     Creating devices for Azure IoT Hub with SAS token automatically              :       A few weeks ago, I started an IoT project with a company responsible for a huge amount of different buildings around the world. We deployed several virtual and physical sensors. . . :                                                                               Marcel                23 Nov 2018                                                                                                                                     OneDrive PowerShell Module - Added support for OneDrive for Business              :       More than two years ago, I created my PowerShell module to access OneDrive. This module can be installed with a one-liner from https://www. powershellgallery. com/packages/OneDrive:                                                                               Marcel                05 Nov 2018                                                                                                                                     Working with the OneDrive PowerShell Module              :       Recently I got some questions on how to work with my PowerShell module for OneDrive. Therefore, I put together some examples. :                                                                               Marcel                29 Sep 2018                                               &laquo; Prev       1        2      Next &raquo; "
    }, {
    "id": 5,
    "url": "/privacyDe",
    "title": "Datenschutz",
    "body": "English version Datenschutzerklärung: Personenbezogene Daten (nachfolgend zumeist nur „Daten“ genannt) werden von uns nur im Rahmen der Erforderlichkeit sowie zum Zwecke der Bereitstellung eines funktionsfähigen und nutzerfreundlichen Internetauftritts, inklusive seiner Inhalte und der dort angebotenen Leistungen, verarbeitet. Gemäß Art. 4 Ziffer 1. der Verordnung (EU) 2016/679, also der Datenschutz-Grundverordnung (nachfolgend nur „DSGVO“ genannt), gilt als „Verarbeitung“ jeder mit oder ohne Hilfe automatisierter Verfahren ausgeführter Vorgang oder jede solche Vorgangsreihe im Zusammenhang mit personenbezogenen Daten, wie das Erheben, das Erfassen, die Organisation, das Ordnen, die Speicherung, die Anpassung oder Veränderung, das Auslesen, das Abfragen, die Verwendung, die Offenlegung durch Übermittlung, Verbreitung oder eine andere Form der Bereitstellung, den Abgleich oder die Verknüpfung, die Einschränkung, das Löschen oder die Vernichtung. Mit der nachfolgenden Datenschutzerklärung informieren wir Sie insbesondere über Art, Umfang, Zweck, Dauer und Rechtsgrundlage der Verarbeitung personenbezogener Daten, soweit wir entweder allein oder gemeinsam mit anderen über die Zwecke und Mittel der Verarbeitung entscheiden. Zudem informieren wir Sie nachfolgend über die von uns zu Optimierungszwecken sowie zur Steigerung der Nutzungsqualität eingesetzten Fremdkomponenten, soweit hierdurch Dritte Daten in wiederum eigener Verantwortung verarbeiten. Unsere Datenschutzerklärung ist wie folgt gegliedert: I. Informationen über uns als VerantwortlicheII. Rechte der Nutzer und BetroffenenIII. Informationen zur Datenverarbeitung I. Informationen über uns als Verantwortliche: Verantwortlicher Anbieter dieses Internetauftritts im datenschutzrechtlichen Sinne ist: Marcel MeurerEichholzer Weg 3551519 OdenthalDeutschland Telefon: +49 173 7331284E-Mail: marcel. meurer@itprocloud. de II. Rechte der Nutzer und Betroffenen: Mit Blick auf die nachfolgend noch näher beschriebene Datenverarbeitung haben die Nutzer und Betroffenen das Recht  auf Bestätigung, ob sie betreffende Daten verarbeitet werden, auf Auskunft über die verarbeiteten Daten, auf weitere Informationen über die Datenverarbeitung sowie auf Kopien der Daten (vgl. auch Art. 15 DSGVO); auf Berichtigung oder Vervollständigung unrichtiger bzw. unvollständiger Daten (vgl. auch Art. 16 DSGVO); auf unverzügliche Löschung der sie betreffenden Daten (vgl. auch Art. 17 DSGVO), oder, alternativ, soweit eine weitere Verarbeitung gemäß Art. 17 Abs. 3 DSGVO erforderlich ist, auf Einschränkung der Verarbeitung nach Maßgabe von Art. 18 DSGVO; auf Erhalt der sie betreffenden und von ihnen bereitgestellten Daten und auf Übermittlung dieser Daten an andere Anbieter/Verantwortliche (vgl. auch Art. 20 DSGVO); auf Beschwerde gegenüber der Aufsichtsbehörde, sofern sie der Ansicht sind, dass die sie betreffenden Daten durch den Anbieter unter Verstoß gegen datenschutzrechtliche Bestimmungen verarbeitet werden (vgl. auch Art. 77 DSGVO). Darüber hinaus ist der Anbieter dazu verpflichtet, alle Empfänger, denen gegenüber Daten durch den Anbieter offengelegt worden sind, über jedwede Berichtigung oder Löschung von Daten oder die Einschränkung der Verarbeitung, die aufgrund der Artikel 16, 17 Abs. 1, 18 DSGVO erfolgt, zu unterrichten. Diese Verpflichtung besteht jedoch nicht, soweit diese Mitteilung unmöglich oder mit einem unverhältnismäßigen Aufwand verbunden ist. Unbeschadet dessen hat der Nutzer ein Recht auf Auskunft über diese Empfänger. Ebenfalls haben die Nutzer und Betroffenen nach Art. 21 DSGVO das Recht auf Widerspruch gegen die künftige Verarbeitung der sie betreffenden Daten, sofern die Daten durch den Anbieter nach Maßgabe von Art. 6 Abs. 1 lit. f) DSGVO verarbeitet werden. Insbesondere ist ein Widerspruch gegen die Datenverarbeitung zum Zwecke der Direktwerbung statthaft. III. Informationen zur Datenverarbeitung: Ihre bei Nutzung unseres Internetauftritts verarbeiteten Daten werden gelöscht oder gesperrt, sobald der Zweck der Speicherung entfällt, der Löschung der Daten keine gesetzlichen Aufbewahrungspflichten entgegenstehen und nachfolgend keine anderslautenden Angaben zu einzelnen Verarbeitungsverfahren gemacht werden. Cookies: a) Sitzungs-Cookies/Session-CookiesWir verwenden mit unserem Internetauftritt sog. Cookies. Cookies sind kleine Textdateien oder andere Speichertechnologien, die durch den von Ihnen eingesetzten Internet-Browser auf Ihrem Endgerät ablegt und gespeichert werden. Durch diese Cookies werden im individuellen Umfang bestimmte Informationen von Ihnen, wie beispielsweise Ihre Browser- oder Standortdaten oder Ihre IP-Adresse, verarbeitet.   Durch diese Verarbeitung wird unser Internetauftritt benutzerfreundlicher, effektiver und sicherer, da die Verarbeitung bspw. die Wiedergabe unseres Internetauftritts in unterschiedlichen Sprachen oder das Angebot einer Warenkorbfunktion ermöglicht. Rechtsgrundlage dieser Verarbeitung ist Art. 6 Abs. 1 lit b. ) DSGVO, sofern diese Cookies Daten zur Vertragsanbahnung oder Vertragsabwicklung verarbeitet werden. Falls die Verarbeitung nicht der Vertragsanbahnung oder Vertragsabwicklung dient, liegt unser berechtigtes Interesse in der Verbesserung der Funktionalität unseres Internetauftritts. Rechtsgrundlage ist in dann Art. 6 Abs. 1 lit. f) DSGVO. Mit Schließen Ihres Internet-Browsers werden diese Session-Cookies gelöscht. b) Drittanbieter-CookiesGegebenenfalls werden mit unserem Internetauftritt auch Cookies von Partnerunternehmen, mit denen wir zum Zwecke der Werbung, der Analyse oder der Funktionalitäten unseres Internetauftritts zusammenarbeiten, verwendet. Die Einzelheiten hierzu, insbesondere zu den Zwecken und den Rechtsgrundlagen der Verarbeitung solcher Drittanbieter-Cookies, entnehmen Sie bitte den nachfolgenden Informationen. c) BeseitigungsmöglichkeitSie können die Installation der Cookies durch eine Einstellung Ihres Internet-Browsers verhindern oder einschränken. Ebenfalls können Sie bereits gespeicherte Cookies jederzeit löschen. Die hierfür erforderlichen Schritte und Maßnahmen hängen jedoch von Ihrem konkret genutzten Internet-Browser ab. Bei Fragen benutzen Sie daher bitte die Hilfefunktion oder Dokumentation Ihres Internet-Browsers oder wenden sich an dessen Hersteller bzw. Support. Bei sog. Flash-Cookies kann die Verarbeitung allerdings nicht über die Einstellungen des Browsers unterbunden werden. Stattdessen müssen Sie insoweit die Einstellung Ihres Flash-Players ändern. Auch die hierfür erforderlichen Schritte und Maßnahmen hängen von Ihrem konkret genutzten Flash-Player ab. Bei Fragen benutzen Sie daher bitte ebenso die Hilfefunktion oder Dokumentation Ihres Flash-Players oder wenden sich an den Hersteller bzw. Benutzer-Support. Sollten Sie die Installation der Cookies verhindern oder einschränken, kann dies allerdings dazu führen, dass nicht sämtliche Funktionen unseres Internetauftritts vollumfänglich nutzbar sind. Kontaktanfragen / Kontaktmöglichkeit: Sofern Sie per Kontaktformular oder E-Mail mit uns in Kontakt treten, werden die dabei von Ihnen angegebenen Daten zur Bearbeitung Ihrer Anfrage genutzt. Die Angabe der Daten ist zur Bearbeitung und Beantwortung Ihre Anfrage erforderlich - ohne deren Bereitstellung können wir Ihre Anfrage nicht oder allenfalls eingeschränkt beantworten. Rechtsgrundlage für diese Verarbeitung ist Art. 6 Abs. 1 lit. b) DSGVO. Ihre Daten werden gelöscht, sofern Ihre Anfrage abschließend beantwortet worden ist und der Löschung keine gesetzlichen Aufbewahrungspflichten entgegenstehen, wie bspw. bei einer sich etwaig anschließenden Vertragsabwicklung. Nutzerbeiträge, Kommentare und Bewertungen: Wir bieten Ihnen an, auf unseren Internetseiten Fragen, Antworten, Meinungen oder Bewertungen, nachfolgend nur „Beiträge genannt, zu veröffentlichen. Sofern Sie dieses Angebot in Anspruch nehmen, verarbeiten und veröffentlichen wir Ihren Beitrag, Datum und Uhrzeit der Einreichung sowie das von Ihnen ggf. genutzte Pseudonym. Rechtsgrundlage hierbei ist Art. 6 Abs. 1 lit. a) DSGVO. Die Einwilligung können Sie gemäß Art. 7 Abs. 3 DSGVO jederzeit mit Wirkung für die Zukunft widerrufen. Hierzu müssen Sie uns lediglich über Ihren Widerruf in Kenntnis setzen. Darüber hinaus verarbeiten wir auch Ihre IP- und E-Mail-Adresse. Die IP-Adresse wird verarbeitet, weil wir ein berechtigtes Interesse daran haben, weitere Schritte einzuleiten oder zu unterstützen, sofern Ihr Beitrag in Rechte Dritter eingreift und/oder er sonst wie rechtswidrig erfolgt. Rechtsgrundlage ist in diesem Fall Art. 6 Abs. 1 lit. f) DSGVO. Unser berechtigtes Interesse liegt in der ggf. notwendigen Rechtsverteidigung. Abonnement von Beiträgen: Sofern Sie Beiträge auf unseren Internetseiten veröffentlichen, bieten wir Ihnen zusätzlich an, etwaige Folgebeiträge Dritter zu abonnieren. Um Sie über diese Folgebeiträge per E-Mail informieren zu können, verarbeiten wir Ihre E-Mail-Adresse. Rechtsgrundlage hierbei ist Art. 6 Abs. 1 lit. a) DSGVO. Die Einwilligung in dieses Abonnement können Sie gemäß Art. 7 Abs. 3 DSGVO jederzeit mit Wirkung für die Zukunft widerrufen. Hierzu müssen Sie uns lediglich über Ihren Widerruf in Kenntnis setzen oder den in der jeweiligen E-Mail enthaltenen Abmeldelink betätigen. Twitter: Wir unterhalten bei Twitter eine Onlinepräsenz um unser Unternehmen sowie unsere Leistungen zu präsentieren und mit Kunden/Interessenten zu kommunizieren. Twitter ist ein Service der Twitter Inc. , 1355 Market Street, Suite 900, San Francisco, CA 94103, USA. Insofern weisen wir darauf hin, dass die Möglichkeit besteht, dass Daten der Nutzer außerhalb der Europäischen Union, insbesondere in den USA, verarbeitet werden. Hierdurch können gesteigerte Risiken für die Nutzer insofern bestehen, als dass z. B. der spätere Zugriff auf die Nutzerdaten erschwert werden kann. Auch haben wir keinen Zugriff auf diese Nutzerdaten. Die Zugriffsmöglichkeit liegt ausschließlich bei Twitter. Die Twitter Inc. ist unter dem Privacy Shield zertifiziert und hat sich damit verpflichtet, die europäischen Datenschutzstandards einzuhalten https://www. privacyshield. gov/participant?id=a2zt0000000TORzAAO&amp;status=Active Die Datenschutzhinweise von Twitter finden Sie unter https://twitter. com/de/privacy YouTube: Wir unterhalten bei YouTube eine Onlinepräsenz um unser Unternehmen sowie unsere Leistungen zu präsentieren und mit Kunden/Interessenten zu kommunizieren. YouTube ist ein Service der Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland, ein Tochterunternehmen der Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043 USA. Insofern weisen wir darauf hin, dass die Möglichkeit besteht, dass Daten der Nutzer außerhalb der Europäischen Union, insbesondere in den USA, verarbeitet werden. Hierdurch können gesteigerte Risiken für die Nutzer insofern bestehen, als dass z. B. der spätere Zugriff auf die Nutzerdaten erschwert werden kann. Auch haben wir keinen Zugriff auf diese Nutzerdaten. Die Zugriffsmöglichkeit liegt ausschließlich bei YouTube. Die Google LLC ist unter dem Privacy Shield zertifiziert und hat sich damit verpflichtet, die europäischen Datenschutzstandards einzuhalten https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active Die Datenschutzhinweise von YouTube finden Sie unter https://policies. google. com/privacy LinkedIn: Wir unterhalten bei LinkedIn eine Onlinepräsenz um unser Unternehmen sowie unsere Leistungen zu präsentieren und mit Kunden/Interessenten zu kommunizieren. LinkedIn ist ein Service der LinkedIn Ireland Unlimited Company, Wilton Plaza, Wilton Place, Dublin 2, Irland, ein Tochterunternehmen der LinkedIn Corporation, 1000 W. Maude Avenue, Sunnyvale, CA 94085, USA. Insofern weisen wir darauf hin, dass die Möglichkeit besteht, dass Daten der Nutzer außerhalb der Europäischen Union, insbesondere in den USA, verarbeitet werden. Hierdurch können gesteigerte Risiken für die Nutzer insofern bestehen, als dass z. B. der spätere Zugriff auf die Nutzerdaten erschwert werden kann. Auch haben wir keinen Zugriff auf diese Nutzerdaten. Die Zugriffsmöglichkeit liegt ausschließlich bei LinkedIn. Die LinkedIn Corporation ist unter dem Privacy Shield zertifiziert und hat sich damit verpflichtet, die europäischen Datenschutzstandards einzuhalten https://www. privacyshield. gov/participant?id=a2zt0000000L0UZAA0&amp;status=Active Die Datenschutzhinweise von LinkedIn finden Sie unter https://www. linkedin. com/legal/privacy-policy Verlinkung Social-Media über Grafik oder Textlink: Wir bewerben auf unserer Webseite auch Präsenzen auf den nachstehend aufgeführten sozialen Netzwerken. Die Einbindung erfolgt dabei über eine verlinkte Grafik des jeweiligen Netzwerks. Durch den Einsatz dieser verlinkten Grafik wird verhindert, dass es bei dem Aufruf einer Website, die über eine Social-Media-Bewerbung verfügt, automatisch zu einem Verbindungsaufbau zum jeweiligen Server des sozialen Netzwerks kommt, um eine Grafik des jeweiligen Netzwerkes selbst darzustellen. Erst durch einen Klick auf die entsprechende Grafik wird der Nutzer zu dem Dienst des jeweiligen sozialen Netzwerks weitergeleitet. Nach der Weiterleitung des Nutzers werden durch das jeweilige Netzwerk Informationen über den Nutzer erfasst. Es kann hierbei nicht ausgeschlossen werden, dass eine Verarbeitung der so erhobenen  Daten in den USA stattfindet. Dies sind zunächst Daten wie IP-Adresse, Datum, Uhrzeit und besuchte Seite. Ist der Nutzer währenddessen in seinem Benutzerkonto des jeweiligen Netzwerks eingeloggt, kann der Netzwerk-Betreiber ggf. die gesammelten Informationen des konkreten Besuchs des Nutzers dem persönlichen Account des Nutzers zuordnen. Interagiert der Nutzer über einen „Teilen“-Button des jeweiligen Netzwerks, können diese Informationen in dem persönlichen Benutzerkonto des Nutzers gespeichert und ggf. veröffentlicht werden. Will der Nutzer verhindern, dass die gesammelten Informationen unmittelbar seinem Benutzerkonto zugeordnet werden, muss er sich vor dem Anklicken der Grafik ausloggen. Zudem besteht die Möglichkeit, das jeweilige Benutzerkonto entsprechend zu konfigurieren. Folgende soziale Netzwerke werden in unsere Seite durch Verlinkung eingebunden: twitter: Twitter Inc. , 795 Folsom St. , Suite 600, San Francisco, CA 94107, USA Datenschutzerklärung: https://twitter. com/privacy Zertifizierung EU-US-Datenschutz („EU-US Privacy Shield“) https://www. privacyshield. gov/…0000TORzAAO&amp;status=Active YouTube: Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland, ein Tochterunternehmen der Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043 USA Datenschutzerklärung: https://policies. google. com/privacy Zertifizierung EU-US-Datenschutz („EU-US Privacy Shield“) https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active LinkedIn: LinkedIn Ireland Unlimited Company, Wilton Plaza, Wilton Place, Dublin 2, Irland, ein Tochterunternehmen der LinkedIn Corporation, 1000 W. Maude Avenue, Sunnyvale, CA 94085 USA. Datenschutzerklärung: https://www. linkedin. com/legal/privacy-policy Zertifizierung EU-US-Datenschutz („EU-US Privacy Shield“) https://www. privacyshield. gov/participant?id=a2zt0000000L0UZAA0&amp;status=Active „Twitter“-Social-Plug-in: In unserem Internetauftritt setzen wir das Plug-in des Social-Networks Twitter ein. Bei Twitter handelt es sich um einen Internetservice der Twitter Inc. , 795 Folsom St. , Suite 600, San Francisco, CA 94107, USA, nachfolgend nur „Twitter“ genannt. Durch die Zertifizierung nach dem EU-US-Datenschutzschild („EU-US Privacy Shield“) https://www. privacyshield. gov/participant?id=a2zt0000000TORzAAO&amp;status=Active garantiert Twitter, dass die Datenschutzvorgaben der EU auch bei der Verarbeitung von Daten in den USA eingehalten werden. Rechtsgrundlage ist Art. 6 Abs. 1 lit. f) DSGVO. Unser berechtigtes Interesse liegt in der Qualitätsverbesserung unseres Internetauftritts. Sofern das Plug-in auf einer der von Ihnen besuchten Seiten unseres Internetauftritts hinterlegt ist, lädt Ihr Internet-Browser eine Darstellung des Plug-ins von den Servern von Twitter in den USA herunter. Aus technischen Gründen ist es dabei notwendig, dass Twitter Ihre IP-Adresse verarbeitet. Daneben werden aber auch Datum und Uhrzeit des Besuchs unserer Internetseiten erfasst. Sollten Sie bei Twitter eingeloggt sein, während Sie eine unserer mit dem Plug-in versehenen Internetseite besuchen, werden die durch das Plug-in gesammelten Informationen Ihres konkreten Besuchs von Twitter erkannt. Die so gesammelten Informationen weist Twitter womöglich Ihrem dortigen persönlichen Nutzerkonto zu. Sofern Sie also bspw. den sog. „Teilen“-Button von Twitter benutzen, werden diese Informationen in Ihrem Twitter-Nutzerkonto gespeichert und ggf. über die Plattform von Twitter veröffentlicht. Wenn Sie das verhindern möchten, müssen Sie sich entweder vor dem Besuch unseres Internetauftritts bei Twitter ausloggen oder die entsprechenden Einstellungen in Ihrem Twitter-Benutzerkonto vornehmen. Weitergehende Informationen über die Erhebung und Nutzung von Daten sowie Ihre diesbezüglichen Rechte und Schutzmöglichkeiten hält Twitter in den unter https://twitter. com/privacy abrufbaren Datenschutzhinweisen bereit. Google Analytics: In unserem Internetauftritt setzen wir Google Analytics ein. Hierbei handelt es sich um einen Webanalysedienst der Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland, nachfolgend nur „Google“ genannt. Durch die Zertifizierung nach dem EU-US-Datenschutzschild („EU-US Privacy Shield“) https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active garantiert Google, dass die Datenschutzvorgaben der EU auch bei der Verarbeitung von Daten in den USA eingehalten werden. Der Dienst Google Analytics dient zur Analyse des Nutzungsverhaltens unseres Internetauftritts. Rechtsgrundlage ist Art. 6 Abs. 1 lit. f) DSGVO. Unser berechtigtes Interesse liegt in der Analyse, Optimierung und dem wirtschaftlichen Betrieb unseres Internetauftritts. Nutzungs- und nutzerbezogene Informationen, wie bspw. IP-Adresse, Ort, Zeit oder Häufigkeit des Besuchs unseres Internetauftritts, werden dabei an einen Server von Google in den USA übertragen und dort gespeichert. Allerdings nutzen wir Google Analytics mit der sog. Anonymisierungsfunktion. Durch diese Funktion kürzt Google die IP-Adresse schon innerhalb der EU bzw. des EWR. Die so erhobenen Daten werden wiederum von Google genutzt, um uns eine Auswertung über den Besuch unseres Internetauftritts sowie über die dortigen Nutzungsaktivitäten zur Verfügung zu stellen. Auch können diese Daten genutzt werden, um weitere Dienstleistungen zu erbringen, die mit der Nutzung unseres Internetauftritts und der Nutzung des Internets zusammenhängen. Google gibt an, Ihre IP-Adresse nicht mit anderen Daten zu verbinden. Zudem hält Google unter https://www. google. com/intl/de/policies/privacy/partners weitere datenschutzrechtliche Informationen für Sie bereit, so bspw. auch zu den Möglichkeiten, die Datennutzung zu unterbinden. Zudem bietet Google unter https://tools. google. com/dlpage/gaoptout?hl=de ein sog. Deaktivierungs-Add-on nebst weiteren Informationen hierzu an. Dieses Add-on lässt sich mit den gängigen Internet-Browsern installieren und bietet Ihnen weitergehende Kontrollmöglichkeit über die Daten, die Google bei Aufruf unseres Internetauftritts erfasst. Dabei teilt das Add-on dem JavaScript (ga. js) von Google Analytics mit, dass Informationen zum Besuch unseres Internetauftritts nicht an Google Analytics übermittelt werden sollen. Dies verhindert aber nicht, dass Informationen an uns oder an andere Webanalysedienste übermittelt werden. Ob und welche weiteren Webanalysedienste von uns eingesetzt werden, erfahren Sie natürlich ebenfalls in dieser Datenschutzerklärung. YouTube: In unserem Internetauftritt setzen wir YouTube ein. Hierbei handelt es sich um ein Videoportal der YouTube LLC. , 901 Cherry Ave. , 94066 San Bruno, CA, USA, nachfolgend nur „YouTube“ genannt. YouTube ist ein Tochterunternehmen der Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland, nachfolgend nur „Google“ genannt. Durch die Zertifizierung nach dem EU-US-Datenschutzschild („EU-US Privacy Shield“) https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active garantiert Google und damit auch das Tochterunternehmen YouTube, dass die Datenschutzvorgaben der EU auch bei der Verarbeitung von Daten in den USA eingehalten werden. Wir nutzen YouTube im Zusammenhang mit der Funktion „Erweiterter Datenschutzmodus“, um Ihnen Videos anzeigen zu können. Rechtsgrundlage ist Art. 6 Abs. 1 lit. f) DSGVO. Unser berechtigtes Interesse liegt in der Qualitätsverbesserung unseres Internetauftritts. Die Funktion „Erweiterter Datenschutzmodus“ bewirkt laut Angaben von YouTube, dass die nachfolgend noch näher bezeichneten Daten nur dann an den Server von YouTube übermittelt werden, wenn Sie ein Video auch tatsächlich starten. Ohne diesen „Erweiterten Datenschutz“ wird eine Verbindung zum Server von YouTube in den USA hergestellt, sobald Sie eine unserer Internetseiten, auf der ein YouTube-Video eingebettet ist, aufrufen. Diese Verbindung ist erforderlich, um das jeweilige Video auf unserer Internetseite über Ihren Internet-Browser darstellen zu können. Im Zuge dessen wird YouTube zumindest Ihre IP-Adresse, das Datum nebst Uhrzeit sowie die von Ihnen besuchte Internetseite erfassen und verarbeiten. Zudem wird eine Verbindung zu dem Werbenetzwerk „DoubleClick“ von Google hergestellt. Sollten Sie gleichzeitig bei YouTube eingeloggt sein, weist YouTube die Verbindungsinformationen Ihrem YouTube-Konto zu. Wenn Sie das verhindern möchten, müssen Sie sich entweder vor dem Besuch unseres Internetauftritts bei YouTube ausloggen oder die entsprechenden Einstellungen in Ihrem YouTube-Benutzerkonto vornehmen. Zum Zwecke der Funktionalität sowie zur Analyse des Nutzungsverhaltens speichert YouTube dauerhaft Cookies über Ihren Internet-Browser auf Ihrem Endgerät. Falls Sie mit dieser Verarbeitung nicht einverstanden sind, haben Sie die Möglichkeit, die Speicherung der Cookies durch eine Einstellung in Ihrem Internet-Browsers zu verhindern. Nähere Informationen hierzu finden Sie vorstehend unter „Cookies“. Weitergehende Informationen über die Erhebung und Nutzung von Daten sowie Ihre diesbezüglichen Rechte und Schutzmöglichkeiten hält Google in den unter https://policies. google. com/privacy abrufbaren Datenschutzhinweisen bereit. {% comment %} MailChimp - Newsletter: Wir bieten Ihnen die Möglichkeit an, sich bei uns über unseren Internetauftritt für unsere kostenlosen Newsletter anmelden zu können. Zum Newsletterversand setzen wir MailChimp, einen Dienst der The Rocket Science Group, LLC, 512 Means Street, Suite 404, Atlanta, GA 30318, USA, nachfolgend nur „The Rocket Science Group“ genannt, ein. Durch die Zertifizierung nach dem EU-US-Datenschutzschild („EU-US Privacy Shield“) https://www. privacyshield. gov/participant?id=a2zt0000000TO6hAAG&amp;status=Active garantiert The Rocket Science Group, dass die Datenschutzvorgaben der EU auch bei der Verarbeitung von Daten in den USA eingehalten werden. Zudem bietet The Rocket Science Group unter http://mailchimp. com/legal/privacy/ weitergehende Datenschutzinformationen an. Falls Sie sich zu unserem Newsletter-Versand anmelden, werden die während des Anmeldevorgangs abgefragten Daten, wie Ihre E-Mail-Adresse sowie, optional, Ihr Name nebst Anschrift, durch The Rocket Science Group verarbeitet. Zudem werden Ihre IP-Adresse sowie das Datum Ihrer Anmeldung nebst Uhrzeit gespeichert. Im Rahmen des weiteren Anmeldevorgangs wird Ihre Einwilligung in die Übersendung des Newsletters eingeholt, der Inhalt konkret beschreiben und auf diese Datenschutzerklärung verwiesen. Der anschließend über The Rocket Science Group versandte Newsletter enthält zudem einen sog. Zählpixel, auch Web Beacon genannt“. Mit Hilfe dieses Zählpixels können wir auswerten, ob und wann Sie unseren Newsletter gelesen haben und ob Sie den in dem Newsletter etwaig enthaltenen weiterführenden Links gefolgt sind. Neben weiteren technischen Daten, wie bspw. die Daten Ihres EDV-Systems und Ihre IP-Adresse, werden die dabei verarbeiteten Daten gespeichert, damit wir unser Newsletter-Angebot optimieren und auf die Wünsche der Leser eingehen können. Die Daten werden also zur Steigerung der Qualität und Attraktivität unseres Newsletter-Angebots zu steigern. Rechtsgrundlage für den Versand des Newsletters und die Analyse ist Art. 6 Abs. 1 lit. a. ) DSGVO. Die Einwilligung in den Newsletter-Versand können Sie gemäß Art. 7 Abs. 3 DSGVO jederzeit mit Wirkung für die Zukunft widerrufen. Hierzu müssen Sie uns lediglich über Ihren Widerruf in Kenntnis setzen oder den in jedem Newsletter enthaltenen Abmeldelink betätigen. {% endcomment %} Muster-Datenschutzerklärung der Anwaltskanzlei Weiß &amp; Partner "
    }, {
    "id": 6,
    "url": "/privacyEn",
    "title": "Data Privacy",
    "body": "German version Privacy Policy: Personal data (usually referred to just as “data” below) will only be processed by us to the extent necessary and for the purpose of providing a functional and user-friendly website, including its contents, and the services offered there. Per Art. 4 No. 1 of Regulation (EU) 2016/679, i. e. the General Data Protection Regulation (hereinafter referred to as the “GDPR”), “processing” refers to any operation or set of operations such as collection, recording, organization, structuring, storage, adaptation, alteration, retrieval, consultation, use, disclosure by transmission, dissemination, or otherwise making available, alignment, or combination, restriction, erasure, or destruction performed on personal data, whether by automated means or not. The following privacy policy is intended to inform you in particular about the type, scope, purpose, duration, and legal basis for the processing of such data either under our own control or in conjunction with others. We also inform you below about the third-party components we use to optimize our website and improve the user experience which may result in said third parties also processing data they collect and control. Our privacy policy is structured as follows: I. Information about us as controllers of your dataII. The rights of users and data subjectsIII. Information about the data processing I. Information about us as controllers of your data: The party responsible for this website (the “controller”) for purposes of data protection law is: Marcel MeurerEichholzer Weg 3551519 OdenthalDeutschland Telephone: +49 173 7331284Email: marcel. meurer@itprocloud. de II. The rights of users and data subjects: With regard to the data processing to be described in more detail below, users and data subjects have the right  to confirmation of whether data concerning them is being processed, information about the data being processed, further information about the nature of the data processing, and copies of the data (cf. also Art. 15 GDPR); to correct or complete incorrect or incomplete data (cf. also Art. 16 GDPR); to the immediate deletion of data concerning them (cf. also Art. 17 DSGVO), or, alternatively, if further processing is necessary as stipulated in Art. 17 Para. 3 GDPR, to restrict said processing per Art. 18 GDPR; to receive copies of the data concerning them and/or provided by them and to have the same transmitted to other providers/controllers (cf. also Art. 20 GDPR); to file complaints with the supervisory authority if they believe that data concerning them is being processed by the controller in breach of data protection provisions (see also Art. 77 GDPR). In addition, the controller is obliged to inform all recipients to whom it discloses data of any such corrections, deletions, or restrictions placed on processing the same per Art. 16, 17 Para. 1, 18 GDPR. However, this obligation does not apply if such notification is impossible or involves a disproportionate effort. Nevertheless, users have a right to information about these recipients. Likewise, under Art. 21 GDPR, users and data subjects have the right to object to the controller’s future processing of their data pursuant to Art. 6 Para. 1 lit. f) GDPR. In particular, an objection to data processing for the purpose of direct advertising is permissible. III. Information about the data processing: Your data processed when using our website will be deleted or blocked as soon as the purpose for its storage ceases to apply, provided the deletion of the same is not in breach of any statutory storage obligations or unless otherwise stipulated below. Cookies: a) Session cookiesWe use cookies on our website. Cookies are small text files or other storage technologies stored on your computer by your browser. These cookies process certain specific information about you, such as your browser, location data, or IP address.   This processing makes our website more user-friendly, efficient, and secure, allowing us, for example, to display our website in different languages or to offer a shopping cart function. The legal basis for such processing is Art. 6 Para. 1 lit. b) GDPR, insofar as these cookies are used to collect data to initiate or process contractual relationships. If the processing does not serve to initiate or process a contract, our legitimate interest lies in improving the functionality of our website. The legal basis is then Art. 6 Para. 1 lit. f) GDPR. When you close your browser, these session cookies are deleted. b) Third-party cookiesIf necessary, our website may also use cookies from companies with whom we cooperate for the purpose of advertising, analyzing, or improving the features of our website. Please refer to the following information for details, in particular for the legal basis and purpose of such third-party collection and processing of data collected through cookies. c) Disabling cookiesYou can refuse the use of cookies by changing the settings on your browser. Likewise, you can use the browser to delete cookies that have already been stored. However, the steps and measures required vary, depending on the browser you use. If you have any questions, please use the help function or consult the documentation for your browser or contact its maker for support. Browser settings cannot prevent so-called flash cookies from being set. Instead, you will need to change the setting of your Flash player. The steps and measures required for this also depend on the Flash player you are using. If you have any questions, please use the help function or consult the documentation for your Flash player or contact its maker for support. If you prevent or restrict the installation of cookies, not all of the functions on our site may be fully usable. Contact: If you contact us via email or the contact form, the data you provide will be used for the purpose of processing your request. We must have this data in order to process and answer your inquiry; otherwise we will not be able to answer it in full or at all. The legal basis for this data processing is Art. 6 Para. 1 lit. b) GDPR. Your data will be deleted once we have fully answered your inquiry and there is no further legal obligation to store your data, such as if an order or contract resulted therefrom. User posts, comments, and ratings: We offer you the opportunity to post questions, answers, opinions, and ratings on our website, hereinafter referred to jointly as “posts. ” If you make use of this opportunity, we will process and publish your post, the date and time you submitted it, and any pseudonym you may have used. The legal basis for this is Art. 6 Para. 1 lit. a) GDPR. You may revoke your prior consent under Art. 7 Para. 3 GDPR with future effect. All you have to do is inform us that you are revoking your consent. In addition, we will also process your IP address and email address. The IP address is processed because we might have a legitimate interest in taking or supporting further action if your post infringes the rights of third parties and/or is otherwise unlawful. In this case, the legal basis is Art. 6 Para. 1 lit. f) GDPR. Our legitimate interest lies in any legal defense we may have to mount. Follow-up comments: If you make posts on our website, we also offer you the opportunity to subscribe to any subsequent follow-up comments made by third parties. In order to be able to inform you about these follow-up comments, we will need to process your email address. The legal basis for this is Art. 6 Para. 1 lit. a) GDPR. You may revoke your prior consent to this subscription under Art. 7 Para. 3 GDPR with future effect. All you have to do is inform us that you are revoking your consent or click on the unsubscribe link contained in each email. Twitter: We maintain an online presence on Twitter to present our company and our services and to communicate with customers/prospects. Twitter is a service provided by Twitter Inc. , 1355 Market Street, Suite 900, San Francisco, CA 94103, USA. We would like to point out that this might cause user data to be processed outside the European Union, particularly in the United States. This may increase risks for users that, for example, may make subsequent access to the user data more difficult. We also do not have access to this user data. Access is only available to Twitter. Twitter Inc. is certified under the Privacy Shield and committed to adhering to European privacy standards. https://www. privacyshield. gov/participant?id=a2zt0000000TORzAAO&amp;status=Active The privacy policy of Twitter can be found at https://twitter. com/privacy YouTube: We maintain an online presence on YouTube to present our company and our services and to communicate with customers/prospects. YouTube is a service of Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Ireland, a subsidiary of Google LLC, 1600 Amphitheater Parkway, Mountain View, CA 94043 USA. We would like to point out that this might cause user data to be processed outside the European Union, particularly in the United States. This may increase risks for users that, for example, may make subsequent access to the user data more difficult. We also do not have access to this user data. Access is only available to YouTube. Google LLC is certified under the Privacy Shield and committed to comply with European privacy standards. https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active The YouTube privacy policy can be found here: https://policies. google. com/privacy LinkedIn: We maintain an online presence on LinkedIn to present our company and our services and to communicate with customers/prospects. LinkedIn is a service of LinkedIn Ireland Unlimited Company, Wilton Plaza, Wilton Place, Dublin 2, Irland, a subsidiary of LinkedIn Corporation, 1000 W. Maude Avenue, Sunnyvale, CA 94085, USA. We would like to point out that this might cause user data to be processed outside the European Union, particularly in the United States. This may increase risks for users that, for example, may make subsequent access to the user data more difficult. We also do not have access to this user data. Access is only available to LinkedIn. LinkedIn Corporation is certified under the Privacy Shield and committed to comply with European privacy standards. https://www. privacyshield. gov/participant?id=a2zt0000000L0UZAA0&amp;status=Active The LinkedIn privacy policy can be found here: https://www. linkedin. com/legal/privacy-policy Social media links via graphics: We also integrate the following social media sites into our website. The integration takes place via a linked graphic of the respective site. The use of these graphics stored on our own servers prevents the automatic connection to the servers of these networks for their display. Only by clicking on the corresponding graphic will you be forwarded to the service of the respective social network. Once you click, that network may record information about you and your visit to our site. It cannot be ruled out that such data will be processed in the United States. Initially, this data includes such things as your IP address, the date and time of your visit, and the page visited. If you are logged into your user account on that network, however, the network operator might assign the information collected about your visit to our site to your personal account. If you interact by clicking Like, Share, etc. , this information can be stored your personal user account and possibly posted on the respective network. To prevent this, you need to log out of your social media account before clicking on the graphic. The various social media networks also offer settings that you can configure accordingly. The following social networks are integrated into our site by linked graphics: twitter: Twitter Inc. , 795 Folsom St. , Suite 600, San Francisco, CA 94107, USA Privacy Policy: https://twitter. com/privacy EU-US Privacy Shield https://www. privacyshield. gov/…0000TORzAAO&amp;status=Active YouTube: Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland, a subsidiary of Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043 USA Privacy Policy: https://policies. google. com/privacy EU-US Privacy Shield https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active LinkedIn: LinkedIn Ireland Unlimited Company, Wilton Plaza, Wilton Place, Dublin 2, Irland, a subsidiary of LinkedIn Corporation, 1000 W. Maude Avenue, Sunnyvale, CA 94085 USA. Privacy Policy: https://www. linkedin. com/legal/privacy-policy EU-US Privacy Shield https://www. privacyshield. gov/participant?id=a2zt0000000L0UZAA0&amp;status=Active Twitter plug-in: Our website uses the plug-in of the Twitter social network. The Twitter service is operated by Twitter Inc. , 795 Folsom St. , Suite 600, San Francisco, CA 94107, USA (“Twitter”). Through certification according to the EU-US Privacy Shield https://www. privacyshield. gov/participant?id=a2zt0000000TORzAAO&amp;status=Active Twitter guarantees that it will follow the EU’s data protection regulations when processing data in the United States. The legal basis is Art. 6 Para. 1 lit. f) GDPR. Our legitimate interest lies in improving the quality of our website. If the plug-in is stored on one of the pages you visit on our website, your browser will download an icon for the plug-in from Twitter’s servers in the USA. For technical reasons, it is necessary for Twitter to process your IP address. In addition, the date and time of your visit to our website will also be recorded. If you are logged in to Twitter while visiting one of our plugged-in websites, the information collected by the plug-in from your specific visit will be recognized by Twitter. The information collected may then be assigned to your personal account at Twitter. If, for example, you use the Twitter Tweet button, this information will be stored in your Twitter account and may be published on the Twitter platform. To prevent this, you must either log out of Twitter before visiting our site or make the appropriate settings in your Twitter account. Further information about the collection and use of data as well as your rights and protection options in Twitter’s privacy policy found at https://twitter. com/privacy Google Analytics: We use Google Analytics on our website. This is a web analytics service provided by Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland (hereinafter: Google). Through certification according to the EU-US Privacy Shield https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active Google guarantees that it will follow the EU’s data protection regulations when processing data in the United States. The Google Analytics service is used to analyze how our website is used. The legal basis is Art. 6 Para. 1 lit. f) GDPR. Our legitimate interest lies in the analysis, optimization, and economic operation of our site. Usage and user-related information, such as IP address, place, time, or frequency of your visits to our website will be transmitted to a Google server in the United States and stored there. However, we use Google Analytics with the so-called anonymization function, whereby Google truncates the IP address within the EU or the EEA before it is transmitted to the US. The data collected in this way is in turn used by Google to provide us with an evaluation of visits to our website and what visitors do once there. This data can also be used to provide other services related to the use of our website and of the internet in general. Google states that it will not connect your IP address to other data. In addition, Google provides further information with regard to its data protection practices at https://www. google. com/intl/de/policies/privacy/partners, including options you can exercise to prevent such use of your data. In addition, Google offers an opt-out add-on at https://tools. google. com/dlpage/gaoptout?hl=en in addition with further information. This add-on can be installed on the most popular browsers and offers you further control over the data that Google collects when you visit our website. The add-on informs Google Analytics’ JavaScript (ga. js) that no information about the website visit should be transmitted to Google Analytics. However, this does not prevent information from being transmitted to us or to other web analytics services we may use as detailed herein. YouTube: We use YouTube on our website. This is a video portal operated by YouTube LLC, 901 Cherry Ave, 94066 San Bruno, CA, USA, hereinafter referred to as “YouTube”. YouTube is a subsidiary of Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland, hereinafter referred to as “Google”. Through certification according to the EU-US Privacy Shield https://www. privacyshield. gov/participant?id=a2zt000000001L5AAI&amp;status=Active Google and its subsidiary YouTube guarantee that they will follow the EU’s data protection regulations when processing data in the United States. We use YouTube in its advanced privacy mode to show you videos. The legal basis is Art. 6 Para. 1 lit. f) GDPR. Our legitimate interest lies in improving the quality of our website. According to YouTube, the advanced privacy mode means that the data specified below will only be transmitted to the YouTube server if you actually start a video. Without this mode, a connection to the YouTube server in the USA will be established as soon as you access any of our webpages on which a YouTube video is embedded. This connection is required in order to be able to display the respective video on our website within your browser. YouTube will record and process at a minimum your IP address, the date and time the video was displayed, as well as the website you visited. In addition, a connection to the DoubleClick advertising network of Google is established. If you are logged in to YouTube when you access our site, YouTube will assign the connection information to your YouTube account. To prevent this, you must either log out of YouTube before visiting our site or make the appropriate settings in your YouTube account. For the purpose of functionality and analysis of usage behavior, YouTube permanently stores cookies on your device via your browser. If you do not agree to this processing, you have the option of preventing the installation of cookies by making the appropriate settings in your browser. Further details can be found in the section about cookies above. Further information about the collection and use of data as well as your rights and protection options in Google’s privacy policy found at https://policies. google. com/privacy{% comment %} MailChimp - Newsletter: We offer you the opportunity to register for our free newsletter via our website. We use MailChimp, a service of The Rocket Science Group, LLC, 512 Means Street, Suite 404, Atlanta, GA 30318, USA, hereinafter referred to as “The Rocket Science Group”. Through certification according to the EU-US Privacy Shield https://www. privacyshield. gov/participant?id=a2zt0000000TO6hAAG&amp;status=Active the Rocket Science Group guarantees that it will follow the EU’s data protection regulations when processing data in the United States. In addition, the Rocket Science Group offers further information about its data protection practices at http://mailchimp. com/legal/privacy/ If you register for our free newsletter, the data requested from you for this purpose, i. e. your email address and, optionally, your name and address, will be processed by The Rocket Science Group. In addition, your IP address and the date and time of your registration will be saved. During the registration process, your consent to receive this newsletter will be obtained together with a concrete description of the type of content it will offer and reference made to this privacy policy. The newsletter then sent out by The Rocket Science Group will also contain a tracking pixel called a web beacon. This pixel helps us evaluate whether and when you have read our newsletter and whether you have clicked any links contained therein. In addition to further technical data, such as data about your computer hardware and your IP address, the data processed will be stored so that we can optimize our newsletter and respond to the wishes of our readers. The data will therefore increase the quality and attractiveness of our newsletter. The legal basis for sending the newsletter and the analysis is Art. 6 Para. 1 lit. a) GDPR. You may revoke your prior consent to receive this newsletter under Art. 7 Para. 3 GDPR with future effect. All you have to do is inform us that you are revoking your consent or click on the unsubscribe link contained in each newsletter. {% endcomment %} Model Data Protection Statement for Anwaltskanzlei Weiß &amp; Partner "
    }, {
    "id": 7,
    "url": "/page2/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Posts:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 8,
    "url": "/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ &#8220;sitemap. xml&#8221;   absolute_url }}   "
    }, {
    "id": 9,
    "url": "/Windows-Virtual-Desktop-Admin/",
    "title": "WVD Admin - A native administration Gui for Windows Virtual Desktop",
    "body": "2019/11/02 - Windows Virtual Desktop is generally available and under continuous improvement. There was the time before Ignite 2019 where no administration GUI was publicly available. This changed with Ignite. The PG of Remote Desktop services releases an in-portal configuration for Windows Virtual Desktop which looks very nice and has a lot of configurable options. See https://twitter. com/RDS4U/status/1189773044094361601 for a preview or check it out in the Azure portal. Sometimes it helps to have a native GUI to make some configuration. Therefore I build a tool to do this. At this time you can administrate an existing WVD Tenant, add apps and desktops, send messages to users and more. The next version will have the capability to start and stop the VMs in Azure and do mass-rollout like Citrix’s machine creation service (with a template managing to build golden images). To work with the GUI you need a service principal with the permission to administrate your WVD tenant or tenants. I decide to use a service principal at this time to avoid confusion if my Azure Ad user only a guest account in the WVD tenant to administrate. On the other hand: This service principal will be used in the next version to rollout new session hosts and to change their power state. To give your service principal the right permission to your tenant execute the following PowerShell script first (where Builder City is the tenant name and 89050a12-d7a5-49ee-97cd-000000000000 your service principal id): 1New-RdsRoleAssignment -TenantName  Builder City  -RoleDefinitionName  RDS Owner  -ApplicationId 89050a12-d7a5-49ee-97cd-000000000000And finally: Please give me feedback if something doesn’t work as expected or if you miss something. Feel free to test it and download the 64-bit Windows application “WVD Admin” from here: WVDAdmin. zip "
    }, {
    "id": 10,
    "url": "/PolarConf-2019/",
    "title": "PolarConf 2019 - Building own solutions whit Azure Monitor ",
    "body": "2019/10/16 - In October I visited Finland the very first time to speak at PolarConf and I have to say: It was amazing. A great single track event over two days. It was the first conference where I had a speak with only one track. And I have to say: It’s a really good concept. No half-full tracks and missing the feeling you miss a parallel track (or simple: you have not to decide between two or more tracks). What to say about Finland: It an amazing country in the north of Europe with some touch from the Swedish and Russian cultures. It looks very clear, focused and with a sustainable mindset on the subject of environmental protection. And finally: I love the sauna culture. But back to the conference: I had the chance to talk about building own solutions with Azure Monitor. Finalize the session I put the presentation I held here: PolarConf 2019 - Build your own Azure Monitor solution. pdf Site information: One part of my presentation was to show the Tweet count with #PolarConf with Azure Monitor. Thanks to @techmike2kx https://polarconf. fi/ "
    }, {
    "id": 11,
    "url": "/Anouncing-Project-MySmartScale/",
    "title": "Announcing the community version of "Project MySmartScale"",
    "body": "2019/10/09 - Windows Virtual Desktop is released and gateways around the world are available - even in Europe which cause in a low latency - perfect. Windows Virtual Desktop supplement the current solutions on the virtualization market like Citrix Application Virtualization and VMware Horizon. It’s focused on running as-a-service in the Azure cloud and it’s very cost-efficient compared to the other vendors. Of course: The tools and the administrative capabilities for WVD differ from the others - till now. But there is still a niche that is not yet filled - until today. The VMs are running permanently even if no users using the environment which leads to avoidable costs. But there is a solution: Announcement of the community version of Project MySmartScale: “Project MySmartScale” starts and smartly deallocates session hosts for WVD. It learns about the user’s behavior and can actively logoff unused sessions at the right time to save compute power – and money. The solution is 100% based on Azure platform services and fits into the whole “as-a-service” story. But starting and stopping session hosts is not as easy as it sounds: To have the right amount of session hosts ready before users try to login in the morning you must predict the user behavior. And this is what “Project MySmartScale” does:  Predict the logon count over time based on historical data Predict the logon count over time based on the acceleration of logons Start the sessions hosts a few minutes before they are needed Stop/deallocates unused session hosts if they are not needed … Today I make this solution available via GitHub. You can easily deploy the solution into your Azure subscription and start to scale your VWD environment based on the usage. This can save up to 60-70% of the costs compared to a 24/7 pay-as-you-go model. Side-Note: It also scales a Citrix XenApp / Virtual Apps and Desktop environment in Azure without using Citrix Cloud (for IaaS). The free community version supports up to 5 VMs. Feel free to use it: https://github. com/MarcelMeurer/Project-MySmartScale "
    }, {
    "id": 12,
    "url": "/Workshop-Azure-Monitor-Examples/",
    "title": "Workshop Azure Monitor - Lessons",
    "body": "2019/09/21 - To get practice in using Azure Monitor, I have prepared some examples. These examples can be recreated with a little PowerShell. I have prepared more complex program parts. These can be found in the “Tools” folder. Finished solutions are stored in the folder “Samples”. GitHub: https://github. com/MarcelMeurer/Workshop-AzureMonitor In the Tools folder there are the following scripts:: 1. /Add-AzureMonitorData. ps1 -WorpspaceId &lt;WorkSpaceId&gt; -WorpspaceKey &lt;WorpspaceKey&gt; -LogTypeName &lt;LogTypeName&gt; [-TimeStampField &lt;TimeStampField&gt;] -JsonData &lt;JsonData&gt;Send jsonData to the Log Analytics workspace into the given LogTyeName. TimeStampField is not mandatory. If given, it must be the name of the field containing the timestamp of each data set. Missions: Store information about the running processes from your computer: Collect the process information from your computer each 30 seconds and send these data to your Log Analytics workspace. Use PowerShell to automate this mission. Select an app and use this app to “overload” your CPU. If data are visible in Log Analytics, build a custom dashboard by using “Log” to query the data.    Find out:      Count of distinct processes   Average CPU load over time (all processes). Render a time chart   Render a time chart for the app you used to overload the CPU      Some useful PowerShell commands:  12345#Get cpu consumption by process(Get-Counter  \process(*)\% Processor Time ). CounterSamples#Convert objects to $json=$object | ConvertTo-JsonStore temperature data for multiple cities: Collect data from OpenWeatherMap for three different cities each 30 seconds. Send the data to your Log Analytics workspace using Add-AzureMonitorData. ps1. Use PowerShell to automate this mission. If data are visible in Log Analytics, build a custom dashboard using the View Designer within Log Analytics. Build:  One overview tile showing the number of the different cities Two dashboards showing the temperature and humidity as a chart and as a list per city Connect PowerBi Dekstop to your data: Display Line Charts and use a selector/filter for the cities (drop down field)Hints:    Collect data from OpenWeatherMap      https://openweathermap. org/   Create an account and api key   Test your key (it can take some minutes): https://api. openweathermap. org/data/2. 5/weather?q=Bonn&amp;APIKEY=xxxxxxx      Some useful PowerShell commands:  12345678#Endless-loopdo {  } while ($true)#Sleep $n secondssleep $n#make a http requestInvoke-WebRequest -Uri $uri -Method GET -ContentType  application/json Build your own log-writer function: Build a log-writer function for your own PowerShell scripts using Log Analytics. There are some request to your solution:  Have the following columns:     TimeStamp (as TimeGeneratedField)                         Serverity (Debug       Information       Warning       Error)                     Message (Text)   ScriptName (Name of the script using your function)   "
    }, {
    "id": 13,
    "url": "/Speaking-update/",
    "title": "On the road - My next speaking engagements",
    "body": "2019/09/07 - I’m happy to be a part of a great community.  On my journey, I have the possibility to speak at some conferences, meetups and other events. And I loved it. Especially, if I can talk about Azure, IoT, Machine Learning, AI, Azure Monitor, etc. Maybe we will meet personally at one of the next events: "
    }, {
    "id": 14,
    "url": "/CDC-Germany-RDS-&-Windows-Virtual-Desktop-Desktops-in-2019/",
    "title": "CDC Germany: RDS and Windows Virtual Desktop – Desktops in the year 2019 and beyond",
    "body": "2019/05/23 - From 21. to 22. April 2019 the annual Cloud and Datacenter Conference took place in Hanau/Frankfurt in Germany. It’s one of my favorite community events in Germany. This year I was allowed to contribute something to RDS in Windows Server 2019 and Windows Virtual Desktop – including Windows 10 Multi Session Host and FSLogix (an awesome combination). I published my slides to slideshare. net: https://de. slideshare. net/MarcelMeurer/rds-windows-virtual-desktop-desktop-in-2019 The demos are also available via Youtube:: Windows Virtual Desktop - Login to a shared Windows 10 Multi Session Host: https://youtu. be/rgsaQf3hmHw Windows Virtual Desktop - Update the template VM: https://youtu. be/YqrEm3EhbVY Windows Virtual Desktop - Build a new Image from a template VM: https://youtu. be/MOuH482A1co Windows Virtual Desktop - Deploy a VM from a template via PowerShell: https://youtu. be/U9zxyk_HuAM Windows Virtual Desktop - Deploy a Scale Set from an image, re-scale, Azure Monitor: https://youtu. be/_l5P_JeQANM Fist published on: https://www. sepago. de/blog/cdc-germany-rds-windows-virtual-desktop-desktops-in-2019/ "
    }, {
    "id": 15,
    "url": "/Publish-your-solution-to-the-Azure-Marketplace/",
    "title": "Publish your solution to the Azure Marketplace",
    "body": "2019/03/25 - Publishing own solutions to the Azure Marketplace seems to be very easy by using the documentation on https://docs. microsoft. com/en-us/azure/marketplace/marketplace-publishers-guide. To avoid any pitfalls I wrote down some insights about my first approach. In this blog, I will focus on “Azure Applications” The Cloud Partner Dashboard: Make sure that you have access to the Cloud Partner Portal at https://cloudpartner. azure. com. In my case, I use my coopered credentials to log in. Assign your Dev Center account details via Publisher Profile: Hint:I had some trouble doing this. My Dev Center account was not accepted. The reason was that my Dev Center account and my cooperated account names are/aren’t similar. A Dev Center account is always an MSA (former live id). So, I couldn’t invite this account into the Cloud Partner portal. My workaround:  Create a new MSA, e. g. myname. dev@outlook. com Create a new Dev Center account with the new MSA: https://developer. microsoft. com Add the new MSA into the Cloud Partner Portal Assign your Dev Center accountPrepare your publishing package: Publishing (-) Azure Applications means that you provide an ARM template and other resources, like:  mainTemplate. json createUiDefinition. json (https://docs. microsoft. com/en-us/azure/managed-applications/create-uidefinition-overview) nestedtemplates. …. json (for linked templates) and maybe some other foldersAll the files must be in a zip archive for (-) further upload. The folder structure is important and createUiDefinition. json and mainTemplate. json are mandatory. The ARM templates and the create UI are checked by Microsoft before your offer is available to the public. To avoid some iterations, make sure that you have observed the following things:  ARM Templates     Do not reference external sources like nested templates on GitHub – everything must be in the package   maintemplate. json must have a “parameters” property   Parameters without defaultValue s. They must have a corresponding output in createUiDefinition. json   A parameter named “location” must exist and it must have a defaultValue of resourceGroup(). location   Use the correct API versions#VM Image ref must not contain “-preview”   Do not concat Ids like:“[Concat(‘/subscriptions/’, parameters(‘subscriptionId’), ‘/resourceGroups/’, parameters(‘resourcegroup’), ‘/providers/Microsoft. OperationalInsights/workspaces/’, parameters(‘workspace’))]”use resourceId:“[resourceId(‘Microsoft. OperationalInsights/workspaces’, parameters(‘workspace’))]    createUiDefinition. json     Must have a schema property   Handler property value should be ‘Microsoft. Compute. MultiVm’   Version property value must match schema version   Must have parameters and output(-) properties   Output location must be present in mainTemplate parameters   Output workspace must be present in mainTemplate parameters   Parameters should have basics and steps properties   Location must be in outputs and should match [location()]   Do not say that a user has to enter a unique name (e. g. for a web app) – generate a unique name with an appendix (use uniqueString()), e. g. :“[concat(parameters(‘resourcename’),’-‘, uniqueString(resourceGroup(). id,subscription(). subscriptionId))]”   Text boxes (for names) must have a regex constraint   Text boxes (for names) must have a validationMessage   Publish your package for a private test: After you have zipped your package, you can create a new “Azure Application” offer in the Cloud Partner portal. Select a new offer, Azure application and fill out the fields. Publish it for your personal test (add your subscription id to make it visible).  Publish your package to the public: After you have tested your package privately, you can apply to make it public to the world. This takes some time while automatism and a (human) reviewer check your templates. If something is invalid, you get a mail with a link to a pull request where you can check what’s wrong. Fist published on: https://www. sepago. de/blog/publish-your-solution-to-the-azure-marketplace/ "
    }, {
    "id": 16,
    "url": "/Why-configuring-Azure-AD-authentication-with-an-Azure-Web-App-fails/",
    "title": "Why configuring Azure AD authentication with an Azure Web App fails",
    "body": "2019/02/09 - I spent hours today adding Azure AD authentication to an Azure MVC web application with Visual Studio. I always got the same error while adding the preconfigured AD application: “Error: Unable to query for Azure AD applications: An error occurred while processing this request. ” My account has the right permission in Azure AD – I thought. After a while I found out: Visual Studio was connected to my Azure AD with three different accounts: Normally, that’s what I want, even if I have to publish some apps in other tenants/subscriptions. But in this special case two accounts are part of the Azure tenant where my Azure applications should be deployed: Visual Studio uses the first account (marked in red), which does not have the appropriate permissions. My “fast” resolution: I gave this account the right Azure AD role (Application Administrator) for 5 minutes and tried again with success: First published on: https://www. sepago. de/blog/why-configuring-azure-ad-authentication-with-an-azure-web-app-fails/ "
    }, {
    "id": 17,
    "url": "/Deploy-an-Azure-Functional-App-as-an-interface-to-Log-Analytics-Azure-Monitor/",
    "title": "Deploy an Azure Functional App as an interface to Log Analytics / Azure Monitor",
    "body": "2019/01/13 - IntroductionMicrosoft offers with Log Analytics a cloud-based big data service. Log Analytics is used by several services (including Azure itself) to log and analyze data. It’s a core component of Azure Monitor and Application Insights. Log Analytics key facts:  Cloud-based No data aggregation Pay per upload and data retention Powerful query language (kql: &lt;https://docs. microsoft. com/en-us/azure/kusto/&gt;) Direct support for visualization on portal. azure. comI use Log Analytics for several projects where data aggregation and analyzation are main tasks. If I write code, I push data directly to Log Analytics – including generating a SAS signature for every single upload. The mandatory SAS signature avoids a simple upload via http-post to Log Analytics. But in some cases, it could be very helpful to work with a simple http-post command. For example: If you use Azure Stream Analytics, you cannot push data directly to Log Analytics. To allow pushing data via http-post I built this project. This project deploys an Azure function to your subscription. This function offers a simple http(s) interface (webhook) you can use to post JSON data to it. This data will be processed by the Azure Function and will be posted to your Log Analytics workspace. Examples:With Postman: With PowerShell: 1234567$data='{ localTime : 2019-01-02T11:11:12. 013Z , Humi :46. 5, Temp :14. 2}'Invoke-WebRequest -Uri  https://testaf01xx8. azurewebsites. net/api/Send2LogAnalytics?code=xje5aQIMzPxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx==  -Method POST -Body $data With Stream Analytics: Query: 1234INTO[To-Function]FROM[From-IoT-Hub] Output: Enter your Azure Function parameters Results in Log Analytics: For another data series Deploying and configurationDeploy your Azure Function using the deploy to Azure button.  Github: https://github. com/MarcelMeurer/FunctionApp-to-LogAnalytics Configuration: In the next step enter the following parameters:  Resource Group:Select an existing or create a new resource group in a location of your choice (the function will be deployed in the Azure region of the resource group) Site name:A unique name of your function (unique means a worldwide unique hostname; the fqdn is: . azurewebsites. com) Workspace_Id:The workspace id of your Log Analytics workspace (Log Analytics resource -&gt; Advanced settings -&gt; Workspace id) Workspace_Key:The workspace id of your Log Analytics workspace (Log Analytics resource -&gt; Advanced settings -&gt; Primary or secondary key) LogType:Name of your type (“table” name). You will see this name with an appended _CL (custom log) later in your workspace with your data Time Field:Optional. All data sets you send get a new field called “TimeGenerated”. TimeGenerated contains the time the data arrived at the workspace. If you set Time field to a custom field (like localTime from the example above), the time in this field is used as TimeGenerated. Hint: Workspace_Id, Workspace_Key, LogType, Time Field can be changed later in the function app: Your Function app -&gt; Platform features -&gt; Application settings Resources: After the deployment three resources are deployed and configured:  ServerFarmPlan:A consumption-based pricing plan for the Azure Functional App. See https://azure. microsoft. com/en-us/pricing/details/functions/ check the estimated costs billed to your subscription Site name - Application Insights:Application Insights to monitor the Azure Function itself Site name - Azure Functional App:The Azure Function containing the codeGet the resource URL of the Azure Function: Open your Azure Function and navigate to Functions -&gt; Send2LogAnalytics -&gt; &lt;/&gt; Get function URL This URL contains your private key. First published on: https://www. sepago. de/blog/deploy-an-azure-functional-app-as-an-interface-to-log-analytics-azure-monitor/ "
    }, {
    "id": 18,
    "url": "/Creating-devices-for-Azure-IoT-Hub-with-SAS-token-automatically/",
    "title": "Creating devices for Azure IoT Hub with SAS token automatically",
    "body": "2018/11/23 - A few weeks ago, I started an IoT project with a company responsible for a huge amount of different buildings around the world. We deployed several virtual and physical sensors in Azure IoT Hub. Doing this we had three challenges:  Deploy new IoT devices in Azure IoT hub in a batch Generate SAS tokens for these IoT devices Generate SAS tokens even if a device still exist in Azure IoT HubThe requirement of batch processing avoids the use of the Device Explorer to generate SAS token. Therefore, I wrote a short PowerShell script: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108function New-SASToken{PARAM([Parameter(Mandatory=$True)][string]$ResourceUri,[Parameter(Mandatory=$True)][string]$Key,[string]$KeyName=  ,[int]$TokenTimeOut=1800 # in seconds)[Reflection. Assembly]::LoadWithPartialName( System. Web )| out-null$Expires=([DateTimeOffset]::Now. ToUnixTimeSeconds())+$TokenTimeOut#Building Token$SignatureString=[System. Web. HttpUtility]::UrlEncode($ResourceUri)+  `n  + [string]$Expires$HMAC = New-Object System. Security. Cryptography. HMACSHA256$HMAC. key = [Convert]::FromBase64String($Key)$Signature = $HMAC. ComputeHash([Text. Encoding]::ASCII. GetBytes($SignatureString))$Signature = [Convert]::ToBase64String($Signature)$SASToken =  SharedAccessSignature sr=  + [System. Web. HttpUtility]::UrlEncode($ResourceUri) +  &amp;sig=  + [System. Web. HttpUtility]::UrlEncode($Signature) +  &amp;se=  + $Expiresif ($KeyName -ne  ){$SASToken=$SASToken+ &amp;skn=$KeyName }return $SASToken}function New-IoTDevice{PARAM([Parameter(Mandatory=$True)][string]$IoTHubConnectionString,[Parameter(Mandatory=$True)][string]$DeviceId)[Reflection. Assembly]::LoadWithPartialName( System. Web )| out-null$strings=$IoTHubConnectionString. split( ; )$keys =@{}for ($i=0; $i -lt $strings. count; $i++){$keys[$strings[$i]. split( = )[0]]=$strings[$i]. split( = )[1]}$keys[ SharedAccessKey ]=$keys[ SharedAccessKey ]+ = $body='{deviceId: '+$DeviceId+' }'try{$webRequest=Invoke-WebRequest -Method PUT -Uri  https://$($keys[ HostName ])/devices/$([System. Web. HttpUtility]::UrlEncode($DeviceId))?api-version=2018-06-30  -ContentType  application/json  -Header @{ Authorization = (New-SASToken -ResourceUri $keys[ HostName ] -Key $keys[ SharedAccessKey ] -KeyName $keys[ SharedAccessKeyName ])} -Body $body -UseBasicParsing} catch [System. Net. WebException]{if ($_. Exception. Response. StatusCode. value__ -eq 409){write-host  Device exists. Getting data from IoT hub $webRequest=Invoke-WebRequest -Method GET -Uri  https://$($keys[ HostName ])/devices/$([System. Web. HttpUtility]::UrlEncode($DeviceId))?api-version=2018-06-30  -ContentType  application/json  -Header @{ Authorization = (New-SASToken -ResourceUri $keys[ HostName ] -Key $keys[ SharedAccessKey ] -KeyName $keys[ SharedAccessKeyName ])} -UseBasicParsing}else{Write-Error  An exception was caught: $($_. Exception. Message) }}return ConvertFrom-Json $webRequest. Content}function Send-IoTDeviceTestString{PARAM([Parameter(Mandatory=$True)][string]$sasToken)[Reflection. Assembly]::LoadWithPartialName( System. Web )| out-null$t1=[System. Web. HttpUtility]::UrlDecode($sasToken)$t2=$t1. Split( = )$t3=$t2[1]. Split( &amp; )[0]$deviceId=$t3. Split( / )[2]$iotHubDeviceHost=$t3$iotHubRestURI =  https://$($iotHubDeviceHost)/messages/events?api-version=2018-04-01 #$iotHubRestURI$Headers = @{ Authorization  = $sasToken;  Content-Type  =  application/json }# Message Payload$datetime = get-date$body = @{datetime = $datetimedeviceId = $deviceIdMessage =  Sending data to iot hub }$body = $body | ConvertTo-Jsonreturn Invoke-RestMethod -Uri $iotHubRestURI -Headers $Headers -Method Post -Body $body}#$iotHubName =  Workshop-IoT  # host name of the iot hub$iotManagementConnectionString= HostName=Workshop-IoT. azure-devices. net;SharedAccessKeyName=iothubowner;SharedAccessKey=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx  # insert the connection string of your iot hub# name of the new devices$array = @( TestDev1 , SEPAGO_HBS2. 0_DE_Cologne_HQ_VDEV_ISP08-IO0 , SEPAGO_HBS2. 0_DE_Cologne_HQ_VDEV_ISP08-RTU )foreach ($deviceId in $array){Write-Host  New device created: $($deviceId) $device=New-IoTDevice -IoTHubConnectionString $iotManagementConnectionString -DeviceId $deviceId$sasToken=New-SASToken -ResourceUri  $($iotHubName). azure-devices. net/devices/$([System. Web. HttpUtility]::UrlEncode($device. deviceId))  -Key $device. authentication. symmetricKey. primaryKeywrite-host  DeviceId: ,$device. deviceIdwrite-host  SASToken: ,$sasToken$deviceConfigSend-IoTDeviceTestString -sasToken $sasTokenwrite-host( -------------------------- )}Feel free to use it in your projects. Feedback welcome First published on: https://www. sepago. de/blog/creating-devices-for-azure-iot-hub-with-sas-token-automatically/ "
    }, {
    "id": 19,
    "url": "/OneDrive-PowerShell-Module-Added-support-for-OneDrive-for-Business/",
    "title": "OneDrive PowerShell Module - Added support for OneDrive for Business",
    "body": "2018/11/05 - More than two years ago, I created my PowerShell module to access OneDrive. This module can be installed with a one-liner from https://www. powershellgallery. com/packages/OneDrive Again, I was asked to support OneDrive for Business and finally, I’m ready: From version 2. 0. 0 OneDrive for Business is supported. I provide the complete documentation on GitHub, where I will maintain it: https://github. com/MarcelMeurer/PowerShellGallery-OneDrive Here is the summary of version 2. 0. 0: -——————————————— The OneDrive PowerShell module is available via PowerShellGallery. com. If you want to support and work with me feel free to make changes cloning this repo, change and send me and a pull request. This OneDrive version (2. 0. 0 and higher in PowerShellGallery. com) supports:  OneDrive personal OneDrive for BusinessInstallation: Open PowerShell and 1Install-Module -Name OneDrive -Scope CurrentUser -forceYou can update the module to a newer version with the same command (-force). If you don’t use PowerShellGet currently, go to the Gallery on https://www. powershellgallery. com/packages/OneDrive and click “Get Started”. Check your installation with Get-Help -Name OneDrive Authentication: Before you start using the OneDrive module you have registered your script/application. This differs depending on the OneDrive version to be used. OneDrive Personal: Read this on my blog: https://www. sepago. de/blog/onedrive-powershell-module-new-version-with-improved-authentication/  Go to: https://apps. dev. microsoft. com and login with your Microsoft Account (MSA) and “Add an app” in the category “converged applications” Enter a name and press “create” Press “Generate New Password” and save the password (app key) Also, save the “Application id” Press “Add Platforms” and select “Web” Check “Allow implicit Flow” and enter a “Redirect URL”. This is not a real URL. Choose a localhost address and note it. In my case, I chose: http://localhost/login Press “Save” Now you have all the necessary data for your app/script:     Client Id: 5dd40b03-0ead-451b-b5e3-f704550e8cca   AppKey: xqacs8K92MuCJKgciRHQ1Cf   RedirectURI: http://localhost/login    To get an authentication token use:1$Auth=Get-ODAuthentication -ClientID 5dd40b03-0ead-451b-b5e3-f704550e8cca -AppKey xqacs8K92MuCJKgciRHQ1Cf -RedirectURI http://localhost/login OneDrive for Business: To use OneDrive for business you have to register your script/app to in Azure Active Directory  Add an application in Azure Active Directory inside the Azure portal: https://portal. azure. com/#blade/Microsoft_AAD_IAM/ActiveDirectoryMenuBlade/RegisteredApps Chose “New application registration”   Give your application a name and a unique sign-on URL. The sign-on URL has to be a valid URL but doesn’t have to exist. E. g. : http://sepago. de/1Drive4Business (make later sure that this URL is in the reply URL list of your application)     Within the “Required permissions” add “Office 365 SharePoint Online (Microsoft. Sharepoint)”     Select “Read and write user files” below “delegated permissions” for the Office 365 API     Generate a secret key for this application and save it for later use. Also, save the application Id     You should now have the following parameter:      Client Id: 2831fc52-e1b8-4493-9f3a-a3dad74b2081   AppKey: TqoSXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX=   RedirectURI: http://sepago. de/1Drive4Business      Additionally you need the resource URL for OneDrive for Business. Normally: https://-my. sharepoint. com/. In our company this is the URL “   https://sepagogmbh-my. sharepoint. com/   ” (the last one / is important).      Resource ID: https://sepagogmbh-my. sharepoint. com/    To get an authentication token use:1$Auth=Get-ODAuthentication -ClientId  2831fc52-e1b8-4493-9f3a-a3dad74b2081  -AppKey  TqoSXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX= &amp;nbsp; -RedirectURI  http://sepago. de/1Drive4Business  -ResourceId  https://sepagogmbh-my. sharepoint. com/ Renew the authentication with a refresh token: An access token is 1 hour valid. You can get a new access token with the refresh token provided by the last authentication. This is necessary if you are creating a script that will work for a long time without further user input. Renew your access token automatically in the program code. 1$Auth=Get-ODAuthentication -ClientId 2831fc52-e1b8-4493-9f3a-a3dad74b2081 -AppKey  TqoSXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX=  -RedirectURI  http://sepago. de/1Drive4Business  -ResourceId  https://sepagogmbh-my. sharepoint. com/  -RefreshToken $LastAuth. refresh_token Where $LastAuth is your last authentication result (containing the refresh token) For OneDrive personal leave the ResourceId empty (-ResourceId “”)Working with files and folders: Get an authentication code from above and store it in $Auth List files and folders: 1Get-ODChildItems -AccessToken $Auth. access_token -ResourceId  https://sepagogmbh-my. sharepoint. com/  -path  / List files and folders: Remove-ODItem -AccessToken $Auth. access_token -ResourceId “https://sepagogmbh-my. sharepoint. com/” -path “/Upload” Creating a folder: 1New-ODFolder -AccessToken $Auth. access_token -ResourceId  https://sepagogmbh-my. sharepoint. com/  -path  /  -FolderName  Upload Upload local files to OneDrive: 1Add-ODItem -AccessToken $Auth. access_token -ResourceId  https://sepagogmbh-my. sharepoint. com/  -LocalFile  D:\DEV\PowerShell\PowerShellGallery-OneDrive\Test\Uploads\IoT Workshop. pptx  -Path  /Upload List OneDrive drives: 1Get-ODDrives -AccessToken $Auth. access_token -ResourceId  https://sepagogmbh-my. sharepoint. com/ Downloading some files: 123Get-ODItem -AccessToken $Auth. access_token -ResourceId  https://sepagogmbh-my. sharepoint. com/  -Path  /Upload/Doings. txt  -LocalPath  D:\DEV\PowerShell\PowerShellGallery-OneDrive\Test\Downloads Get-ODItem -AccessToken $Auth. access_token -ResourceId  https://sepagogmbh-my. sharepoint. com/  -Path  /Upload/Doings. txt  -LocalPath  D:\DEV\PowerShell\PowerShellGallery-OneDrive\Test\Downloads  -LocalFileName  Copy from OneDrive. Doings. txt Delete a file in OneDrive: 1Remove-ODItem -AccessToken $Auth. access_token -ResourceId  https://sepagogmbh-my. sharepoint. com/  -Path  /Upload/Doings. txt First published on: https://www. sepago. de/blog/onedrive-powershell-module-added-support-for-onedrive-for-business/ "
    }, {
    "id": 20,
    "url": "/Working-with-the-OneDrive-PowerShell-Module/",
    "title": "Working with the OneDrive PowerShell Module",
    "body": "2018/09/29 - Recently I got some questions on how to work with my PowerShell module for OneDrive. Therefore, I put together some examples. Remember: The OneDrive module is for OneDrive personal and doesn’t work with OneDrive business / Sharepoint. First: Register an app (authentication) for OneDrive: https://www. sepago. de/blog/onedrive-powershell-module-new-version-with-improved-authentication/ Authenticate to OneDrive: 1234$Authentication=Get-ODAuthentication -ClientID  xxxxxxxxxxxxxxxxxxxxxxx  -AppKey  yyyyyyyyyyyyyyyy  -RedirectURI  http://localhost/login $at=$Authentication. access_token Show files and folders: 1Get-ODChildItems -AccessToken $at -path  /  Create a new folder in OneDrive 1New-ODFolder -AccessToken $at -FolderName  Images  Copy files from local to OneDrive 1Add-ODItem -AccessToken $at -LocalFile  . \LA-02. jpg  -Path  /Images  Copy file from OneDrive to local disk 12Get-ODItem -AccessToken $at -Path  /Images/LA-02. jpg  -LocalPath  D:\Local\downloads Get-ODItem -AccessToken $at -Path  /Images/LA-02. jpg  -LocalPath  D:\Local\downloads  -LocalFileName  Copy from OneDrive. jpg  Delete file in OneDrive 1Remove-ODItem -AccessToken $at -Path  /Images/LA-02. jpg  First published on: https://www. sepago. de/blog/working-with-the-onedrive-powershell-module/ "
    }, {
    "id": 21,
    "url": "/Adding-Guest-Users-to-Azure-AD-from-Excel-with-PowerShell/",
    "title": "Adding Guest Users to Azure AD from Excel with PowerShell",
    "body": "2018/07/13 - Sharing access across different tenants in one of the key benefits of Azure AD. My customers appreciate that they can provide Azure-based solution to their cooperated users and to guest users as well. Cooperated users include users from the group and subsidiaries. They all can access resources with one identity – on-premises and in the cloud (Same-sign-on, single-sign-on). Guest users can be deployed manually via the Azure portal, via PowerShell or with a connector to another system (like SAP HR). Adding users from an Excel file can be done with PowerShell. To show an example I created an Excel file with some headers:  Company Surname Name Mail Job role To add this user, we must archive these steps:  Login into Azure AD with appropriate rights Enumerate through the excel table Inviting the user Adding the right properties (company, name, surname, …) to the invited user objectTo do this I prepared this script: 123456789101112131415161718192021222324252627282930313233343536373839$invocation = (Get-Variable MyInvocation). Value$directorypath = Split-Path $invocation. MyCommand. Path$directorypath$ExcelFile=$directorypath+ \Users2Invite. xlsx  # Path to the excel file$InviteRedirectURL= https://mycompany. com  # Redirect url after the first logon$WorkSheetNum= Tabelle1  # Name of the table in the excel fileif (!$lastLogin) {  # put your Azure AD tenant id here (Azure portal / Azure Active Directory / Properties / Directory ID)  $global:lastLogin=Connect-AzureAD -TenantId  xxxxxxxxxxxxx-xxxxxxxx-xxxxxxxxxxx-xxxxxxxxxxx  }$Excel = New-Object -ComObject Excel. Application$WorkBook = $Excel. Workbooks. Open($ExcelFile)$WorkSheet = $WorkBook. WorkSheets. Item($WorkSheetNum)$RowNum = 2While ($WorkSheet. Cells. Item($RowNum, 1). Text -ne   ) { # Read the first line from sheet $Company =  Ext:  +$WorkSheet. Cells. Item($RowNum, 1). Text. trim() $Surname = $WorkSheet. Cells. Item($RowNum, 2). Text. trim() $Name = $WorkSheet. Cells. Item($RowNum, 3). Text. trim() $Mailadress = $WorkSheet. Cells. Item($RowNum, 4). Text. trim() $JobTitle = $WorkSheet. Cells. Item($RowNum, 5). Text. trim() $userFullName=$Name+ ,  +$Surname Write-Output( Adding user:  +$userFullName+  ( +$Mailadress+ ) ) $invitation=New-AzureADMSInvitation -InvitedUserDisplayName $userFullName -InvitedUserEmailAddress $Mailadress -SendInvitationMessage $true -InviteRedirectURL $InviteRedirectURL $user = Get-AzureADUser -ObjectId $invitation. InvitedUser. Id Set-AzureADUser -ObjectId $invitation. InvitedUser. Id -Surname $Name Set-AzureADUser -ObjectId $invitation. InvitedUser. Id -GivenName $Surname Set-AzureADUser -ObjectId $invitation. InvitedUser. Id -JobTitle $JobTitle Set-AzureADUser -ObjectId $invitation. InvitedUser. Id -Department $Company Set-AzureADUser -ObjectId $invitation. InvitedUser. Id -Displayname $user. Displayname $RowNum++}If you run this script all users in the excel file will be invited to your Azure AD tenant. Remark: The company field can not be written to an Azure AD user object (read-only). So I write the company to the department field. First published on: https://www. sepago. de/blog/adding-guest-users-to-azure-ad-from-excel-with-powershell/ "
    }, {
    "id": 22,
    "url": "/Enumerating-Azure-AD-administrative-accounts-with-PowerShell/",
    "title": "Enumerating Azure AD administrative accounts with PowerShell",
    "body": "2018/06/22 - Users can have different administrative roles in Azure Ad. Azure Portal can show these roles and members. Sometimes it can be favorable to get roles and members in a PowerShell object list. To login into your Azure AD tenant use: 1Connect-AzureAD -TenantId xxxWhere xxx is your tenant id. The -TenantId is optional. But if your account member of different Azure ADs you can select the right one. After login in with your credential you can show the different roles with: 1Get-AzureADDirectoryRoleOutput: Using PSCustomObject helps to build a list/array of custom objects to save all roles and users. The full code: 12345678910111213141516171819$roleUsers = @() $roles=Get-AzureADDirectoryRoleForEach($role in $roles) { $users=Get-AzureADDirectoryRoleMember -ObjectId $role. ObjectId ForEach($user in $users) {  write-host $role. DisplayName,$user. DisplayName  $obj = New-Object PSCustomObject  $obj | Add-Member -type NoteProperty -name RoleName -value     $obj | Add-Member -type NoteProperty -name UserDisplayName -value     $obj | Add-Member -type NoteProperty -name IsAdSynced -value false  $obj. RoleName=$role. DisplayName  $obj. UserDisplayName=$user. DisplayName  $obj. IsAdSynced=$user. DirSyncEnabled -eq $true  $roleUsers+=$obj }}$roleUsersOutput: Feel free to extend the custom object with other values form Azure AD user object. First published on: https://www. sepago. de/blog/enumerating-azure-ad-administrative-accounts-with-powershell-2/ "
    }, {
    "id": 23,
    "url": "/Deploying-a-custom-OMS-Log-Analytics-Workspace-via-GitHub-Avoid-problems-with-ARM-templates/",
    "title": "Deploying a custom OMS Log Analytics Workspace via GitHub – Avoid problems with ARM templates",
    "body": "2018/05/03 - Azure is “my” cloud with a lot of platform services allowing users, programmers, and DevOps building powerful and scalable solutions. One of my favorite ones is Azure OMS Log Analytics – a big data platform with a great query language and professional dashboards. In the past, I build a custom agent to collect data from Microsoft RDS and Citrix environment to provide a deep insight into the user experiences and resource usage http://loganalytics. sepago. com/. Additionally, I have built four dashboards and a lot of views to visualize the data:  To make it easier to deploy an OMS Log Analytics workspace including my tiles and views I decided to offer a “Deploy to Azure” solution via GitHub. Finally, an ARM template for an Azure deployment. One ARM template including all resources (doesn’t work well) First, I built an ARM template including the workspace definition and four definitions of the tiles (including their views). But I got some weird effects: Sometimes I got only 2 tiles with a deployment, sometimes 3 and rarely the four I expected. What happens – or what I thought what happened? The tile definition in the ARM files is independent of each other’s, so the ARM engine tried to deploy them parallel. And here is a problem: This didn’t (and don’t) work with the current API. The API didn’t wait for the full deployment and finished after the first tile is deployed. One ARM template for the deployment and one for each tile (works well) It took days to find a reliable solution. The solution I use now works differently: I have one ARM template for each tile and one ARM template for the workspace itself. The ARM template for the workspace references all the four tile ARM templates using the resource type “Microsoft. Resources/deployments”. This deployment type allows a special trick to avoid the parallel processing of all linked templates: A serial mode! The serial mode controls the ARM processing and avoids parallel processing. With this trick, the deployment works reliably. See the ARM templates at GitHub: https://github. com/MarcelMeurer/LogAnalytics-for-Citrix-and-RDS/ To help the community to find this workaround some keywords: “Azure OMS Log Analytics Deployment with ARM some tiles are missing” First published on: https://www. sepago. de/blog/deploying-a-custom-oms-log-analytics-workspace-via-github-avoid-problems-with-arm-templates/ "
    }, {
    "id": 24,
    "url": "/Monitoring-End-User-Computing-Environments-with-Azure-OMS-LogAnalytics-with-Deploy-to-Azure/",
    "title": "Monitoring End-User Computing Environments with Azure OMS LogAnalytics with Deploy to Azure",
    "body": "2018/03/31 - Several months ago, I built a solution focused on monitoring the user experiences on remote desktop environments based on Citrix XenApp, XenDesktop and Microsoft RDS. Particularly RDS/RDP was imported because there is no solution from Microsoft. End-user computing environments are complex and not easy to monitor. The most common monitoring solutions are focused on typical server parameters like CPU and memory consumption, free disk space and so on. But administrators need more insight into the parameters responsible for the user experience like bandwidth, latency, utilization of the virtual hardware by application, etc. To meet these demands, I decided to build a solution considering the following requirements:  Storing the raw data without aggregation to an average value per hour. I need the data per minute – for all times I need a “time back” mode to look back in the RDS environment to each time frame in the past Avoidance of any Infrastructure-as-a-service like a Windows application server, SQL database or the likeIt was obvious to use an Azure service as a platform for my solution.  And so, I built my solution based on Azure OMS LogAnalytics. Azure OMS offers a “big-data style” platform to save, index, query and visualize data. The core part of this solution is my small agent: Installed on each worker (Citrix or Microsoft) it collects, combines and uploads data to your personal Azure OMS Log Analytics workspace. And of course: It offers monitoring of RDS/Citrix workers in any cloud as well as on-premises / hybrid works. Description of the full solution (incl. download): http://loganalytics. sepago. com/ After several improvements, I can now offer a quicker and saver deployment and update for a prepared OMS workspace directly into your Azure subscription. To do this: Go to https://github. com/MarcelMeurer/LogAnalytics-for-Citrix-and-RDS and deploy your workspace directly. It’s as simple as any other deployment from the Azure marketplace: Just click the right “Deploy to Azure” button and enter a few parameters. You will get a prepared Azure OMS workspace including the tiles and views for this solution. The rollout workspace is a “standalone” pricing tier with a 360 days retention. https://github. com/MarcelMeurer/LogAnalytics-for-Citrix-and-RDS https://www. youtube. com/watch?v=A5ehFVIDotU First published on: https://www. sepago. de/blog/monitoring-end-user-computing-environments-with-azure-oms-loganalytics-with-deploy-to-azure/ "
    }, {
    "id": 25,
    "url": "/Deallocate-an-Azure-VM-from-itself/",
    "title": "Deallocate an Azure VM from itself",
    "body": "2018/01/16 - These days I’m dealing with the automation of starting and stopping Azure virtual machines. I do this to avoid unnecessary costs for customers running Citrix or RDS workers on Azure. I translated a piece of my work into a PowerShell script to de-allocate the VM on which it is running. Azure Instance Metadata Service: To get information about the running VM I use Azure Instance Metadata Service (https://docs. microsoft. com/en-us/azure/virtual-machines/windows/instance-metadata-service). This information contains the public IP address, VM size, os type and a lot more. To identify this Azure VM for later deallocation later, I need some specific information: the vmId. You can get meta data using PowerShell: 1`$md``=``Invoke-RestMethod` `-Headers` `@{`` Metadata ``=`` true ``}` `-URI` `http://169. 254. 169. 254/metadata/instance``?``api-version=2017-08-01` $md. compute. vmId contains the unique identifier for the running VM. I will use this id later to match the correct VM for deallocating. Service Principal Account: I want to deallocate the VM automatically without logging-in myself. Therefore I have to use a service principal account. It is pretty easy to create a service principal account: Go to the Azure portal, open the Azure Active Directory of your subscription(s) and choose „App registration“ – “New application registration”: Give your app a name (e. g. : PowerShell-Services) and enter a sign-on URL. User http://localhost for this URL and click “Create”.  Select the previously created app, select “Keys” and go on: Enter a name, select an expiration time and save the configuration: Important: copy your key directly after saving it: Also, copy the application id for later use: And last: copy the tenant id from your Azure Active Directory by selecting it and click on “Properties”: You have all the data you need to logon unattended now: App-id: 21acad78-9006-4f22-9156-xxxxxxxxxxxxx App-key: sjsgUk7a5hgaTkZGuOGeLxxxxxxxxxxxxxxxJ0lXs2/o= Tenant-id: 06522f94-0d15-4fba-aac8-xxxxxxxxxxxxxxx Give the right permissions: In my case, I will use this single app/service principal to shut down and deallocate every VM in my Azure subscription (this can be different in your case and can be a security breach if another user gets the logon data from your PowerShell script). To give the app the right to work with VM I added in on subscription level: Select Subscriptions -&gt; subscription -&gt; Access Control (IAM) -&gt; Add Role: Virtual Machine Contributor* Assign to: Azure AD user, group, or application Select: You application/service principal Save * The app/service principal has the permission to start/stop/modify/… all VM’s in the subscription. If you need more granularity you can create custom roles (https://www. sepago. de/blog/2017/07/13/preventing-administrative-users-to-change-critical-network-settings-in-an-azure-hub) The script: To find from your VM the corresponding one in Azure use this PowerShell script with the service principal credentials and deallocate it: 12345678910111213141516171819202122232425262728$AppId= 21acad78-9006-4f22-9156-xxxxxxxxxxxxx $AppKey= sjsgUk7a5hgaTkZGuOGeLxxxxxxxxxxxxxxxJ0lXs2/o= $TenantId= 06522f94-0d15-4fba-aac8-xxxxxxxxxxxxxxx $md=Invoke-RestMethod -Headers @{ Metadata = true } -URI http://169. 254. 169. 254/metadata/instance?api-version=2017-08-01$Cred = New-Object System. Management. Automation. PSCredential ($AppId, (ConvertTo-SecureString $AppKey -AsPlainText -Force))Login-AzureRmAccount -Credential $cred -ServicePrincipal -TenantId $TenantId# enumerate subscriptions$subscritions=Get-AzureRmSubscriptionforeach ($subscription in $subscritions){  Write-Host( Working on subscription: $($subscription. name) )  Get-AzureRmSubscription -SubscriptionId $subscription. Id |Out-Null  $vms=Get-AzureRmVM  Write-Host( Number of VMs: $($vms. Count) )  $vm=@($vms | where vmId -EQ $md. compute. vmId)  if ($vm -ne 0)  {    Write-Host( Deallocating $($vm. Name) )    Stop-AzureRmVM -Id $vm[0]. Id -Name $vm[0]. Name -Force  } else  {    Write-Host( VM not found in this subscription )  }}Hint: @skillriver wrote a blog shutting to Shutdown and Deallocate an Azure VM using Managed Service Identity. This avoids to create an Azure AD application: https://gotoguy. blog/2018/01/17/shutdown-and-deallocate-an-azure-vm-using-managed-service-identity-and-instance-metadata-service/ First published on: https://www. sepago. de/blog/deallocate-an-azure-vm-from-itself/ "
    }, {
    "id": 26,
    "url": "/How-to-use-http-delete,-put,-head,-connections,-connect-with-an-Azure-Web-App/",
    "title": "How to use http delete, put, head, connections, connect with an Azure Web App",
    "body": "2017/12/27 - I often use Azure Web Apps to deploy tools and programs running serverless. A few weeks ago, I deployed an MVC web site with a controller to handle file uploads to an Azure Storage Account. For the client-side, I used jquery-FileUpload, which also allows triggering a controller to delete a file. If a user tries to delete a file, jquery-FileUpload triggers the controller with the http-request method “DELETE”. In my local environment, this worked as expected but nothing happened in my Azure Web App deployment. If found out that an Azure Web App supports only http-get and post by default. My first attempt was to add the methods DELETE via web. config: 1&lt;add name= ExtensionlessUrlHandler-Integrated-4. 0  path= *.   verb=  DELETE  type= System. Web. Handlers. TransferRequestHandler  preCondition= integratedMode,runtimeVersionv4. 0  /&gt;But this didn’t work. The full web site was no longer accessible: The page cannot be displayed because an internal server error has occurred. The right way to add a method/verb is to remove all first and then re-add them: 12&lt;remove name= ExtensionlessUrlHandler-Integrated-4. 0  /&gt;&lt;add name= ExtensionlessUrlHandler-Integrated-4. 0  path= *.   verb= GET,POST,PUT,DELETE  type= System. Web. Handlers. TransferRequestHandler  preCondition= integratedMode,runtimeVersionv4. 0  /&gt; First published on: https://www. sepago. de/blog/how-to-use-http-delete-put-head-connections-connect-with-an-azure-web-app/ "
    }, {
    "id": 27,
    "url": "/Deploy-a-node.js-script-in-seconds-to-an-Azure-Web-App-with-git-and-run-it-server-less/",
    "title": "Deploy a node.js script in seconds to an Azure Web App with git and run it server-less",
    "body": "2017/09/04 - Deploy a node. js script in seconds to an Azure Web App with git and run it server-less In customer projects, I sometimes develop small applications to collect and process data from different data sources or to offer a web interface. In any case, I try to avoid rolling out a VM to run these apps. I strictly prefer using Platform-as-a-Service and it works nearly 100% if I use an Azure Web App or Azure Functions. The advantages are obvious:  No patching of VM’s No further infrastructure for VM’s No monitoring of OS specific metrics No additional monitoring solution Not involved in release cycles for the operating system And a lot moreIn this post, I will describe how easy it is to deploy a node. js application with git to an Azure Web App. To make it more comprehensible I will describe it with a node. js game called “tanks” from @darthrubens. Tanks is a multi-player game developed in node. js. Tools: Later in this post we will need a few tools to test the game locally and to upload it to an Azure Web App. Install:  Node. js: https://nodejs. orgto test the node. js application locally Git: https://git-for-windows. github. ioto manage the source code and in this case: to upload applications The node. js application for this test: https://github. com/rubentd/tanksdownload the zip file and extract it to a folderCreate an Azure Web App: Create an Azure Web App in the Azure Portal with an App service plan (or use an existing one):  Use at least a standard pricing tier to enable apps to run permanently.  false Configuration of the Azure Web App (save it): Get the publishing information (username and password) by downloading the profile:  Write down the username, password and the web app url for later. Test the application locally (optional): Extract the zip file from tanks to a folder, open a command line and navigate to this folder. At the very first time, you must install the packages and dependencies for the node. js application. Type: npm install To run the node. js application type: npm start The application starts and is accessible by this url: http://localhost:8082/  Upload the node. js application to the Azure Web App: In this post, I use git to manage the source code and upload it to Azure. I recommend learning how to use git. It’s a very powerful tool. I only describe the necessary steps here. First initialize your git project by typing: git init Add the files and directories to your local repository *git add ** Then commit all to git: git commit -m “Init” Add the web app as a remote repository (use your web app url and add scm after the host name): git remote add azure http://deploy-an-app. scm. azurewebsites. net And finally push your application (you will be asked for the username and password) git push azure master Hint: Git ignores node_modules folder. The modules will be installed by the Azure Web App based on the dependencies listed in packages. json   Done: Your Azure Web App is now running your node. js application: First published on: https://www. sepago. de/blog/deploy-a-node-js-script-in-seconds-to-an-azure-web-app-with-git-and-run-it-server-less/ "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});